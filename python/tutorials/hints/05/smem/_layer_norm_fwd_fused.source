#loc = loc(unknown)
#loc1 = loc("X")
#loc2 = loc("Y")
#loc3 = loc("W")
#loc4 = loc("B")
#loc5 = loc("Mean")
#loc6 = loc("Rstd")
#loc7 = loc("stride")
#loc8 = loc("N")
#loc9 = loc("eps")
#loc12 = loc("input")
#loc13 = loc("a")
#loc14 = loc("b")
module {
  tt.func public @_layer_norm_fwd_fused(%X: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("X"), %Y: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("Y"), %W: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("W"), %B: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("B"), %Mean: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("Mean"), %Rstd: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("Rstd"), %stride: i32 {tt.divisibility = 16 : i32} loc("stride"), %N: i32 {tt.divisibility = 16 : i32} loc("N"), %eps: f32 loc("eps")) attributes {noinline = false} {
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = arith.extsi %0 : i32 to i64 loc(#loc)
    %2 = arith.extsi %stride : i32 to i64 loc(#loc)
    %3 = arith.muli %1, %2 : i64 loc(#loc)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc)
    %4 = arith.cmpi sle, %3, %c2147483647_i64 : i64 loc(#loc)
    %5 = arith.cmpi sge, %3, %c-2147483648_i64 : i64 loc(#loc)
    %6 = arith.andi %4, %5 : i1 loc(#loc)
    %7 = arith.muli %0, %stride : i32 loc(#loc)
    %8 = tt.addptr %Y, %7 : !tt.ptr<f16>, i32 loc(#loc)
    %9 = arith.extsi %0 : i32 to i64 loc(#loc)
    %10 = arith.extsi %stride : i32 to i64 loc(#loc)
    %11 = arith.muli %9, %10 : i64 loc(#loc)
    %c2147483647_i64_0 = arith.constant 2147483647 : i64 loc(#loc)
    %c-2147483648_i64_1 = arith.constant -2147483648 : i64 loc(#loc)
    %12 = arith.cmpi sle, %11, %c2147483647_i64_0 : i64 loc(#loc)
    %13 = arith.cmpi sge, %11, %c-2147483648_i64_1 : i64 loc(#loc)
    %14 = arith.andi %12, %13 : i1 loc(#loc)
    %15 = arith.muli %0, %stride : i32 loc(#loc)
    %16 = tt.addptr %X, %15 : !tt.ptr<f16>, i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %17 = tt.call @"triton.language.standard.zeros____(0, 0)cconstexpr_8192__(1,)cconstexpr_fp32_"() : () -> tensor<8192xf32> loc(#loc)
    %c0_i32_2 = arith.constant 0 : i32 loc(#loc)
    %c8192_i32 = arith.constant 8192 : i32 loc(#loc)
    %18 = arith.bitcast %c0_i32_2 : i32 to i32 loc(#loc)
    %19 = arith.bitcast %N : i32 to i32 loc(#loc)
    %20 = arith.bitcast %c8192_i32 : i32 to i32 loc(#loc)
    %21 = ub.poison : i32 loc(#loc)
    %_mean = scf.for %off = %18 to %19 step %20 iter_args(%_mean_7 = %17) -> (tensor<8192xf32>)  : i32 {
      %42 = tt.make_range {end = 8192 : i32, start = 0 : i32} : tensor<8192xi32> loc(#loc)
      %43 = tt.splat %off : i32 -> tensor<8192xi32> loc(#loc)
      %44 = arith.extsi %43 : tensor<8192xi32> to tensor<8192xi64> loc(#loc)
      %45 = arith.extsi %42 : tensor<8192xi32> to tensor<8192xi64> loc(#loc)
      %46 = arith.addi %44, %45 : tensor<8192xi64> loc(#loc)
      %c2147483647_i64_8 = arith.constant 2147483647 : i64 loc(#loc)
      %c-2147483648_i64_9 = arith.constant -2147483648 : i64 loc(#loc)
      %cst_10 = arith.constant dense<2147483647> : tensor<8192xi64> loc(#loc)
      %47 = arith.cmpi sle, %46, %cst_10 : tensor<8192xi64> loc(#loc)
      %cst_11 = arith.constant dense<-2147483648> : tensor<8192xi64> loc(#loc)
      %48 = arith.cmpi sge, %46, %cst_11 : tensor<8192xi64> loc(#loc)
      %49 = arith.andi %47, %48 : tensor<8192xi1> loc(#loc)
      %50 = arith.addi %43, %42 : tensor<8192xi32> loc(#loc)
      %51 = tt.splat %N : i32 -> tensor<8192xi32> loc(#loc)
      %52 = arith.cmpi slt, %50, %51 : tensor<8192xi32> loc(#loc)
      %53 = tt.splat %16 : !tt.ptr<f16> -> tensor<8192x!tt.ptr<f16>> loc(#loc)
      %54 = tt.addptr %53, %50 : tensor<8192x!tt.ptr<f16>>, tensor<8192xi32> loc(#loc)
      %cst_12 = arith.constant 0.000000e+00 : f32 loc(#loc)
      %cst_13 = arith.constant dense<0.000000e+00> : tensor<8192xf32> loc(#loc)
      %55 = arith.truncf %cst_13 : tensor<8192xf32> to tensor<8192xf16> loc(#loc)
      %56 = tt.load %54, %52, %55 {flagtree_hints = "shared_memory"} : tensor<8192x!tt.ptr<f16>> loc(#loc)
      %57 = arith.extf %56 : tensor<8192xf16> to tensor<8192xf32> loc(#loc)
      %58 = arith.addf %_mean_7, %57 : tensor<8192xf32> loc(#loc)
      scf.yield %58 : tensor<8192xf32> loc(#loc)
    } loc(#loc10)
    %22 = tt.call @"triton.language.standard.sum__fp32S8192S__(1,)cconstexpr_0__(2,)cconstexpr_False__(3,)cNone"(%_mean) : (tensor<8192xf32>) -> f32 loc(#loc)
    %23 = arith.sitofp %N : i32 to f32 loc(#loc)
    %24 = arith.divf %22, %23 : f32 loc(#loc)
    %25 = tt.call @"triton.language.standard.zeros____(0, 0)cconstexpr_8192__(1,)cconstexpr_fp32_"() : () -> tensor<8192xf32> loc(#loc)
    %c0_i32_3 = arith.constant 0 : i32 loc(#loc)
    %c8192_i32_4 = arith.constant 8192 : i32 loc(#loc)
    %26 = arith.bitcast %c0_i32_3 : i32 to i32 loc(#loc)
    %27 = arith.bitcast %N : i32 to i32 loc(#loc)
    %28 = arith.bitcast %c8192_i32_4 : i32 to i32 loc(#loc)
    %29 = ub.poison : i32 loc(#loc)
    %_var = scf.for %off = %26 to %27 step %28 iter_args(%_var_7 = %25) -> (tensor<8192xf32>)  : i32 {
      %42 = tt.make_range {end = 8192 : i32, start = 0 : i32} : tensor<8192xi32> loc(#loc)
      %43 = tt.splat %off : i32 -> tensor<8192xi32> loc(#loc)
      %44 = arith.extsi %43 : tensor<8192xi32> to tensor<8192xi64> loc(#loc)
      %45 = arith.extsi %42 : tensor<8192xi32> to tensor<8192xi64> loc(#loc)
      %46 = arith.addi %44, %45 : tensor<8192xi64> loc(#loc)
      %c2147483647_i64_8 = arith.constant 2147483647 : i64 loc(#loc)
      %c-2147483648_i64_9 = arith.constant -2147483648 : i64 loc(#loc)
      %cst_10 = arith.constant dense<2147483647> : tensor<8192xi64> loc(#loc)
      %47 = arith.cmpi sle, %46, %cst_10 : tensor<8192xi64> loc(#loc)
      %cst_11 = arith.constant dense<-2147483648> : tensor<8192xi64> loc(#loc)
      %48 = arith.cmpi sge, %46, %cst_11 : tensor<8192xi64> loc(#loc)
      %49 = arith.andi %47, %48 : tensor<8192xi1> loc(#loc)
      %50 = arith.addi %43, %42 : tensor<8192xi32> loc(#loc)
      %51 = tt.splat %N : i32 -> tensor<8192xi32> loc(#loc)
      %52 = arith.cmpi slt, %50, %51 : tensor<8192xi32> loc(#loc)
      %53 = tt.splat %16 : !tt.ptr<f16> -> tensor<8192x!tt.ptr<f16>> loc(#loc)
      %54 = tt.addptr %53, %50 : tensor<8192x!tt.ptr<f16>>, tensor<8192xi32> loc(#loc)
      %cst_12 = arith.constant 0.000000e+00 : f32 loc(#loc)
      %cst_13 = arith.constant dense<0.000000e+00> : tensor<8192xf32> loc(#loc)
      %55 = arith.truncf %cst_13 : tensor<8192xf32> to tensor<8192xf16> loc(#loc)
      %56 = tt.load %54, %52, %55 {flagtree_hints = "shared_memory"} : tensor<8192x!tt.ptr<f16>> loc(#loc)
      %57 = arith.extf %56 : tensor<8192xf16> to tensor<8192xf32> loc(#loc)
      %58 = tt.splat %N : i32 -> tensor<8192xi32> loc(#loc)
      %59 = arith.cmpi slt, %50, %58 : tensor<8192xi32> loc(#loc)
      %60 = tt.splat %24 : f32 -> tensor<8192xf32> loc(#loc)
      %61 = arith.subf %57, %60 : tensor<8192xf32> loc(#loc)
      %cst_14 = arith.constant 0.000000e+00 : f32 loc(#loc)
      %cst_15 = arith.constant 0.000000e+00 : f32 loc(#loc)
      %cst_16 = arith.constant dense<0.000000e+00> : tensor<8192xf32> loc(#loc)
      %62 = arith.select %59, %61, %cst_16 : tensor<8192xi1>, tensor<8192xf32> loc(#loc)
      %63 = arith.mulf %62, %62 : tensor<8192xf32> loc(#loc)
      %64 = arith.addf %_var_7, %63 : tensor<8192xf32> loc(#loc)
      scf.yield %64 : tensor<8192xf32> loc(#loc)
    } loc(#loc11)
    %30 = tt.call @"triton.language.standard.sum__fp32S8192S__(1,)cconstexpr_0__(2,)cconstexpr_False__(3,)cNone"(%_var) : (tensor<8192xf32>) -> f32 loc(#loc)
    %31 = arith.sitofp %N : i32 to f32 loc(#loc)
    %32 = arith.divf %30, %31 : f32 loc(#loc)
    %33 = arith.addf %32, %eps : f32 loc(#loc)
    %34 = math.sqrt %33 : f32 loc(#loc)
    %c1_i32 = arith.constant 1 : i32 loc(#loc)
    %cst = arith.constant 1.000000e+00 : f32 loc(#loc)
    %35 = arith.divf %cst, %34 : f32 loc(#loc)
    %36 = tt.addptr %Mean, %0 : !tt.ptr<f32>, i32 loc(#loc)
    tt.store %36, %24 : !tt.ptr<f32> loc(#loc)
    %37 = tt.addptr %Rstd, %0 : !tt.ptr<f32>, i32 loc(#loc)
    tt.store %37, %35 : !tt.ptr<f32> loc(#loc)
    %c0_i32_5 = arith.constant 0 : i32 loc(#loc)
    %c8192_i32_6 = arith.constant 8192 : i32 loc(#loc)
    %38 = arith.bitcast %c0_i32_5 : i32 to i32 loc(#loc)
    %39 = arith.bitcast %N : i32 to i32 loc(#loc)
    %40 = arith.bitcast %c8192_i32_6 : i32 to i32 loc(#loc)
    %41 = ub.poison : i32 loc(#loc)
    scf.for %off = %38 to %39 step %40  : i32 {
      %42 = tt.make_range {end = 8192 : i32, start = 0 : i32} : tensor<8192xi32> loc(#loc)
      %43 = tt.splat %off : i32 -> tensor<8192xi32> loc(#loc)
      %44 = arith.extsi %43 : tensor<8192xi32> to tensor<8192xi64> loc(#loc)
      %45 = arith.extsi %42 : tensor<8192xi32> to tensor<8192xi64> loc(#loc)
      %46 = arith.addi %44, %45 : tensor<8192xi64> loc(#loc)
      %c2147483647_i64_7 = arith.constant 2147483647 : i64 loc(#loc)
      %c-2147483648_i64_8 = arith.constant -2147483648 : i64 loc(#loc)
      %cst_9 = arith.constant dense<2147483647> : tensor<8192xi64> loc(#loc)
      %47 = arith.cmpi sle, %46, %cst_9 : tensor<8192xi64> loc(#loc)
      %cst_10 = arith.constant dense<-2147483648> : tensor<8192xi64> loc(#loc)
      %48 = arith.cmpi sge, %46, %cst_10 : tensor<8192xi64> loc(#loc)
      %49 = arith.andi %47, %48 : tensor<8192xi1> loc(#loc)
      %50 = arith.addi %43, %42 : tensor<8192xi32> loc(#loc)
      %51 = tt.splat %N : i32 -> tensor<8192xi32> loc(#loc)
      %52 = arith.cmpi slt, %50, %51 : tensor<8192xi32> loc(#loc)
      %53 = tt.splat %W : !tt.ptr<f16> -> tensor<8192x!tt.ptr<f16>> loc(#loc)
      %54 = tt.addptr %53, %50 : tensor<8192x!tt.ptr<f16>>, tensor<8192xi32> loc(#loc)
      %55 = tt.load %54, %52 {flagtree_hints = "shared_memory"} : tensor<8192x!tt.ptr<f16>> loc(#loc)
      %56 = tt.splat %B : !tt.ptr<f16> -> tensor<8192x!tt.ptr<f16>> loc(#loc)
      %57 = tt.addptr %56, %50 : tensor<8192x!tt.ptr<f16>>, tensor<8192xi32> loc(#loc)
      %58 = tt.load %57, %52 {flagtree_hints = "shared_memory"} : tensor<8192x!tt.ptr<f16>> loc(#loc)
      %59 = tt.splat %16 : !tt.ptr<f16> -> tensor<8192x!tt.ptr<f16>> loc(#loc)
      %60 = tt.addptr %59, %50 : tensor<8192x!tt.ptr<f16>>, tensor<8192xi32> loc(#loc)
      %cst_11 = arith.constant 0.000000e+00 : f32 loc(#loc)
      %cst_12 = arith.constant dense<0.000000e+00> : tensor<8192xf32> loc(#loc)
      %61 = arith.truncf %cst_12 : tensor<8192xf32> to tensor<8192xf16> loc(#loc)
      %62 = tt.load %60, %52, %61 {flagtree_hints = "shared_memory"} : tensor<8192x!tt.ptr<f16>> loc(#loc)
      %63 = arith.extf %62 : tensor<8192xf16> to tensor<8192xf32> loc(#loc)
      %64 = tt.splat %24 : f32 -> tensor<8192xf32> loc(#loc)
      %65 = arith.subf %63, %64 : tensor<8192xf32> loc(#loc)
      %66 = tt.splat %35 : f32 -> tensor<8192xf32> loc(#loc)
      %67 = arith.mulf %65, %66 : tensor<8192xf32> loc(#loc)
      %68 = arith.extf %55 : tensor<8192xf16> to tensor<8192xf32> loc(#loc)
      %69 = arith.mulf %67, %68 : tensor<8192xf32> loc(#loc)
      %70 = arith.extf %58 : tensor<8192xf16> to tensor<8192xf32> loc(#loc)
      %71 = arith.addf %69, %70 : tensor<8192xf32> loc(#loc)
      %72 = tt.splat %8 : !tt.ptr<f16> -> tensor<8192x!tt.ptr<f16>> loc(#loc)
      %73 = tt.addptr %72, %50 : tensor<8192x!tt.ptr<f16>>, tensor<8192xi32> loc(#loc)
      %74 = arith.truncf %71 : tensor<8192xf32> to tensor<8192xf16> loc(#loc)
      tt.store %73, %74, %52 : tensor<8192x!tt.ptr<f16>> loc(#loc)
    } loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
  tt.func private @"triton.language.standard.zeros____(0, 0)cconstexpr_8192__(1,)cconstexpr_fp32_"() -> tensor<8192xf32> attributes {noinline = false} {
    %cst = arith.constant 0.000000e+00 : f32 loc(#loc)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<8192xf32> loc(#loc)
    tt.return %cst_0 : tensor<8192xf32> loc(#loc)
  ^bb1:  // no predecessors
    %0 = ub.poison : tensor<8192xf32> loc(#loc)
    tt.return %0 : tensor<8192xf32> loc(#loc)
  } loc(#loc)
  tt.func private @"triton.language.standard.sum__fp32S8192S__(1,)cconstexpr_0__(2,)cconstexpr_False__(3,)cNone"(%input: tensor<8192xf32> loc("input")) -> f32 attributes {noinline = false} {
    %0 = "tt.reduce"(%input) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32 loc(unknown), %arg2: f32 loc(unknown)):
      %2 = tt.call @triton.language.standard._sum_combine__fp32_fp32__(%arg1, %arg2) : (f32, f32) -> f32 loc(#loc)
      tt.reduce.return %2 : f32 loc(#loc)
    }) : (tensor<8192xf32>) -> f32 loc(#loc)
    tt.return %0 : f32 loc(#loc)
  ^bb1:  // no predecessors
    %1 = ub.poison : f32 loc(#loc)
    tt.return %1 : f32 loc(#loc)
  } loc(#loc)
  tt.func private @triton.language.standard._sum_combine__fp32_fp32__(%a: f32 loc("a"), %b: f32 loc("b")) -> f32 attributes {noinline = false} {
    %0 = arith.addf %a, %b : f32 loc(#loc)
    tt.return %0 : f32 loc(#loc)
  ^bb1:  // no predecessors
    %1 = ub.poison : f32 loc(#loc)
    tt.return %1 : f32 loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc10 = loc("_mean")
#loc11 = loc("_var")
