//
// Generated by LLVM NVPTX Back-End
//

.version 8.7
.target sm_90a
.address_size 64

	// .globl	softmax_kernel          // -- Begin function softmax_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @softmax_kernel
.visible .entry softmax_kernel(
	.param .u64 .ptr .global .align 1 softmax_kernel_param_0,
	.param .u64 .ptr .global .align 1 softmax_kernel_param_1,
	.param .u32 softmax_kernel_param_2,
	.param .u32 softmax_kernel_param_3,
	.param .u32 softmax_kernel_param_4,
	.param .u32 softmax_kernel_param_5,
	.param .u64 .ptr .global .align 1 softmax_kernel_param_6,
	.param .u64 .ptr .global .align 1 softmax_kernel_param_7
)
.reqntid 256
{
	.reg .pred 	%p<23>;
	.reg .b32 	%r<177>;
	.reg .b64 	%rd<34>;

// %bb.0:
	ld.param.b32 	%r29, [softmax_kernel_param_5];
	ld.param.b32 	%r28, [softmax_kernel_param_4];
	ld.param.b32 	%r26, [softmax_kernel_param_2];
	ld.param.b64 	%rd4, [softmax_kernel_param_1];
	mov.u32 	%r176, %ctaid.x;
	mov.u32 	%r2, %nctaid.x;
	mov.u32 	%r3, %tid.x;
	and.b32 	%r54, %r3, 255;
	or.b32 	%r4, %r54, 256;
	or.b32 	%r5, %r54, 512;
	or.b32 	%r55, %r3, 768;
	setp.lt.s32 	%p1, %r54, %r29;
	setp.lt.s32 	%p2, %r4, %r29;
	setp.lt.s32 	%p3, %r5, %r29;
	setp.lt.s32 	%p4, %r55, %r29;
	setp.ge.s32 	%p5, %r176, %r28;
	setp.lt.s32 	%p6, %r176, %r28;
	mul.lo.s32 	%r56, %r26, %r176;
	mad.wide.s32 	%rd17, %r56, 4, %rd4;
	mul.wide.u32 	%rd18, %r54, 4;
	add.s64 	%rd5, %rd17, %rd18;
	add.s64 	%rd6, %rd5, 1024;
	add.s64 	%rd7, %rd5, 2048;
	mul.wide.u32 	%rd19, %r55, 4;
	add.s64 	%rd8, %rd17, %rd19;
	shl.b32 	%r6, %r54, 2;
	mov.b32 	%r57, global_smem;
	add.s32 	%r30, %r57, %r6;
	selp.b32 	%r58, 4, 0, %p1;
	selp.b32 	%r31, %r58, 0, %p6;
	// begin inline asm
	cp.async.ca.shared.global [ %r30 + 0 ], [ %rd5 + 0 ], 0x4, %r31;
	// end inline asm
	add.s32 	%r32, %r30, 1024;
	selp.b32 	%r59, 4, 0, %p2;
	selp.b32 	%r33, %r59, 0, %p6;
	// begin inline asm
	cp.async.ca.shared.global [ %r32 + 0 ], [ %rd6 + 0 ], 0x4, %r33;
	// end inline asm
	add.s32 	%r34, %r30, 2048;
	selp.b32 	%r60, 4, 0, %p3;
	selp.b32 	%r35, %r60, 0, %p6;
	// begin inline asm
	cp.async.ca.shared.global [ %r34 + 0 ], [ %rd7 + 0 ], 0x4, %r35;
	// end inline asm
	add.s32 	%r36, %r30, 3072;
	selp.b32 	%r61, 4, 0, %p4;
	selp.b32 	%r37, %r61, 0, %p6;
	// begin inline asm
	cp.async.ca.shared.global [ %r36 + 0 ], [ %rd8 + 0 ], 0x4, %r37;
	// end inline asm
	cp.async.commit_group;
	add.s32 	%r62, %r176, %r2;
	setp.lt.s32 	%p7, %r62, %r28;
	mul.lo.s32 	%r63, %r26, %r62;
	mad.wide.s32 	%rd20, %r63, 4, %rd4;
	add.s64 	%rd9, %rd20, %rd18;
	add.s64 	%rd10, %rd9, 1024;
	add.s64 	%rd11, %rd9, 2048;
	add.s64 	%rd12, %rd20, %rd19;
	bar.sync 	0;
	add.s32 	%r38, %r30, 4096;
	selp.b32 	%r39, %r58, 0, %p7;
	// begin inline asm
	cp.async.ca.shared.global [ %r38 + 0 ], [ %rd9 + 0 ], 0x4, %r39;
	// end inline asm
	add.s32 	%r40, %r30, 5120;
	selp.b32 	%r41, %r59, 0, %p7;
	// begin inline asm
	cp.async.ca.shared.global [ %r40 + 0 ], [ %rd10 + 0 ], 0x4, %r41;
	// end inline asm
	add.s32 	%r42, %r30, 6144;
	selp.b32 	%r43, %r60, 0, %p7;
	// begin inline asm
	cp.async.ca.shared.global [ %r42 + 0 ], [ %rd11 + 0 ], 0x4, %r43;
	// end inline asm
	add.s32 	%r44, %r30, 7168;
	selp.b32 	%r45, %r61, 0, %p7;
	// begin inline asm
	cp.async.ca.shared.global [ %r44 + 0 ], [ %rd12 + 0 ], 0x4, %r45;
	// end inline asm
	cp.async.commit_group;
	add.s32 	%r64, %r62, %r2;
	setp.lt.s32 	%p8, %r64, %r28;
	mul.lo.s32 	%r65, %r26, %r64;
	mad.wide.s32 	%rd21, %r65, 4, %rd4;
	add.s64 	%rd13, %rd21, %rd18;
	add.s64 	%rd14, %rd13, 1024;
	add.s64 	%rd15, %rd13, 2048;
	add.s64 	%rd16, %rd21, %rd19;
	bar.sync 	0;
	add.s32 	%r46, %r30, 8192;
	selp.b32 	%r47, %r58, 0, %p8;
	// begin inline asm
	cp.async.ca.shared.global [ %r46 + 0 ], [ %rd13 + 0 ], 0x4, %r47;
	// end inline asm
	add.s32 	%r48, %r30, 9216;
	selp.b32 	%r49, %r59, 0, %p8;
	// begin inline asm
	cp.async.ca.shared.global [ %r48 + 0 ], [ %rd14 + 0 ], 0x4, %r49;
	// end inline asm
	add.s32 	%r50, %r30, 10240;
	selp.b32 	%r51, %r60, 0, %p8;
	// begin inline asm
	cp.async.ca.shared.global [ %r50 + 0 ], [ %rd15 + 0 ], 0x4, %r51;
	// end inline asm
	add.s32 	%r52, %r30, 11264;
	selp.b32 	%r53, %r61, 0, %p8;
	// begin inline asm
	cp.async.ca.shared.global [ %r52 + 0 ], [ %rd16 + 0 ], 0x4, %r53;
	// end inline asm
	cp.async.commit_group;
	@%p5 bra 	$L__BB0_3;
// %bb.1:                               // %.lr.ph
	ld.param.b32 	%r27, [softmax_kernel_param_3];
	ld.param.b64 	%rd3, [softmax_kernel_param_0];
	cvt.u64.u32 	%rd1, %r54;
	cvt.u64.u32 	%rd2, %r55;
	and.b32 	%r7, %r3, 31;
	mul.lo.s32 	%r68, %r2, 3;
	sub.s32 	%r8, %r28, %r68;
	shl.b32 	%r69, %r3, 7;
	and.b32 	%r70, %r69, 3072;
	shl.b32 	%r71, %r3, 4;
	and.b32 	%r72, %r71, 112;
	shl.b32 	%r73, %r3, 2;
	and.b32 	%r74, %r73, 896;
	add.s32 	%r76, %r57, %r70;
	add.s32 	%r77, %r76, %r72;
	add.s32 	%r9, %r77, %r74;
	add.s32 	%r78, %r57, 12288;
	shr.u32 	%r79, %r3, 3;
	and.b32 	%r80, %r79, 28;
	add.s32 	%r87, %r78, %r80;
	add.s32 	%r90, %r78, %r73;
	add.s32 	%r81, %r176, %r68;
	mul.lo.s32 	%r173, %r26, %r81;
	mul.lo.s32 	%r13, %r2, %r26;
	mul.lo.s32 	%r172, %r176, %r27;
	mul.lo.s32 	%r15, %r2, %r27;
	mov.b32 	%r175, 2;
	mov.b32 	%r174, -1;
	setp.eq.b32 	%p11, %r3, 0;
$L__BB0_2:                              // =>This Inner Loop Header: Depth=1
	setp.lt.u32 	%p10, %r3, 8;
	setp.eq.b32 	%p9, %r7, 0;
	cvt.u32.u64 	%r111, %rd2;
	cvt.u32.u64 	%r112, %rd1;
	setp.lt.s32 	%p18, %r111, %r29;
	setp.lt.s32 	%p15, %r112, %r29;
	setp.lt.s32 	%p19, %r176, %r8;
	add.s32 	%r113, %r174, 1;
	setp.gt.s32 	%p20, %r113, 2;
	selp.b32 	%r174, 0, %r113, %p20;
	cp.async.wait_group 	2;
	bar.sync 	0;
	shl.b32 	%r114, %r174, 12;
	add.s32 	%r86, %r9, %r114;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r82, %r83, %r84, %r85}, [%r86];
	// end inline asm
	selp.f32 	%r115, %r82, 0fFF800000, %p15;
	selp.f32 	%r116, %r83, 0fFF800000, %p2;
	selp.f32 	%r117, %r84, 0fFF800000, %p3;
	selp.f32 	%r118, %r85, 0fFF800000, %p18;
	max.f32 	%r119, %r115, %r116;
	max.f32 	%r120, %r119, %r117;
	max.f32 	%r121, %r120, %r118;
	shfl.sync.bfly.b32 	%r122, %r121, 16, 31, -1;
	max.f32 	%r123, %r121, %r122;
	shfl.sync.bfly.b32 	%r124, %r123, 8, 31, -1;
	max.f32 	%r125, %r123, %r124;
	shfl.sync.bfly.b32 	%r126, %r125, 4, 31, -1;
	max.f32 	%r127, %r125, %r126;
	shfl.sync.bfly.b32 	%r128, %r127, 2, 31, -1;
	max.f32 	%r129, %r127, %r128;
	shfl.sync.bfly.b32 	%r130, %r129, 1, 31, -1;
	max.f32 	%r88, %r129, %r130;
	// begin inline asm
	@%p9 st.shared.b32 [ %r87 + 0 ], %r88;
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p10 ld.shared.b32 %r89, [ %r90 + 0 ];
	// end inline asm
	shfl.sync.bfly.b32 	%r131, %r89, 4, 31, -1;
	max.f32 	%r132, %r89, %r131;
	shfl.sync.bfly.b32 	%r133, %r132, 2, 31, -1;
	max.f32 	%r134, %r132, %r133;
	shfl.sync.bfly.b32 	%r135, %r134, 1, 31, -1;
	max.f32 	%r92, %r134, %r135;
	// begin inline asm
	@%p11 st.shared.b32 [ %r90 + 0 ], %r92;
	// end inline asm
	bar.sync 	0;
	ld.shared.b32 	%r137, [global_smem+12288];
	sub.f32 	%r138, %r115, %r137;
	sub.f32 	%r139, %r116, %r137;
	sub.f32 	%r140, %r117, %r137;
	sub.f32 	%r141, %r118, %r137;
	mul.f32 	%r142, %r138, 0f3FB8AA3B;
	ex2.approx.f32 	%r143, %r142;
	mul.f32 	%r144, %r139, 0f3FB8AA3B;
	ex2.approx.f32 	%r145, %r144;
	mul.f32 	%r146, %r140, 0f3FB8AA3B;
	ex2.approx.f32 	%r147, %r146;
	mul.f32 	%r148, %r141, 0f3FB8AA3B;
	ex2.approx.f32 	%r149, %r148;
	bar.sync 	0;
	add.f32 	%r150, %r143, %r145;
	add.f32 	%r151, %r150, %r147;
	add.f32 	%r152, %r151, %r149;
	shfl.sync.bfly.b32 	%r153, %r152, 16, 31, -1;
	add.f32 	%r154, %r152, %r153;
	shfl.sync.bfly.b32 	%r155, %r154, 8, 31, -1;
	add.f32 	%r156, %r154, %r155;
	shfl.sync.bfly.b32 	%r157, %r156, 4, 31, -1;
	add.f32 	%r158, %r156, %r157;
	shfl.sync.bfly.b32 	%r159, %r158, 2, 31, -1;
	add.f32 	%r160, %r158, %r159;
	shfl.sync.bfly.b32 	%r161, %r160, 1, 31, -1;
	add.f32 	%r94, %r160, %r161;
	// begin inline asm
	@%p9 st.shared.b32 [ %r87 + 0 ], %r94;
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p10 ld.shared.b32 %r95, [ %r90 + 0 ];
	// end inline asm
	shfl.sync.bfly.b32 	%r162, %r95, 4, 31, -1;
	add.f32 	%r163, %r95, %r162;
	shfl.sync.bfly.b32 	%r164, %r163, 2, 31, -1;
	add.f32 	%r165, %r163, %r164;
	shfl.sync.bfly.b32 	%r166, %r165, 1, 31, -1;
	add.f32 	%r98, %r165, %r166;
	// begin inline asm
	@%p11 st.shared.b32 [ %r90 + 0 ], %r98;
	// end inline asm
	bar.sync 	0;
	ld.shared.b32 	%r167, [global_smem+12288];
	div.full.f32 	%r99, %r143, %r167;
	div.full.f32 	%r100, %r145, %r167;
	div.full.f32 	%r101, %r147, %r167;
	div.full.f32 	%r102, %r149, %r167;
	mad.wide.s32 	%rd30, %r172, 4, %rd3;
	shl.b64 	%rd31, %rd1, 2;
	add.s64 	%rd22, %rd30, %rd31;
	add.s64 	%rd23, %rd22, 1024;
	add.s64 	%rd24, %rd22, 2048;
	shl.b64 	%rd32, %rd2, 2;
	add.s64 	%rd25, %rd30, %rd32;
	// begin inline asm
	@%p15 st.global.b32 [ %rd22 + 0 ], { %r99 };
	// end inline asm
	// begin inline asm
	@%p2 st.global.b32 [ %rd23 + 0 ], { %r100 };
	// end inline asm
	// begin inline asm
	@%p3 st.global.b32 [ %rd24 + 0 ], { %r101 };
	// end inline asm
	// begin inline asm
	@%p18 st.global.b32 [ %rd25 + 0 ], { %r102 };
	// end inline asm
	add.s32 	%r168, %r175, 1;
	setp.gt.s32 	%p21, %r168, 2;
	selp.b32 	%r175, 0, %r168, %p21;
	mad.wide.s32 	%rd33, %r173, 4, %rd4;
	add.s64 	%rd26, %rd33, %rd31;
	add.s64 	%rd27, %rd26, 1024;
	add.s64 	%rd28, %rd26, 2048;
	add.s64 	%rd29, %rd33, %rd32;
	shl.b32 	%r169, %r175, 12;
	add.s32 	%r170, %r57, %r169;
	add.s32 	%r103, %r170, %r6;
	selp.b32 	%r171, 4, 0, %p19;
	selp.b32 	%r104, %r171, 0, %p15;
	// begin inline asm
	cp.async.ca.shared.global [ %r103 + 0 ], [ %rd26 + 0 ], 0x4, %r104;
	// end inline asm
	add.s32 	%r105, %r103, 1024;
	selp.b32 	%r106, %r171, 0, %p2;
	// begin inline asm
	cp.async.ca.shared.global [ %r105 + 0 ], [ %rd27 + 0 ], 0x4, %r106;
	// end inline asm
	add.s32 	%r107, %r103, 2048;
	selp.b32 	%r108, %r171, 0, %p3;
	// begin inline asm
	cp.async.ca.shared.global [ %r107 + 0 ], [ %rd28 + 0 ], 0x4, %r108;
	// end inline asm
	add.s32 	%r109, %r103, 3072;
	selp.b32 	%r110, %r171, 0, %p18;
	// begin inline asm
	cp.async.ca.shared.global [ %r109 + 0 ], [ %rd29 + 0 ], 0x4, %r110;
	// end inline asm
	cp.async.commit_group;
	add.s32 	%r176, %r176, %r2;
	add.s32 	%r173, %r173, %r13;
	add.s32 	%r172, %r172, %r15;
	setp.lt.s32 	%p22, %r176, %r28;
	@%p22 bra 	$L__BB0_2;
$L__BB0_3:                              // %._crit_edge
	cp.async.wait_group 	0;
	bar.sync 	0;
	ret;
                                        // -- End function
}
