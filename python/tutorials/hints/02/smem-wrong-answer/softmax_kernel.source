#loc = loc(unknown)
#loc1 = loc("output_ptr")
#loc2 = loc("input_ptr")
#loc3 = loc("input_row_stride")
#loc4 = loc("output_row_stride")
#loc5 = loc("n_rows")
#loc6 = loc("n_cols")
#loc7 = loc("input")
#loc8 = loc("a")
#loc9 = loc("b")
module {
  tt.func public @softmax_kernel(%output_ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("output_ptr"), %input_ptr: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("input_ptr"), %input_row_stride: i32 loc("input_row_stride"), %output_row_stride: i32 loc("output_row_stride"), %n_rows: i32 loc("n_rows"), %n_cols: i32 loc("n_cols")) attributes {noinline = false} {
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = tt.get_num_programs x : i32 loc(#loc)
    %2 = arith.bitcast %0 : i32 to i32 loc(#loc)
    %3 = arith.bitcast %n_rows : i32 to i32 loc(#loc)
    %4 = arith.bitcast %1 : i32 to i32 loc(#loc)
    %5 = ub.poison : i32 loc(#loc)
    scf.for %row_idx = %2 to %3 step %4  : i32 {
      %6 = arith.extsi %row_idx : i32 to i64 loc(#loc)
      %7 = arith.extsi %input_row_stride : i32 to i64 loc(#loc)
      %8 = arith.muli %6, %7 : i64 loc(#loc)
      %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc)
      %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc)
      %9 = arith.cmpi sle, %8, %c2147483647_i64 : i64 loc(#loc)
      %10 = arith.cmpi sge, %8, %c-2147483648_i64 : i64 loc(#loc)
      %11 = arith.andi %9, %10 : i1 loc(#loc)
      %12 = arith.muli %row_idx, %input_row_stride : i32 loc(#loc)
      %13 = tt.addptr %input_ptr, %12 : !tt.ptr<f32>, i32 loc(#loc)
      %14 = tt.make_range {end = 1024 : i32, start = 0 : i32} : tensor<1024xi32> loc(#loc)
      %15 = tt.splat %13 : !tt.ptr<f32> -> tensor<1024x!tt.ptr<f32>> loc(#loc)
      %16 = tt.addptr %15, %14 : tensor<1024x!tt.ptr<f32>>, tensor<1024xi32> loc(#loc)
      %17 = tt.splat %n_cols : i32 -> tensor<1024xi32> loc(#loc)
      %18 = arith.cmpi slt, %14, %17 : tensor<1024xi32> loc(#loc)
      %cst = arith.constant 0xFF800000 : f32 loc(#loc)
      %cst_0 = arith.constant dense<0xFF800000> : tensor<1024xf32> loc(#loc)
      %19 = tt.load %16, %18, %cst_0 {flagtree_hints = "shared_memory"} : tensor<1024x!tt.ptr<f32>> loc(#loc)
      %20 = tt.call @"triton.language.standard.max__fp32S1024S__(1,)cconstexpr_0__(2,)cconstexpr_False__(3,)cconstexpr_True__(4,)cconstexpr_False_"(%19) : (tensor<1024xf32>) -> f32 loc(#loc)
      %21 = tt.splat %20 : f32 -> tensor<1024xf32> loc(#loc)
      %22 = arith.subf %19, %21 : tensor<1024xf32> loc(#loc)
      %23 = math.exp %22 : tensor<1024xf32> loc(#loc)
      %24 = tt.call @"triton.language.standard.sum__fp32S1024S__(1,)cconstexpr_0__(2,)cconstexpr_False__(3,)cNone"(%23) : (tensor<1024xf32>) -> f32 loc(#loc)
      %25 = tt.splat %24 : f32 -> tensor<1024xf32> loc(#loc)
      %26 = arith.divf %23, %25 : tensor<1024xf32> loc(#loc)
      %27 = arith.extsi %row_idx : i32 to i64 loc(#loc)
      %28 = arith.extsi %output_row_stride : i32 to i64 loc(#loc)
      %29 = arith.muli %27, %28 : i64 loc(#loc)
      %c2147483647_i64_1 = arith.constant 2147483647 : i64 loc(#loc)
      %c-2147483648_i64_2 = arith.constant -2147483648 : i64 loc(#loc)
      %30 = arith.cmpi sle, %29, %c2147483647_i64_1 : i64 loc(#loc)
      %31 = arith.cmpi sge, %29, %c-2147483648_i64_2 : i64 loc(#loc)
      %32 = arith.andi %30, %31 : i1 loc(#loc)
      %33 = arith.muli %row_idx, %output_row_stride : i32 loc(#loc)
      %34 = tt.addptr %output_ptr, %33 : !tt.ptr<f32>, i32 loc(#loc)
      %35 = tt.splat %34 : !tt.ptr<f32> -> tensor<1024x!tt.ptr<f32>> loc(#loc)
      %36 = tt.addptr %35, %14 : tensor<1024x!tt.ptr<f32>>, tensor<1024xi32> loc(#loc)
      tt.store %36, %26, %18 : tensor<1024x!tt.ptr<f32>> loc(#loc)
    } {tt.num_stages = 4 : i32} loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
  tt.func private @"triton.language.standard.max__fp32S1024S__(1,)cconstexpr_0__(2,)cconstexpr_False__(3,)cconstexpr_True__(4,)cconstexpr_False_"(%input: tensor<1024xf32> loc("input")) -> f32 attributes {noinline = false} {
    %0 = "tt.reduce"(%input) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32 loc(unknown), %arg2: f32 loc(unknown)):
      %2 = tt.call @triton.language.standard._elementwise_max__fp32_fp32__(%arg1, %arg2) : (f32, f32) -> f32 loc(#loc)
      tt.reduce.return %2 : f32 loc(#loc)
    }) : (tensor<1024xf32>) -> f32 loc(#loc)
    tt.return %0 : f32 loc(#loc)
  ^bb1:  // no predecessors
    %1 = ub.poison : f32 loc(#loc)
    tt.return %1 : f32 loc(#loc)
  } loc(#loc)
  tt.func private @triton.language.standard._elementwise_max__fp32_fp32__(%a: f32 loc("a"), %b: f32 loc("b")) -> f32 attributes {noinline = false} {
    %0 = arith.maxnumf %a, %b : f32 loc(#loc)
    tt.return %0 : f32 loc(#loc)
  ^bb1:  // no predecessors
    %1 = ub.poison : f32 loc(#loc)
    tt.return %1 : f32 loc(#loc)
  } loc(#loc)
  tt.func private @"triton.language.standard.sum__fp32S1024S__(1,)cconstexpr_0__(2,)cconstexpr_False__(3,)cNone"(%input: tensor<1024xf32> loc("input")) -> f32 attributes {noinline = false} {
    %0 = "tt.reduce"(%input) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32 loc(unknown), %arg2: f32 loc(unknown)):
      %2 = tt.call @triton.language.standard._sum_combine__fp32_fp32__(%arg1, %arg2) : (f32, f32) -> f32 loc(#loc)
      tt.reduce.return %2 : f32 loc(#loc)
    }) : (tensor<1024xf32>) -> f32 loc(#loc)
    tt.return %0 : f32 loc(#loc)
  ^bb1:  // no predecessors
    %1 = ub.poison : f32 loc(#loc)
    tt.return %1 : f32 loc(#loc)
  } loc(#loc)
  tt.func private @triton.language.standard._sum_combine__fp32_fp32__(%a: f32 loc("a"), %b: f32 loc("b")) -> f32 attributes {noinline = false} {
    %0 = arith.addf %a, %b : f32 loc(#loc)
    tt.return %0 : f32 loc(#loc)
  ^bb1:  // no predecessors
    %1 = ub.poison : f32 loc(#loc)
    tt.return %1 : f32 loc(#loc)
  } loc(#loc)
} loc(#loc)
