//
// Generated by LLVM NVPTX Back-End
//

.version 8.7
.target sm_90a
.address_size 64

	// .globl	_attn_bwd               // -- Begin function _attn_bwd
.extern .shared .align 16 .b8 global_smem[];
.global .align 1 .b8 _$_str[11] = {95, 95, 67, 85, 68, 65, 95, 70, 84, 90};
                                        // @_attn_bwd
.visible .entry _attn_bwd(
	.param .u64 .ptr .global .align 1 _attn_bwd_param_0,
	.param .u64 .ptr .global .align 1 _attn_bwd_param_1,
	.param .u64 .ptr .global .align 1 _attn_bwd_param_2,
	.param .f32 _attn_bwd_param_3,
	.param .u64 .ptr .global .align 1 _attn_bwd_param_4,
	.param .u64 .ptr .global .align 1 _attn_bwd_param_5,
	.param .u64 .ptr .global .align 1 _attn_bwd_param_6,
	.param .u64 .ptr .global .align 1 _attn_bwd_param_7,
	.param .u64 .ptr .global .align 1 _attn_bwd_param_8,
	.param .u64 .ptr .global .align 1 _attn_bwd_param_9,
	.param .u32 _attn_bwd_param_10,
	.param .u32 _attn_bwd_param_11,
	.param .u32 _attn_bwd_param_12,
	.param .u32 _attn_bwd_param_13,
	.param .u32 _attn_bwd_param_14,
	.param .u64 .ptr .global .align 1 _attn_bwd_param_15,
	.param .u64 .ptr .global .align 1 _attn_bwd_param_16
)
.reqntid 128
{
	.reg .pred 	%p<110>;
	.reg .b16 	%rs<1609>;
	.reg .b32 	%r<8027>;
	.reg .b64 	%rd<715>;

// %bb.0:
	ld.param.b32 	%r1055, [_attn_bwd_param_14];
	ld.param.b32 	%r1054, [_attn_bwd_param_12];
	ld.param.b64 	%rd335, [_attn_bwd_param_7];
	ld.param.b64 	%rd334, [_attn_bwd_param_6];
	ld.param.b64 	%rd333, [_attn_bwd_param_5];
	ld.param.b64 	%rd332, [_attn_bwd_param_4];
	ld.param.b32 	%r1053, [_attn_bwd_param_3];
	ld.param.b64 	%rd331, [_attn_bwd_param_2];
	ld.param.b64 	%rd330, [_attn_bwd_param_1];
	ld.param.b64 	%rd329, [_attn_bwd_param_0];
	mov.u32 	%r1073, %ctaid.z;
	mul.lo.s32 	%r1074, %r1055, %r1073;
	ld.param.b32 	%r1075, [_attn_bwd_param_13];
	div.s32 	%r1077, %r1073, %r1075;
	mul.lo.s32 	%r1078, %r1077, %r1075;
	sub.s32 	%r1079, %r1073, %r1078;
	ld.param.b32 	%r1080, [_attn_bwd_param_11];
	mul.lo.s32 	%r1081, %r1079, %r1080;
	ld.param.b64 	%rd353, [_attn_bwd_param_8];
	ld.param.b64 	%rd354, [_attn_bwd_param_9];
	ld.param.b32 	%r1082, [_attn_bwd_param_10];
	mad.lo.s32 	%r1083, %r1077, %r1082, %r1081;
	cvt.s64.s32 	%rd1, %r1083;
	mov.u32 	%r1084, %ctaid.x;
	mul.wide.s32 	%rd65, %r1083, 2;
	add.s64 	%rd2, %rd329, %rd65;
	add.s64 	%rd355, %rd330, %rd65;
	add.s64 	%rd356, %rd331, %rd65;
	add.s64 	%rd3, %rd332, %rd65;
	mul.wide.s32 	%rd357, %r1074, 4;
	add.s64 	%rd4, %rd353, %rd357;
	add.s64 	%rd5, %rd354, %rd357;
	shl.b32 	%r1085, %r1084, 7;
	mov.u32 	%r1, %tid.x;
	shr.u32 	%r2, %r1, 5;
	shr.u32 	%r1086, %r1, 3;
	bfe.u32 	%r3, %r1, 3, 4;
	and.b32 	%r4, %r1, 96;
	shr.u32 	%r1087, %r4, 1;
	and.b32 	%r5, %r1, 28;
	bfe.u32 	%r1088, %r1, 2, 3;
	or.b32 	%r1089, %r1087, %r1088;
	and.b32 	%r6, %r1, 127;
	or.b32 	%r91, %r3, %r1085;
	or.b32 	%r1090, %r91, 16;
	or.b32 	%r1091, %r1086, %r1085;
	or.b32 	%r1092, %r1091, 112;
	mul.lo.s32 	%r1093, %r1054, %r91;
	mul.lo.s32 	%r1094, %r1054, %r1090;
	shl.b32 	%r7, %r1054, 5;
	add.s32 	%r1095, %r1093, %r7;
	shl.b32 	%r1096, %r1054, 4;
	add.s32 	%r1097, %r1095, %r1096;
	add.s32 	%r1098, %r1097, %r1096;
	add.s32 	%r1099, %r1098, %r1096;
	add.s32 	%r1100, %r1099, %r1096;
	mul.lo.s32 	%r1101, %r1054, %r1092;
	cvt.s64.s32 	%rd6, %r1093;
	mul.wide.s32 	%rd358, %r1093, 2;
	add.s64 	%rd359, %rd355, %rd358;
	cvt.s64.s32 	%rd7, %r1094;
	mul.wide.s32 	%rd360, %r1094, 2;
	add.s64 	%rd361, %rd355, %rd360;
	cvt.s64.s32 	%rd8, %r1095;
	mul.wide.s32 	%rd362, %r1095, 2;
	add.s64 	%rd363, %rd355, %rd362;
	cvt.s64.s32 	%rd9, %r1097;
	mul.wide.s32 	%rd364, %r1097, 2;
	add.s64 	%rd365, %rd355, %rd364;
	cvt.s64.s32 	%rd10, %r1098;
	mul.wide.s32 	%rd366, %r1098, 2;
	add.s64 	%rd367, %rd355, %rd366;
	cvt.s64.s32 	%rd11, %r1099;
	mul.wide.s32 	%rd368, %r1099, 2;
	add.s64 	%rd369, %rd355, %rd368;
	cvt.s64.s32 	%rd12, %r1100;
	mul.wide.s32 	%rd370, %r1100, 2;
	add.s64 	%rd371, %rd355, %rd370;
	cvt.s64.s32 	%rd13, %r1101;
	mul.wide.s32 	%rd372, %r1101, 2;
	add.s64 	%rd373, %rd355, %rd372;
	and.b32 	%r8, %r1, 7;
	shl.b32 	%r1102, %r8, 3;
	cvt.u64.u32 	%rd14, %r1102;
	mul.wide.u32 	%rd374, %r1102, 2;
	add.s64 	%rd336, %rd359, %rd374;
	add.s64 	%rd337, %rd361, %rd374;
	add.s64 	%rd338, %rd363, %rd374;
	add.s64 	%rd339, %rd365, %rd374;
	add.s64 	%rd340, %rd367, %rd374;
	add.s64 	%rd341, %rd369, %rd374;
	add.s64 	%rd342, %rd371, %rd374;
	add.s64 	%rd343, %rd373, %rd374;
	shl.b32 	%r9, %r6, 4;
	mov.b32 	%r1103, global_smem;
	add.s32 	%r4454, %r1103, %r9;
	// begin inline asm
	cp.async.cg.shared.global [ %r4454 + 0 ], [ %rd336 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4455, %r4454, 2048;
	// begin inline asm
	cp.async.cg.shared.global [ %r4455 + 0 ], [ %rd337 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4456, %r4454, 4096;
	// begin inline asm
	cp.async.cg.shared.global [ %r4456 + 0 ], [ %rd338 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4457, %r4454, 6144;
	// begin inline asm
	cp.async.cg.shared.global [ %r4457 + 0 ], [ %rd339 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4458, %r4454, 8192;
	// begin inline asm
	cp.async.cg.shared.global [ %r4458 + 0 ], [ %rd340 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4459, %r4454, 10240;
	// begin inline asm
	cp.async.cg.shared.global [ %r4459 + 0 ], [ %rd341 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4460, %r4454, 12288;
	// begin inline asm
	cp.async.cg.shared.global [ %r4460 + 0 ], [ %rd342 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4461, %r4454, 14336;
	// begin inline asm
	cp.async.cg.shared.global [ %r4461 + 0 ], [ %rd343 + 0 ], 0x10, 0x10;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	add.s64 	%rd375, %rd356, %rd358;
	add.s64 	%rd376, %rd356, %rd360;
	add.s64 	%rd377, %rd356, %rd362;
	add.s64 	%rd378, %rd356, %rd364;
	add.s64 	%rd379, %rd356, %rd366;
	add.s64 	%rd380, %rd356, %rd368;
	add.s64 	%rd381, %rd356, %rd370;
	add.s64 	%rd382, %rd356, %rd372;
	add.s64 	%rd344, %rd375, %rd374;
	add.s64 	%rd345, %rd376, %rd374;
	add.s64 	%rd346, %rd377, %rd374;
	add.s64 	%rd347, %rd378, %rd374;
	add.s64 	%rd348, %rd379, %rd374;
	add.s64 	%rd349, %rd380, %rd374;
	add.s64 	%rd350, %rd381, %rd374;
	add.s64 	%rd351, %rd382, %rd374;
	add.s32 	%r1104, %r1103, 16384;
	add.s32 	%r4462, %r1104, %r9;
	// begin inline asm
	cp.async.cg.shared.global [ %r4462 + 0 ], [ %rd344 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4463, %r4462, 2048;
	// begin inline asm
	cp.async.cg.shared.global [ %r4463 + 0 ], [ %rd345 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4464, %r4462, 4096;
	// begin inline asm
	cp.async.cg.shared.global [ %r4464 + 0 ], [ %rd346 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4465, %r4462, 6144;
	// begin inline asm
	cp.async.cg.shared.global [ %r4465 + 0 ], [ %rd347 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4466, %r4462, 8192;
	// begin inline asm
	cp.async.cg.shared.global [ %r4466 + 0 ], [ %rd348 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4467, %r4462, 10240;
	// begin inline asm
	cp.async.cg.shared.global [ %r4467 + 0 ], [ %rd349 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4468, %r4462, 12288;
	// begin inline asm
	cp.async.cg.shared.global [ %r4468 + 0 ], [ %rd350 + 0 ], 0x10, 0x10;
	// end inline asm
	add.s32 	%r4469, %r4462, 14336;
	// begin inline asm
	cp.async.cg.shared.global [ %r4469 + 0 ], [ %rd351 + 0 ], 0x10, 0x10;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	and.b32 	%r26, %r1, 3;
	or.b32 	%r27, %r1089, %r1085;
	or.b32 	%r28, %r27, 8;
	or.b32 	%r29, %r27, 64;
	or.b32 	%r30, %r27, 72;
	shl.b32 	%r31, %r26, 1;
	or.b32 	%r1105, %r31, 1;
	or.b32 	%r1106, %r31, 8;
	or.b32 	%r1107, %r31, 9;
	and.b32 	%r1108, %r1, 15;
	add.s64 	%rd383, %rd2, %rd358;
	add.s64 	%rd495, %rd383, %rd374;
	add.s64 	%rd384, %rd3, %rd358;
	add.s64 	%rd503, %rd384, %rd374;
	add.s32 	%r1109, %r1103, 32768;
	add.s32 	%r5794, %r1109, %r9;
	shl.b32 	%r33, %r26, 9;
	add.s32 	%r34, %r1109, %r33;
	shl.b32 	%r35, %r26, 3;
	add.s32 	%r1357, %r1103, 34816;
	add.s32 	%r36, %r1357, %r35;
	xor.b32 	%r37, %r35, 16;
	add.s32 	%r38, %r1357, %r37;
	shl.b32 	%r39, %r1108, 7;
	and.b32 	%r1111, %r1086, 14;
	add.s32 	%r1112, %r1109, %r39;
	add.s32 	%r40, %r1112, %r1111;
	shl.b32 	%r1113, %r1, 1;
	and.b32 	%r1114, %r1113, 126;
	bfe.s32 	%r1115, %r1, 6, 1;
	and.b32 	%r1116, %r1115, 144;
	xor.b32 	%r41, %r1116, %r1114;
	add.s32 	%r42, %r1109, %r41;
	and.b32 	%r43, %r1, 112;
	shl.b32 	%r1117, %r1108, 2;
	add.s32 	%r2788, %r1103, 36864;
	add.s32 	%r1137, %r2788, %r1117;
	add.s32 	%r45, %r2788, %r35;
	shl.b32 	%r46, %r4, 6;
	and.b32 	%r47, %r1, 16;
	or.b32 	%r1119, %r46, %r47;
	or.b32 	%r1120, %r1119, %r39;
	add.s32 	%r1142, %r1103, %r1120;
	add.s32 	%r1147, %r1142, 32;
	add.s32 	%r1152, %r1142, 64;
	add.s32 	%r1157, %r1142, 96;
	add.s32 	%r1162, %r1142, 8192;
	add.s32 	%r1167, %r1142, 8224;
	add.s32 	%r1172, %r1142, 8256;
	add.s32 	%r1177, %r1142, 8288;
	bfe.u32 	%r1121, %r1357, 4, 14;
	cvt.u64.u32 	%rd385, %r1121;
	or.b64 	%rd557, %rd385, -4611685949699522560;
	add.s32 	%r1122, %r1103, 35328;
	bfe.u32 	%r1123, %r1122, 4, 14;
	cvt.u64.u32 	%rd386, %r1123;
	or.b64 	%rd558, %rd386, -4611685949699522560;
	add.s32 	%r1124, %r1103, 35840;
	bfe.u32 	%r1125, %r1124, 4, 14;
	cvt.u64.u32 	%rd387, %r1125;
	or.b64 	%rd559, %rd387, -4611685949699522560;
	add.s32 	%r1126, %r1103, 36352;
	bfe.u32 	%r1127, %r1126, 4, 14;
	cvt.u64.u32 	%rd388, %r1127;
	or.b64 	%rd560, %rd388, -4611685949699522560;
	add.s32 	%r1360, %r1357, %r9;
	shl.b32 	%r57, %r1108, 3;
	add.s32 	%r58, %r1357, %r57;
	add.s32 	%r59, %r1137, %r1117;
	xor.b32 	%r60, %r57, 16;
	add.s32 	%r61, %r2788, %r60;
	xor.b32 	%r62, %r57, 32;
	add.s32 	%r63, %r2788, %r62;
	xor.b32 	%r64, %r57, 48;
	add.s32 	%r65, %r2788, %r64;
	xor.b32 	%r66, %r57, 64;
	add.s32 	%r67, %r2788, %r66;
	xor.b32 	%r68, %r57, 80;
	add.s32 	%r69, %r2788, %r68;
	xor.b32 	%r70, %r57, 96;
	add.s32 	%r71, %r2788, %r70;
	xor.b32 	%r72, %r57, 112;
	add.s32 	%r73, %r2788, %r72;
	shl.b32 	%r74, %r6, 1;
	mad.lo.s32 	%r75, %r6, -14, %r1360;
	add.s32 	%r76, %r1357, %r41;
	xor.b32 	%r77, %r41, 32;
	add.s32 	%r78, %r1357, %r77;
	xor.b32 	%r79, %r41, 64;
	add.s32 	%r80, %r1357, %r79;
	xor.b32 	%r81, %r41, 96;
	add.s32 	%r82, %r1357, %r81;
	bfe.u32 	%r1128, %r2788, 4, 14;
	cvt.u64.u32 	%rd21, %r1128;
	or.b64 	%rd408, %rd21, 4611686293313683456;
	add.s32 	%r1636, %r1104, %r1120;
	add.s32 	%r1641, %r1636, 32;
	add.s32 	%r1646, %r1636, 64;
	add.s32 	%r1651, %r1636, 96;
	add.s32 	%r1656, %r1636, 8192;
	add.s32 	%r1661, %r1636, 8224;
	add.s32 	%r1666, %r1636, 8256;
	add.s32 	%r1671, %r1636, 8288;
	or.b64 	%rd411, %rd385, 4611686293313683456;
	add.s32 	%r1129, %r1103, 34848;
	bfe.u32 	%r1130, %r1129, 4, 14;
	cvt.u64.u32 	%rd389, %r1130;
	or.b64 	%rd412, %rd389, 4611686293313683456;
	add.s32 	%r1131, %r1103, 34880;
	bfe.u32 	%r1132, %r1131, 4, 14;
	cvt.u64.u32 	%rd390, %r1132;
	or.b64 	%rd413, %rd390, 4611686293313683456;
	add.s32 	%r1133, %r1103, 34912;
	bfe.u32 	%r1134, %r1133, 4, 14;
	cvt.u64.u32 	%rd391, %r1134;
	or.b64 	%rd414, %rd391, 4611686293313683456;
	bfe.u32 	%r1135, %r1109, 4, 14;
	cvt.u64.u32 	%rd27, %r1135;
	or.b64 	%rd573, %rd27, -4611685949699522560;
	cvt.s64.s32 	%rd29, %r1085;
	cvt.u64.u32 	%rd392, %r1108;
	cvt.u64.u32 	%rd45, %r31;
	cvt.u64.u32 	%rd44, %r1105;
	cvt.u64.u32 	%rd41, %r1106;
	cvt.u64.u32 	%rd40, %r1107;
	cvt.s64.s32 	%rd57, %r27;
	cvt.s64.s32 	%rd55, %r28;
	cvt.s64.s32 	%rd49, %r29;
	cvt.s64.s32 	%rd47, %r30;
	or.b64 	%rd393, %rd29, %rd392;
	shl.b64 	%rd394, %rd393, 2;
	add.s64 	%rd395, %rd394, %rd357;
	add.s64 	%rd62, %rd354, %rd395;
	add.s64 	%rd63, %rd353, %rd395;
	mul.wide.u32 	%rd64, %r8, 16;
	add.s64 	%rd396, %rd64, %rd358;
	add.s64 	%rd678, %rd396, %rd65;
	mul.wide.s32 	%rd67, %r1096, 2;
	mov.b32 	%r7697, 0f00000000;
	mov.b64 	%rd639, 0;
	setp.eq.b32 	%p1, %r43, 0;
	mov.b64 	%rd638, %rd678;
	mov.b64 	%rd640, %rd29;
	mov.b32 	%r7698, %r7697;
	mov.b32 	%r7699, %r7697;
	mov.b32 	%r7700, %r7697;
	mov.b32 	%r7701, %r7697;
	mov.b32 	%r7702, %r7697;
	mov.b32 	%r7703, %r7697;
	mov.b32 	%r7704, %r7697;
	mov.b32 	%r7705, %r7697;
	mov.b32 	%r7706, %r7697;
	mov.b32 	%r7707, %r7697;
	mov.b32 	%r7708, %r7697;
	mov.b32 	%r7709, %r7697;
	mov.b32 	%r7710, %r7697;
	mov.b32 	%r7711, %r7697;
	mov.b32 	%r7712, %r7697;
	mov.b32 	%r7713, %r7697;
	mov.b32 	%r7714, %r7697;
	mov.b32 	%r7715, %r7697;
	mov.b32 	%r7716, %r7697;
	mov.b32 	%r7717, %r7697;
	mov.b32 	%r7718, %r7697;
	mov.b32 	%r7719, %r7697;
	mov.b32 	%r7720, %r7697;
	mov.b32 	%r7721, %r7697;
	mov.b32 	%r7722, %r7697;
	mov.b32 	%r7723, %r7697;
	mov.b32 	%r7724, %r7697;
	mov.b32 	%r7725, %r7697;
	mov.b32 	%r7726, %r7697;
	mov.b32 	%r7727, %r7697;
	mov.b32 	%r7728, %r7697;
	mov.b32 	%r7729, %r7697;
	mov.b32 	%r7730, %r7697;
	mov.b32 	%r7731, %r7697;
	mov.b32 	%r7732, %r7697;
	mov.b32 	%r7733, %r7697;
	mov.b32 	%r7734, %r7697;
	mov.b32 	%r7735, %r7697;
	mov.b32 	%r7736, %r7697;
	mov.b32 	%r7737, %r7697;
	mov.b32 	%r7738, %r7697;
	mov.b32 	%r7739, %r7697;
	mov.b32 	%r7740, %r7697;
	mov.b32 	%r7741, %r7697;
	mov.b32 	%r7742, %r7697;
	mov.b32 	%r7743, %r7697;
	mov.b32 	%r7744, %r7697;
	mov.b32 	%r7745, %r7697;
	mov.b32 	%r7746, %r7697;
	mov.b32 	%r7747, %r7697;
	mov.b32 	%r7748, %r7697;
	mov.b32 	%r7749, %r7697;
	mov.b32 	%r7750, %r7697;
	mov.b32 	%r7751, %r7697;
	mov.b32 	%r7752, %r7697;
	mov.b32 	%r7753, %r7697;
	mov.b32 	%r7754, %r7697;
	mov.b32 	%r7755, %r7697;
	mov.b32 	%r7756, %r7697;
	mov.b32 	%r7757, %r7697;
	mov.b32 	%r7758, %r7697;
	mov.b32 	%r7759, %r7697;
	mov.b32 	%r7760, %r7697;
	mov.b32 	%r7631, %r7697;
	mov.b32 	%r7632, %r7697;
	mov.b32 	%r7633, %r7697;
	mov.b32 	%r7634, %r7697;
	mov.b32 	%r7635, %r7697;
	mov.b32 	%r7636, %r7697;
	mov.b32 	%r7637, %r7697;
	mov.b32 	%r7638, %r7697;
	mov.b32 	%r7639, %r7697;
	mov.b32 	%r7640, %r7697;
	mov.b32 	%r7641, %r7697;
	mov.b32 	%r7642, %r7697;
	mov.b32 	%r7643, %r7697;
	mov.b32 	%r7644, %r7697;
	mov.b32 	%r7645, %r7697;
	mov.b32 	%r7646, %r7697;
	mov.b32 	%r7647, %r7697;
	mov.b32 	%r7648, %r7697;
	mov.b32 	%r7649, %r7697;
	mov.b32 	%r7650, %r7697;
	mov.b32 	%r7651, %r7697;
	mov.b32 	%r7652, %r7697;
	mov.b32 	%r7653, %r7697;
	mov.b32 	%r7654, %r7697;
	mov.b32 	%r7655, %r7697;
	mov.b32 	%r7656, %r7697;
	mov.b32 	%r7657, %r7697;
	mov.b32 	%r7658, %r7697;
	mov.b32 	%r7659, %r7697;
	mov.b32 	%r7660, %r7697;
	mov.b32 	%r7661, %r7697;
	mov.b32 	%r7662, %r7697;
	mov.b32 	%r7663, %r7697;
	mov.b32 	%r7664, %r7697;
	mov.b32 	%r7665, %r7697;
	mov.b32 	%r7666, %r7697;
	mov.b32 	%r7667, %r7697;
	mov.b32 	%r7668, %r7697;
	mov.b32 	%r7669, %r7697;
	mov.b32 	%r7670, %r7697;
	mov.b32 	%r7671, %r7697;
	mov.b32 	%r7672, %r7697;
	mov.b32 	%r7673, %r7697;
	mov.b32 	%r7674, %r7697;
	mov.b32 	%r7675, %r7697;
	mov.b32 	%r7676, %r7697;
	mov.b32 	%r7677, %r7697;
	mov.b32 	%r7678, %r7697;
	mov.b32 	%r7679, %r7697;
	mov.b32 	%r7680, %r7697;
	mov.b32 	%r7681, %r7697;
	mov.b32 	%r7682, %r7697;
	mov.b32 	%r7683, %r7697;
	mov.b32 	%r7684, %r7697;
	mov.b32 	%r7685, %r7697;
	mov.b32 	%r7686, %r7697;
	mov.b32 	%r7687, %r7697;
	mov.b32 	%r7688, %r7697;
	mov.b32 	%r7689, %r7697;
	mov.b32 	%r7690, %r7697;
	mov.b32 	%r7691, %r7697;
	mov.b32 	%r7692, %r7697;
	mov.b32 	%r7693, %r7697;
	mov.b32 	%r7694, %r7697;
$L__BB0_1:                              // %__nv_exp2f.exit488
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd407, %rd332, %rd638;
	add.s64 	%rd397, %rd329, %rd638;
	bar.sync 	0;
	// begin inline asm
	cp.async.cg.shared.global [ %r5794 + 0 ], [ %rd397 + 0 ], 0x10, 0x10;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r2124, %r2125, %r2126, %r2127}, [%r34];
	ld.shared.v4.b32 	{%r2128, %r2129, %r2130, %r2131}, [%r34+128];
	ld.shared.v4.b32 	{%r2132, %r2133, %r2134, %r2135}, [%r34+256];
	ld.shared.v4.b32 	{%r2136, %r2137, %r2138, %r2139}, [%r34+384];
	ld.shared.v4.b32 	{%r2140, %r2141, %r2142, %r2143}, [%r34+16];
	ld.shared.v4.b32 	{%r2144, %r2145, %r2146, %r2147}, [%r34+144];
	ld.shared.v4.b32 	{%r2148, %r2149, %r2150, %r2151}, [%r34+272];
	ld.shared.v4.b32 	{%r2152, %r2153, %r2154, %r2155}, [%r34+400];
	ld.shared.v4.b32 	{%r2156, %r2157, %r2158, %r2159}, [%r34+32];
	ld.shared.v4.b32 	{%r2160, %r2161, %r2162, %r2163}, [%r34+160];
	ld.shared.v4.b32 	{%r2164, %r2165, %r2166, %r2167}, [%r34+288];
	ld.shared.v4.b32 	{%r2168, %r2169, %r2170, %r2171}, [%r34+416];
	ld.shared.v4.b32 	{%r2172, %r2173, %r2174, %r2175}, [%r34+48];
	ld.shared.v4.b32 	{%r2176, %r2177, %r2178, %r2179}, [%r34+176];
	ld.shared.v4.b32 	{%r2180, %r2181, %r2182, %r2183}, [%r34+304];
	ld.shared.v4.b32 	{%r2184, %r2185, %r2186, %r2187}, [%r34+432];
	ld.shared.v4.b32 	{%r2188, %r2189, %r2190, %r2191}, [%r34+64];
	ld.shared.v4.b32 	{%r2192, %r2193, %r2194, %r2195}, [%r34+192];
	ld.shared.v4.b32 	{%r2196, %r2197, %r2198, %r2199}, [%r34+320];
	ld.shared.v4.b32 	{%r2200, %r2201, %r2202, %r2203}, [%r34+448];
	ld.shared.v4.b32 	{%r2204, %r2205, %r2206, %r2207}, [%r34+80];
	ld.shared.v4.b32 	{%r2208, %r2209, %r2210, %r2211}, [%r34+208];
	ld.shared.v4.b32 	{%r2212, %r2213, %r2214, %r2215}, [%r34+336];
	ld.shared.v4.b32 	{%r2216, %r2217, %r2218, %r2219}, [%r34+464];
	ld.shared.v4.b32 	{%r2220, %r2221, %r2222, %r2223}, [%r34+96];
	ld.shared.v4.b32 	{%r2224, %r2225, %r2226, %r2227}, [%r34+224];
	ld.shared.v4.b32 	{%r2228, %r2229, %r2230, %r2231}, [%r34+352];
	ld.shared.v4.b32 	{%r2232, %r2233, %r2234, %r2235}, [%r34+480];
	ld.shared.v4.b32 	{%r2236, %r2237, %r2238, %r2239}, [%r34+112];
	ld.shared.v4.b32 	{%r2240, %r2241, %r2242, %r2243}, [%r34+240];
	ld.shared.v4.b32 	{%r2244, %r2245, %r2246, %r2247}, [%r34+368];
	ld.shared.v4.b32 	{%r2248, %r2249, %r2250, %r2251}, [%r34+496];
	mov.b32 	{%rs1, %rs2}, %r2128;
	mov.b32 	{%rs3, %rs4}, %r2124;
	mov.b32 	{%rs5, %rs6}, %r2132;
	mov.b32 	{%rs7, %rs8}, %r2136;
	st.shared.v4.b16 	[%r36], {%rs3, %rs1, %rs5, %rs7};
	st.shared.v4.b16 	[%r36+32], {%rs4, %rs2, %rs6, %rs8};
	mov.b32 	{%rs9, %rs10}, %r2129;
	mov.b32 	{%rs11, %rs12}, %r2125;
	mov.b32 	{%rs13, %rs14}, %r2133;
	mov.b32 	{%rs15, %rs16}, %r2137;
	st.shared.v4.b16 	[%r36+64], {%rs11, %rs9, %rs13, %rs15};
	st.shared.v4.b16 	[%r36+96], {%rs12, %rs10, %rs14, %rs16};
	mov.b32 	{%rs17, %rs18}, %r2144;
	mov.b32 	{%rs19, %rs20}, %r2140;
	mov.b32 	{%rs21, %rs22}, %r2148;
	mov.b32 	{%rs23, %rs24}, %r2152;
	st.shared.v4.b16 	[%r36+256], {%rs19, %rs17, %rs21, %rs23};
	st.shared.v4.b16 	[%r36+288], {%rs20, %rs18, %rs22, %rs24};
	mov.b32 	{%rs25, %rs26}, %r2145;
	mov.b32 	{%rs27, %rs28}, %r2141;
	mov.b32 	{%rs29, %rs30}, %r2149;
	mov.b32 	{%rs31, %rs32}, %r2153;
	st.shared.v4.b16 	[%r36+320], {%rs27, %rs25, %rs29, %rs31};
	st.shared.v4.b16 	[%r36+352], {%rs28, %rs26, %rs30, %rs32};
	mov.b32 	{%rs33, %rs34}, %r2160;
	mov.b32 	{%rs35, %rs36}, %r2156;
	mov.b32 	{%rs37, %rs38}, %r2164;
	mov.b32 	{%rs39, %rs40}, %r2168;
	st.shared.v4.b16 	[%r36+512], {%rs35, %rs33, %rs37, %rs39};
	st.shared.v4.b16 	[%r36+544], {%rs36, %rs34, %rs38, %rs40};
	mov.b32 	{%rs41, %rs42}, %r2161;
	mov.b32 	{%rs43, %rs44}, %r2157;
	mov.b32 	{%rs45, %rs46}, %r2165;
	mov.b32 	{%rs47, %rs48}, %r2169;
	st.shared.v4.b16 	[%r36+576], {%rs43, %rs41, %rs45, %rs47};
	st.shared.v4.b16 	[%r36+608], {%rs44, %rs42, %rs46, %rs48};
	mov.b32 	{%rs49, %rs50}, %r2176;
	mov.b32 	{%rs51, %rs52}, %r2172;
	mov.b32 	{%rs53, %rs54}, %r2180;
	mov.b32 	{%rs55, %rs56}, %r2184;
	st.shared.v4.b16 	[%r36+768], {%rs51, %rs49, %rs53, %rs55};
	st.shared.v4.b16 	[%r36+800], {%rs52, %rs50, %rs54, %rs56};
	mov.b32 	{%rs57, %rs58}, %r2177;
	mov.b32 	{%rs59, %rs60}, %r2173;
	mov.b32 	{%rs61, %rs62}, %r2181;
	mov.b32 	{%rs63, %rs64}, %r2185;
	st.shared.v4.b16 	[%r36+832], {%rs59, %rs57, %rs61, %rs63};
	st.shared.v4.b16 	[%r36+864], {%rs60, %rs58, %rs62, %rs64};
	mov.b32 	{%rs65, %rs66}, %r2192;
	mov.b32 	{%rs67, %rs68}, %r2188;
	mov.b32 	{%rs69, %rs70}, %r2196;
	mov.b32 	{%rs71, %rs72}, %r2200;
	st.shared.v4.b16 	[%r36+1024], {%rs67, %rs65, %rs69, %rs71};
	st.shared.v4.b16 	[%r36+1056], {%rs68, %rs66, %rs70, %rs72};
	mov.b32 	{%rs73, %rs74}, %r2193;
	mov.b32 	{%rs75, %rs76}, %r2189;
	mov.b32 	{%rs77, %rs78}, %r2197;
	mov.b32 	{%rs79, %rs80}, %r2201;
	st.shared.v4.b16 	[%r36+1088], {%rs75, %rs73, %rs77, %rs79};
	st.shared.v4.b16 	[%r36+1120], {%rs76, %rs74, %rs78, %rs80};
	mov.b32 	{%rs81, %rs82}, %r2208;
	mov.b32 	{%rs83, %rs84}, %r2204;
	mov.b32 	{%rs85, %rs86}, %r2212;
	mov.b32 	{%rs87, %rs88}, %r2216;
	st.shared.v4.b16 	[%r36+1280], {%rs83, %rs81, %rs85, %rs87};
	st.shared.v4.b16 	[%r36+1312], {%rs84, %rs82, %rs86, %rs88};
	mov.b32 	{%rs89, %rs90}, %r2209;
	mov.b32 	{%rs91, %rs92}, %r2205;
	mov.b32 	{%rs93, %rs94}, %r2213;
	mov.b32 	{%rs95, %rs96}, %r2217;
	st.shared.v4.b16 	[%r36+1344], {%rs91, %rs89, %rs93, %rs95};
	st.shared.v4.b16 	[%r36+1376], {%rs92, %rs90, %rs94, %rs96};
	mov.b32 	{%rs97, %rs98}, %r2224;
	mov.b32 	{%rs99, %rs100}, %r2220;
	mov.b32 	{%rs101, %rs102}, %r2228;
	mov.b32 	{%rs103, %rs104}, %r2232;
	st.shared.v4.b16 	[%r36+1536], {%rs99, %rs97, %rs101, %rs103};
	st.shared.v4.b16 	[%r36+1568], {%rs100, %rs98, %rs102, %rs104};
	mov.b32 	{%rs105, %rs106}, %r2225;
	mov.b32 	{%rs107, %rs108}, %r2221;
	mov.b32 	{%rs109, %rs110}, %r2229;
	mov.b32 	{%rs111, %rs112}, %r2233;
	st.shared.v4.b16 	[%r36+1600], {%rs107, %rs105, %rs109, %rs111};
	st.shared.v4.b16 	[%r36+1632], {%rs108, %rs106, %rs110, %rs112};
	mov.b32 	{%rs113, %rs114}, %r2240;
	mov.b32 	{%rs115, %rs116}, %r2236;
	mov.b32 	{%rs117, %rs118}, %r2244;
	mov.b32 	{%rs119, %rs120}, %r2248;
	st.shared.v4.b16 	[%r36+1792], {%rs115, %rs113, %rs117, %rs119};
	st.shared.v4.b16 	[%r36+1824], {%rs116, %rs114, %rs118, %rs120};
	mov.b32 	{%rs121, %rs122}, %r2241;
	mov.b32 	{%rs123, %rs124}, %r2237;
	mov.b32 	{%rs125, %rs126}, %r2245;
	mov.b32 	{%rs127, %rs128}, %r2249;
	st.shared.v4.b16 	[%r36+1856], {%rs123, %rs121, %rs125, %rs127};
	st.shared.v4.b16 	[%r36+1888], {%rs124, %rs122, %rs126, %rs128};
	mov.b32 	{%rs129, %rs130}, %r2130;
	mov.b32 	{%rs131, %rs132}, %r2126;
	mov.b32 	{%rs133, %rs134}, %r2134;
	mov.b32 	{%rs135, %rs136}, %r2138;
	st.shared.v4.b16 	[%r38+128], {%rs131, %rs129, %rs133, %rs135};
	st.shared.v4.b16 	[%r38+160], {%rs132, %rs130, %rs134, %rs136};
	mov.b32 	{%rs137, %rs138}, %r2131;
	mov.b32 	{%rs139, %rs140}, %r2127;
	mov.b32 	{%rs141, %rs142}, %r2135;
	mov.b32 	{%rs143, %rs144}, %r2139;
	st.shared.v4.b16 	[%r38+192], {%rs139, %rs137, %rs141, %rs143};
	st.shared.v4.b16 	[%r38+224], {%rs140, %rs138, %rs142, %rs144};
	mov.b32 	{%rs145, %rs146}, %r2146;
	mov.b32 	{%rs147, %rs148}, %r2142;
	mov.b32 	{%rs149, %rs150}, %r2150;
	mov.b32 	{%rs151, %rs152}, %r2154;
	st.shared.v4.b16 	[%r38+384], {%rs147, %rs145, %rs149, %rs151};
	st.shared.v4.b16 	[%r38+416], {%rs148, %rs146, %rs150, %rs152};
	mov.b32 	{%rs153, %rs154}, %r2147;
	mov.b32 	{%rs155, %rs156}, %r2143;
	mov.b32 	{%rs157, %rs158}, %r2151;
	mov.b32 	{%rs159, %rs160}, %r2155;
	st.shared.v4.b16 	[%r38+448], {%rs155, %rs153, %rs157, %rs159};
	st.shared.v4.b16 	[%r38+480], {%rs156, %rs154, %rs158, %rs160};
	mov.b32 	{%rs161, %rs162}, %r2162;
	mov.b32 	{%rs163, %rs164}, %r2158;
	mov.b32 	{%rs165, %rs166}, %r2166;
	mov.b32 	{%rs167, %rs168}, %r2170;
	st.shared.v4.b16 	[%r38+640], {%rs163, %rs161, %rs165, %rs167};
	st.shared.v4.b16 	[%r38+672], {%rs164, %rs162, %rs166, %rs168};
	mov.b32 	{%rs169, %rs170}, %r2163;
	mov.b32 	{%rs171, %rs172}, %r2159;
	mov.b32 	{%rs173, %rs174}, %r2167;
	mov.b32 	{%rs175, %rs176}, %r2171;
	st.shared.v4.b16 	[%r38+704], {%rs171, %rs169, %rs173, %rs175};
	st.shared.v4.b16 	[%r38+736], {%rs172, %rs170, %rs174, %rs176};
	mov.b32 	{%rs177, %rs178}, %r2178;
	mov.b32 	{%rs179, %rs180}, %r2174;
	mov.b32 	{%rs181, %rs182}, %r2182;
	mov.b32 	{%rs183, %rs184}, %r2186;
	st.shared.v4.b16 	[%r38+896], {%rs179, %rs177, %rs181, %rs183};
	st.shared.v4.b16 	[%r38+928], {%rs180, %rs178, %rs182, %rs184};
	mov.b32 	{%rs185, %rs186}, %r2179;
	mov.b32 	{%rs187, %rs188}, %r2175;
	mov.b32 	{%rs189, %rs190}, %r2183;
	mov.b32 	{%rs191, %rs192}, %r2187;
	st.shared.v4.b16 	[%r38+960], {%rs187, %rs185, %rs189, %rs191};
	st.shared.v4.b16 	[%r38+992], {%rs188, %rs186, %rs190, %rs192};
	mov.b32 	{%rs193, %rs194}, %r2194;
	mov.b32 	{%rs195, %rs196}, %r2190;
	mov.b32 	{%rs197, %rs198}, %r2198;
	mov.b32 	{%rs199, %rs200}, %r2202;
	st.shared.v4.b16 	[%r38+1152], {%rs195, %rs193, %rs197, %rs199};
	st.shared.v4.b16 	[%r38+1184], {%rs196, %rs194, %rs198, %rs200};
	mov.b32 	{%rs201, %rs202}, %r2195;
	mov.b32 	{%rs203, %rs204}, %r2191;
	mov.b32 	{%rs205, %rs206}, %r2199;
	mov.b32 	{%rs207, %rs208}, %r2203;
	st.shared.v4.b16 	[%r38+1216], {%rs203, %rs201, %rs205, %rs207};
	st.shared.v4.b16 	[%r38+1248], {%rs204, %rs202, %rs206, %rs208};
	mov.b32 	{%rs209, %rs210}, %r2210;
	mov.b32 	{%rs211, %rs212}, %r2206;
	mov.b32 	{%rs213, %rs214}, %r2214;
	mov.b32 	{%rs215, %rs216}, %r2218;
	st.shared.v4.b16 	[%r38+1408], {%rs211, %rs209, %rs213, %rs215};
	st.shared.v4.b16 	[%r38+1440], {%rs212, %rs210, %rs214, %rs216};
	mov.b32 	{%rs217, %rs218}, %r2211;
	mov.b32 	{%rs219, %rs220}, %r2207;
	mov.b32 	{%rs221, %rs222}, %r2215;
	mov.b32 	{%rs223, %rs224}, %r2219;
	st.shared.v4.b16 	[%r38+1472], {%rs219, %rs217, %rs221, %rs223};
	st.shared.v4.b16 	[%r38+1504], {%rs220, %rs218, %rs222, %rs224};
	mov.b32 	{%rs225, %rs226}, %r2226;
	mov.b32 	{%rs227, %rs228}, %r2222;
	mov.b32 	{%rs229, %rs230}, %r2230;
	mov.b32 	{%rs231, %rs232}, %r2234;
	st.shared.v4.b16 	[%r38+1664], {%rs227, %rs225, %rs229, %rs231};
	st.shared.v4.b16 	[%r38+1696], {%rs228, %rs226, %rs230, %rs232};
	mov.b32 	{%rs233, %rs234}, %r2227;
	mov.b32 	{%rs235, %rs236}, %r2223;
	mov.b32 	{%rs237, %rs238}, %r2231;
	mov.b32 	{%rs239, %rs240}, %r2235;
	st.shared.v4.b16 	[%r38+1728], {%rs235, %rs233, %rs237, %rs239};
	st.shared.v4.b16 	[%r38+1760], {%rs236, %rs234, %rs238, %rs240};
	mov.b32 	{%rs241, %rs242}, %r2242;
	mov.b32 	{%rs243, %rs244}, %r2238;
	mov.b32 	{%rs245, %rs246}, %r2246;
	mov.b32 	{%rs247, %rs248}, %r2250;
	st.shared.v4.b16 	[%r38+1920], {%rs243, %rs241, %rs245, %rs247};
	st.shared.v4.b16 	[%r38+1952], {%rs244, %rs242, %rs246, %rs248};
	mov.b32 	{%rs249, %rs250}, %r2243;
	mov.b32 	{%rs251, %rs252}, %r2239;
	mov.b32 	{%rs253, %rs254}, %r2247;
	mov.b32 	{%rs255, %rs256}, %r2251;
	st.shared.v4.b16 	[%r38+1984], {%rs251, %rs249, %rs253, %rs255};
	st.shared.v4.b16 	[%r38+2016], {%rs252, %rs250, %rs254, %rs256};
	ld.shared.b16 	%rs257, [%r40];
	ld.shared.b16 	%rs258, [%r40+16];
	ld.shared.b16 	%rs259, [%r40+32];
	ld.shared.b16 	%rs260, [%r40+48];
	ld.shared.b16 	%rs261, [%r40+64];
	ld.shared.b16 	%rs262, [%r40+80];
	ld.shared.b16 	%rs263, [%r40+96];
	ld.shared.b16 	%rs264, [%r40+112];
	bar.sync 	0;
	st.shared.b16 	[%r42], %rs257;
	st.shared.b16 	[%r42+256], %rs258;
	st.shared.b16 	[%r42+512], %rs259;
	st.shared.b16 	[%r42+768], %rs260;
	st.shared.b16 	[%r42+1024], %rs261;
	st.shared.b16 	[%r42+1280], %rs262;
	st.shared.b16 	[%r42+1536], %rs263;
	st.shared.b16 	[%r42+1792], %rs264;
	or.b64 	%rd421, %rd640, %rd45;
	or.b64 	%rd422, %rd640, %rd44;
	or.b64 	%rd425, %rd640, %rd41;
	or.b64 	%rd426, %rd640, %rd40;
	add.s64 	%rd398, %rd63, %rd639;
	// begin inline asm
	@%p1 cp.async.ca.shared.global [ %r1137 + 0 ], [ %rd398 + 0 ], 0x4, 0x4;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v2.b32 	{%r2252, %r2253}, [%r45];
	ld.shared.v2.b32 	{%r2254, %r2255}, [%r45+32];
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1138, %r1139, %r1140, %r1141}, [%r1142];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1143, %r1144, %r1145, %r1146}, [%r1147];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1148, %r1149, %r1150, %r1151}, [%r1152];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1153, %r1154, %r1155, %r1156}, [%r1157];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1158, %r1159, %r1160, %r1161}, [%r1162];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1163, %r1164, %r1165, %r1166}, [%r1167];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1168, %r1169, %r1170, %r1171}, [%r1172];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1173, %r1174, %r1175, %r1176}, [%r1177];
	// end inline asm
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	shfl.sync.idx.b32 	%r2256, %r2, 0, 31, -1;
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1210,%r1211,%r1212,%r1213,%r1214,%r1215,%r1216,%r1217}, {%r1138,%r1139,%r1140,%r1141}, %rd557, 0, 1, 1, 1;
	// end inline asm
	mov.pred 	%p2, -1;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1210,%r1211,%r1212,%r1213,%r1214,%r1215,%r1216,%r1217}, {%r1143,%r1144,%r1145,%r1146}, %rd558, %p2, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1210,%r1211,%r1212,%r1213,%r1214,%r1215,%r1216,%r1217}, {%r1148,%r1149,%r1150,%r1151}, %rd559, %p2, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1210,%r1211,%r1212,%r1213,%r1214,%r1215,%r1216,%r1217}, {%r1153,%r1154,%r1155,%r1156}, %rd560, %p2, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1282,%r1283,%r1284,%r1285,%r1286,%r1287,%r1288,%r1289}, {%r1158,%r1159,%r1160,%r1161}, %rd557, 0, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1282,%r1283,%r1284,%r1285,%r1286,%r1287,%r1288,%r1289}, {%r1163,%r1164,%r1165,%r1166}, %rd558, %p2, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1282,%r1283,%r1284,%r1285,%r1286,%r1287,%r1288,%r1289}, {%r1168,%r1169,%r1170,%r1171}, %rd559, %p2, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1282,%r1283,%r1284,%r1285,%r1286,%r1287,%r1288,%r1289}, {%r1173,%r1174,%r1175,%r1176}, %rd560, %p2, 1, 1, 1;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r2056, 0;
	mov.b32 	%r1339, %r2056;
	mov.b32 	%r1340, %r2056;
	mov.b32 	%r1338, %r1357;
	// begin inline asm
	// wait for regs: %r1210,%r1211,%r1212,%r1213,%r1214,%r1215,%r1216,%r1217,%r1282,%r1283,%r1284,%r1285,%r1286,%r1287,%r1288,%r1289,%r1338,%r1339,%r1340
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	sub.f32 	%r2258, %r1210, %r2252;
	sub.f32 	%r2259, %r1211, %r2253;
	sub.f32 	%r2260, %r1212, %r2252;
	sub.f32 	%r2261, %r1213, %r2253;
	sub.f32 	%r2262, %r1214, %r2254;
	sub.f32 	%r2263, %r1215, %r2255;
	sub.f32 	%r2264, %r1216, %r2254;
	sub.f32 	%r2265, %r1217, %r2255;
	sub.f32 	%r2266, %r1282, %r2252;
	sub.f32 	%r2267, %r1283, %r2253;
	sub.f32 	%r2268, %r1284, %r2252;
	sub.f32 	%r2269, %r1285, %r2253;
	sub.f32 	%r2270, %r1286, %r2254;
	sub.f32 	%r2271, %r1287, %r2255;
	sub.f32 	%r2272, %r1288, %r2254;
	sub.f32 	%r2273, %r1289, %r2255;
	ex2.approx.ftz.f32 	%r2274, %r2258;
	ex2.approx.ftz.f32 	%r2275, %r2259;
	ex2.approx.ftz.f32 	%r2276, %r2260;
	ex2.approx.ftz.f32 	%r2277, %r2261;
	ex2.approx.ftz.f32 	%r2278, %r2262;
	ex2.approx.ftz.f32 	%r2279, %r2263;
	ex2.approx.ftz.f32 	%r2280, %r2264;
	ex2.approx.ftz.f32 	%r2281, %r2265;
	ex2.approx.ftz.f32 	%r2282, %r2266;
	ex2.approx.ftz.f32 	%r2283, %r2267;
	ex2.approx.ftz.f32 	%r2284, %r2268;
	ex2.approx.ftz.f32 	%r2285, %r2269;
	ex2.approx.ftz.f32 	%r2286, %r2270;
	ex2.approx.ftz.f32 	%r2287, %r2271;
	ex2.approx.ftz.f32 	%r2288, %r2272;
	ex2.approx.ftz.f32 	%r2289, %r2273;
	setp.lt.s64 	%p19, %rd426, %rd47;
	setp.lt.s64 	%p20, %rd425, %rd47;
	setp.lt.s64 	%p21, %rd426, %rd49;
	setp.lt.s64 	%p22, %rd425, %rd49;
	setp.lt.s64 	%p23, %rd422, %rd47;
	setp.lt.s64 	%p24, %rd421, %rd47;
	setp.lt.s64 	%p25, %rd422, %rd49;
	setp.lt.s64 	%p26, %rd421, %rd49;
	setp.lt.s64 	%p27, %rd426, %rd55;
	setp.lt.s64 	%p28, %rd425, %rd55;
	setp.lt.s64 	%p29, %rd426, %rd57;
	setp.lt.s64 	%p30, %rd425, %rd57;
	setp.lt.s64 	%p31, %rd422, %rd55;
	setp.lt.s64 	%p32, %rd421, %rd55;
	setp.lt.s64 	%p33, %rd422, %rd57;
	setp.lt.s64 	%p34, %rd421, %rd57;
	selp.f32 	%r2290, 0f00000000, %r2274, %p34;
	selp.f32 	%r2291, 0f00000000, %r2275, %p33;
	selp.f32 	%r2292, 0f00000000, %r2276, %p32;
	selp.f32 	%r2293, 0f00000000, %r2277, %p31;
	selp.f32 	%r2294, 0f00000000, %r2278, %p30;
	selp.f32 	%r2295, 0f00000000, %r2279, %p29;
	selp.f32 	%r2296, 0f00000000, %r2280, %p28;
	selp.f32 	%r2297, 0f00000000, %r2281, %p27;
	selp.f32 	%r2298, 0f00000000, %r2282, %p26;
	selp.f32 	%r2299, 0f00000000, %r2283, %p25;
	selp.f32 	%r2300, 0f00000000, %r2284, %p24;
	selp.f32 	%r2301, 0f00000000, %r2285, %p23;
	selp.f32 	%r2302, 0f00000000, %r2286, %p22;
	selp.f32 	%r2303, 0f00000000, %r2287, %p21;
	selp.f32 	%r2304, 0f00000000, %r2288, %p20;
	selp.f32 	%r2305, 0f00000000, %r2289, %p19;
	bar.sync 	0;
	// begin inline asm
	cp.async.cg.shared.global [ %r1360 + 0 ], [ %rd407 + 0 ], 0x10, 0x10;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v2.b32 	{%r2306, %r2307}, [%r58];
	ld.shared.v2.b32 	{%r2308, %r2309}, [%r58+128];
	ld.shared.v2.b32 	{%r2310, %r2311}, [%r58+256];
	ld.shared.v2.b32 	{%r2312, %r2313}, [%r58+384];
	ld.shared.v2.b32 	{%r2314, %r2315}, [%r58+512];
	ld.shared.v2.b32 	{%r2316, %r2317}, [%r58+640];
	ld.shared.v2.b32 	{%r2318, %r2319}, [%r58+768];
	ld.shared.v2.b32 	{%r2320, %r2321}, [%r58+896];
	ld.shared.v2.b32 	{%r2322, %r2323}, [%r58+1024];
	ld.shared.v2.b32 	{%r2324, %r2325}, [%r58+1152];
	ld.shared.v2.b32 	{%r2326, %r2327}, [%r58+1280];
	ld.shared.v2.b32 	{%r2328, %r2329}, [%r58+1408];
	ld.shared.v2.b32 	{%r2330, %r2331}, [%r58+1536];
	ld.shared.v2.b32 	{%r2332, %r2333}, [%r58+1664];
	ld.shared.v2.b32 	{%r2334, %r2335}, [%r58+1792];
	ld.shared.v2.b32 	{%r2336, %r2337}, [%r58+1920];
	st.shared.v2.b32 	[%r59], {%r2306, %r2307};
	st.shared.v2.b32 	[%r59+1024], {%r2322, %r2323};
	st.shared.v2.b32 	[%r61+128], {%r2308, %r2309};
	st.shared.v2.b32 	[%r61+1152], {%r2324, %r2325};
	st.shared.v2.b32 	[%r63+256], {%r2310, %r2311};
	st.shared.v2.b32 	[%r63+1280], {%r2326, %r2327};
	st.shared.v2.b32 	[%r65+384], {%r2312, %r2313};
	st.shared.v2.b32 	[%r65+1408], {%r2328, %r2329};
	st.shared.v2.b32 	[%r67+512], {%r2314, %r2315};
	st.shared.v2.b32 	[%r67+1536], {%r2330, %r2331};
	st.shared.v2.b32 	[%r69+640], {%r2316, %r2317};
	st.shared.v2.b32 	[%r69+1664], {%r2332, %r2333};
	st.shared.v2.b32 	[%r71+768], {%r2318, %r2319};
	st.shared.v2.b32 	[%r71+1792], {%r2334, %r2335};
	st.shared.v2.b32 	[%r73+896], {%r2320, %r2321};
	st.shared.v2.b32 	[%r73+1920], {%r2336, %r2337};
	ld.shared.b16 	%rs265, [%r75];
	ld.shared.b16 	%rs266, [%r75+256];
	ld.shared.b16 	%rs267, [%r75+512];
	ld.shared.b16 	%rs268, [%r75+768];
	ld.shared.b16 	%rs269, [%r75+1024];
	ld.shared.b16 	%rs270, [%r75+1280];
	ld.shared.b16 	%rs271, [%r75+1536];
	ld.shared.b16 	%rs272, [%r75+1792];
	bar.sync 	0;
	st.shared.b16 	[%r76], %rs265;
	st.shared.b16 	[%r76+1024], %rs269;
	st.shared.b16 	[%r78+256], %rs266;
	st.shared.b16 	[%r78+1280], %rs270;
	st.shared.b16 	[%r80+512], %rs267;
	st.shared.b16 	[%r80+1536], %rs271;
	st.shared.b16 	[%r82+768], %rs268;
	st.shared.b16 	[%r82+1792], %rs272;
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	cvt.rn.f16x2.f32 	%r1425, %r2291, %r2290;
	cvt.rn.f16x2.f32 	%r1426, %r2293, %r2292;
	cvt.rn.f16x2.f32 	%r1427, %r2295, %r2294;
	cvt.rn.f16x2.f32 	%r1428, %r2297, %r2296;
	cvt.rn.f16x2.f32 	%r1493, %r2299, %r2298;
	cvt.rn.f16x2.f32 	%r1494, %r2301, %r2300;
	cvt.rn.f16x2.f32 	%r1495, %r2303, %r2302;
	cvt.rn.f16x2.f32 	%r1496, %r2305, %r2304;
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7697,%r7698,%r7699,%r7700,%r7701,%r7702,%r7703,%r7704,%r7705,%r7706,%r7707,%r7708,%r7709,%r7710,%r7711,%r7712,%r7713,%r7714,%r7715,%r7716,%r7717,%r7718,%r7719,%r7720,%r7721,%r7722,%r7723,%r7724,%r7725,%r7726,%r7727,%r7728}, {%r1425,%r1426,%r1427,%r1428}, %rd408, %p2, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7729,%r7730,%r7731,%r7732,%r7733,%r7734,%r7735,%r7736,%r7737,%r7738,%r7739,%r7740,%r7741,%r7742,%r7743,%r7744,%r7745,%r7746,%r7747,%r7748,%r7749,%r7750,%r7751,%r7752,%r7753,%r7754,%r7755,%r7756,%r7757,%r7758,%r7759,%r7760}, {%r1493,%r1494,%r1495,%r1496}, %rd408, %p2, 1, 1, 1;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r1562, %r2056;
	mov.b32 	%r1563, %r2056;
	mov.b32 	%r1561, %r2788;
	// begin inline asm
	// wait for regs: %r7697,%r7698,%r7699,%r7700,%r7701,%r7702,%r7703,%r7704,%r7705,%r7706,%r7707,%r7708,%r7709,%r7710,%r7711,%r7712,%r7713,%r7714,%r7715,%r7716,%r7717,%r7718,%r7719,%r7720,%r7721,%r7722,%r7723,%r7724,%r7725,%r7726,%r7727,%r7728,%r7729,%r7730,%r7731,%r7732,%r7733,%r7734,%r7735,%r7736,%r7737,%r7738,%r7739,%r7740,%r7741,%r7742,%r7743,%r7744,%r7745,%r7746,%r7747,%r7748,%r7749,%r7750,%r7751,%r7752,%r7753,%r7754,%r7755,%r7756,%r7757,%r7758,%r7759,%r7760,%r1561,%r1562,%r1563
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	add.s64 	%rd410, %rd62, %rd639;
	bar.sync 	0;
	// begin inline asm
	@%p1 cp.async.ca.shared.global [ %r1137 + 0 ], [ %rd410 + 0 ], 0x4, 0x4;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v2.b32 	{%r2338, %r2339}, [%r45];
	ld.shared.v2.b32 	{%r2340, %r2341}, [%r45+32];
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1632, %r1633, %r1634, %r1635}, [%r1636];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1637, %r1638, %r1639, %r1640}, [%r1641];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1642, %r1643, %r1644, %r1645}, [%r1646];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1647, %r1648, %r1649, %r1650}, [%r1651];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1652, %r1653, %r1654, %r1655}, [%r1656];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1657, %r1658, %r1659, %r1660}, [%r1661];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1662, %r1663, %r1664, %r1665}, [%r1666];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r1667, %r1668, %r1669, %r1670}, [%r1671];
	// end inline asm
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1704,%r1705,%r1706,%r1707,%r1708,%r1709,%r1710,%r1711}, {%r1632,%r1633,%r1634,%r1635}, %rd411, 0, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1704,%r1705,%r1706,%r1707,%r1708,%r1709,%r1710,%r1711}, {%r1637,%r1638,%r1639,%r1640}, %rd412, %p2, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1704,%r1705,%r1706,%r1707,%r1708,%r1709,%r1710,%r1711}, {%r1642,%r1643,%r1644,%r1645}, %rd413, %p2, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1704,%r1705,%r1706,%r1707,%r1708,%r1709,%r1710,%r1711}, {%r1647,%r1648,%r1649,%r1650}, %rd414, %p2, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1776,%r1777,%r1778,%r1779,%r1780,%r1781,%r1782,%r1783}, {%r1652,%r1653,%r1654,%r1655}, %rd411, 0, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1776,%r1777,%r1778,%r1779,%r1780,%r1781,%r1782,%r1783}, {%r1657,%r1658,%r1659,%r1660}, %rd412, %p2, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1776,%r1777,%r1778,%r1779,%r1780,%r1781,%r1782,%r1783}, {%r1662,%r1663,%r1664,%r1665}, %rd413, %p2, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r1776,%r1777,%r1778,%r1779,%r1780,%r1781,%r1782,%r1783}, {%r1667,%r1668,%r1669,%r1670}, %rd414, %p2, 1, 1, 0;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r1832, %r1357;
	mov.b32 	%r1833, %r2056;
	mov.b32 	%r1834, %r2056;
	// begin inline asm
	// wait for regs: %r1704,%r1705,%r1706,%r1707,%r1708,%r1709,%r1710,%r1711,%r1776,%r1777,%r1778,%r1779,%r1780,%r1781,%r1782,%r1783,%r1832,%r1833,%r1834
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	sub.f32 	%r2342, %r1704, %r2338;
	sub.f32 	%r2343, %r1705, %r2339;
	sub.f32 	%r2344, %r1706, %r2338;
	sub.f32 	%r2345, %r1707, %r2339;
	sub.f32 	%r2346, %r1708, %r2340;
	sub.f32 	%r2347, %r1709, %r2341;
	sub.f32 	%r2348, %r1710, %r2340;
	sub.f32 	%r2349, %r1711, %r2341;
	sub.f32 	%r2350, %r1776, %r2338;
	sub.f32 	%r2351, %r1777, %r2339;
	sub.f32 	%r2352, %r1778, %r2338;
	sub.f32 	%r2353, %r1779, %r2339;
	sub.f32 	%r2354, %r1780, %r2340;
	sub.f32 	%r2355, %r1781, %r2341;
	sub.f32 	%r2356, %r1782, %r2340;
	sub.f32 	%r2357, %r1783, %r2341;
	mul.f32 	%r2358, %r2290, %r2342;
	mul.f32 	%r2359, %r2291, %r2343;
	mul.f32 	%r2360, %r2292, %r2344;
	mul.f32 	%r2361, %r2293, %r2345;
	mul.f32 	%r2362, %r2294, %r2346;
	mul.f32 	%r2363, %r2295, %r2347;
	mul.f32 	%r2364, %r2296, %r2348;
	mul.f32 	%r2365, %r2297, %r2349;
	mul.f32 	%r2366, %r2298, %r2350;
	mul.f32 	%r2367, %r2299, %r2351;
	mul.f32 	%r2368, %r2300, %r2352;
	mul.f32 	%r2369, %r2301, %r2353;
	mul.f32 	%r2370, %r2302, %r2354;
	mul.f32 	%r2371, %r2303, %r2355;
	mul.f32 	%r2372, %r2304, %r2356;
	mul.f32 	%r2373, %r2305, %r2357;
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	cvt.rn.f16x2.f32 	%r1918, %r2359, %r2358;
	cvt.rn.f16x2.f32 	%r1919, %r2361, %r2360;
	cvt.rn.f16x2.f32 	%r1920, %r2363, %r2362;
	cvt.rn.f16x2.f32 	%r1921, %r2365, %r2364;
	cvt.rn.f16x2.f32 	%r1986, %r2367, %r2366;
	cvt.rn.f16x2.f32 	%r1987, %r2369, %r2368;
	cvt.rn.f16x2.f32 	%r1988, %r2371, %r2370;
	cvt.rn.f16x2.f32 	%r1989, %r2373, %r2372;
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7631,%r7632,%r7633,%r7634,%r7635,%r7636,%r7637,%r7638,%r7639,%r7640,%r7641,%r7642,%r7643,%r7644,%r7645,%r7646,%r7647,%r7648,%r7649,%r7650,%r7651,%r7652,%r7653,%r7654,%r7655,%r7656,%r7657,%r7658,%r7659,%r7660,%r7661,%r7662}, {%r1918,%r1919,%r1920,%r1921}, %rd573, %p2, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7663,%r7664,%r7665,%r7666,%r7667,%r7668,%r7669,%r7670,%r7671,%r7672,%r7673,%r7674,%r7675,%r7676,%r7677,%r7678,%r7679,%r7680,%r7681,%r7682,%r7683,%r7684,%r7685,%r7686,%r7687,%r7688,%r7689,%r7690,%r7691,%r7692,%r7693,%r7694}, {%r1986,%r1987,%r1988,%r1989}, %rd573, %p2, 1, 1, 0;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r2054, %r1109;
	mov.b32 	%r2055, %r2056;
	// begin inline asm
	// wait for regs: %r7631,%r7632,%r7633,%r7634,%r7635,%r7636,%r7637,%r7638,%r7639,%r7640,%r7641,%r7642,%r7643,%r7644,%r7645,%r7646,%r7647,%r7648,%r7649,%r7650,%r7651,%r7652,%r7653,%r7654,%r7655,%r7656,%r7657,%r7658,%r7659,%r7660,%r7661,%r7662,%r7663,%r7664,%r7665,%r7666,%r7667,%r7668,%r7669,%r7670,%r7671,%r7672,%r7673,%r7674,%r7675,%r7676,%r7677,%r7678,%r7679,%r7680,%r7681,%r7682,%r7683,%r7684,%r7685,%r7686,%r7687,%r7688,%r7689,%r7690,%r7691,%r7692,%r7693,%r7694,%r2054,%r2055,%r2056
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	add.s64 	%rd640, %rd640, 16;
	add.s64 	%rd639, %rd639, 64;
	add.s64 	%rd638, %rd638, %rd67;
	cvt.u32.u64 	%r2374, %rd639;
	setp.ne.b32 	%p35, %r2374, 512;
	@%p35 bra 	$L__BB0_1;
// %bb.2:
	cvt.u32.u64 	%r2375, %rd29;
	shl.b64 	%rd437, %rd1, 1;
	add.s64 	%rd74, %rd334, %rd437;
	add.s64 	%rd75, %rd335, %rd437;
	or.b32 	%r348, %r2375, %r6;
	sub.s32 	%r2376, %r1055, %r2375;
	add.s32 	%r2377, %r2376, -128;
	and.b32 	%r350, %r1, 31;
	setp.gt.s32 	%p36, %r2377, 31;
	cvt.u32.u64 	%r7562, %rd14;
	add.s32 	%r5795, %r5794, 2048;
	shl.b32 	%r7564, %r8, 9;
	shl.b32 	%r7565, %r350, 7;
	shr.u32 	%r7566, %r4, 4;
	or.b64 	%rd588, %rd21, -9223371899399045120;
	or.b64 	%rd604, %rd27, -9223371899399045120;
	mul.wide.s32 	%rd637, %r7, 2;
	@%p36 bra 	$L__BB0_4;
	bra.uni 	$L__BB0_3;
$L__BB0_4:                              // %.lr.ph
	shr.s32 	%r2378, %r2377, 31;
	shr.u32 	%r2379, %r2378, 27;
	add.s32 	%r2380, %r2377, %r2379;
	shr.s32 	%r7695, %r2380, 5;
	add.s32 	%r360, %r1109, %r7564;
	add.s32 	%r361, %r2788, %r7562;
	xor.b32 	%r2391, %r7562, 16;
	add.s32 	%r362, %r2788, %r2391;
	xor.b32 	%r2392, %r7562, 32;
	add.s32 	%r363, %r2788, %r2392;
	xor.b32 	%r2393, %r7562, 48;
	add.s32 	%r364, %r2788, %r2393;
	add.s32 	%r2396, %r1109, %r7565;
	add.s32 	%r365, %r2396, %r7566;
	add.s32 	%r366, %r1109, %r77;
	shl.b32 	%r2397, %r350, 2;
	add.s32 	%r2398, %r1103, 40960;
	add.s32 	%r2424, %r2398, %r2397;
	add.s32 	%r368, %r2398, %r35;
	or.b32 	%r2399, %r39, %r46;
	or.b32 	%r7832, %r2399, %r47;
	add.s32 	%r2429, %r1103, %r7832;
	or.b32 	%r7831, %r7832, 32;
	add.s32 	%r2434, %r2429, 32;
	or.b32 	%r7830, %r7832, 64;
	add.s32 	%r2439, %r2429, 64;
	or.b32 	%r7829, %r7832, 96;
	add.s32 	%r2444, %r2429, 96;
	or.b32 	%r7828, %r7832, 8192;
	add.s32 	%r2449, %r2429, 8192;
	or.b32 	%r7827, %r7832, 8224;
	add.s32 	%r2454, %r2429, 8224;
	or.b32 	%r7826, %r7832, 8256;
	add.s32 	%r2459, %r2429, 8256;
	or.b32 	%r7825, %r7832, 8288;
	add.s32 	%r2464, %r2429, 8288;
	add.s32 	%r2400, %r1103, 37888;
	bfe.u32 	%r2401, %r2400, 4, 14;
	cvt.u64.u32 	%rd645, %r2401;
	or.b64 	%rd452, %rd645, -9223371899399045120;
	add.s32 	%r2402, %r1103, 38912;
	bfe.u32 	%r2403, %r2402, 4, 14;
	cvt.u64.u32 	%rd438, %r2403;
	or.b64 	%rd453, %rd438, -9223371899399045120;
	add.s32 	%r2404, %r1103, 39936;
	bfe.u32 	%r2405, %r2404, 4, 14;
	cvt.u64.u32 	%rd439, %r2405;
	or.b64 	%rd454, %rd439, -9223371899399045120;
	add.s32 	%r2791, %r2788, %r9;
	add.s32 	%r2792, %r2791, 2048;
	add.s32 	%r387, %r2788, %r57;
	add.s32 	%r388, %r2398, %r57;
	add.s32 	%r389, %r2398, %r60;
	add.s32 	%r390, %r2398, %r62;
	add.s32 	%r391, %r2398, %r64;
	add.s32 	%r392, %r2398, %r66;
	add.s32 	%r393, %r2398, %r68;
	add.s32 	%r394, %r2398, %r70;
	add.s32 	%r395, %r2398, %r72;
	add.s32 	%r396, %r2788, %r74;
	add.s32 	%r397, %r2788, %r41;
	add.s32 	%r398, %r2788, %r77;
	add.s32 	%r399, %r2788, %r79;
	add.s32 	%r400, %r2788, %r81;
	bfe.u32 	%r2406, %r2398, 4, 14;
	cvt.u64.u32 	%rd440, %r2406;
	or.b64 	%rd461, %rd440, 4611686293322072064;
	add.s32 	%r2407, %r1103, 43008;
	bfe.u32 	%r2408, %r2407, 4, 14;
	cvt.u64.u32 	%rd441, %r2408;
	or.b64 	%rd462, %rd441, 4611686293322072064;
	add.s32 	%r3204, %r2429, 16384;
	add.s32 	%r3209, %r2429, 16416;
	add.s32 	%r3214, %r2429, 16448;
	add.s32 	%r3219, %r2429, 16480;
	add.s32 	%r3224, %r2429, 24576;
	add.s32 	%r3229, %r2429, 24608;
	add.s32 	%r3234, %r2429, 24640;
	add.s32 	%r3239, %r2429, 24672;
	or.b64 	%rd466, %rd21, 4611686293322072064;
	add.s32 	%r2409, %r1103, 36896;
	bfe.u32 	%r2410, %r2409, 4, 14;
	cvt.u64.u32 	%rd442, %r2410;
	or.b64 	%rd467, %rd442, 4611686293322072064;
	add.s32 	%r2411, %r1103, 36928;
	bfe.u32 	%r2412, %r2411, 4, 14;
	cvt.u64.u32 	%rd443, %r2412;
	or.b64 	%rd468, %rd443, 4611686293322072064;
	add.s32 	%r2413, %r1103, 36960;
	bfe.u32 	%r2414, %r2413, 4, 14;
	cvt.u64.u32 	%rd444, %r2414;
	or.b64 	%rd469, %rd444, 4611686293322072064;
	add.s32 	%r2415, %r1103, 32800;
	bfe.u32 	%r2416, %r2415, 4, 14;
	cvt.u64.u32 	%rd445, %r2416;
	or.b64 	%rd475, %rd445, -9223371899399045120;
	add.s32 	%r2417, %r91, 144;
	mul.lo.s32 	%r2418, %r1054, %r2417;
	mad.wide.s32 	%rd446, %r2418, 2, %rd64;
	add.s64 	%rd644, %rd332, %rd446;
	add.s32 	%r2419, %r91, 128;
	mul.lo.s32 	%r2420, %r1054, %r2419;
	mad.wide.s32 	%rd447, %r2420, 2, %rd64;
	add.s64 	%rd643, %rd332, %rd447;
	add.s64 	%rd642, %rd329, %rd446;
	add.s64 	%rd641, %rd329, %rd447;
	add.s32 	%r2421, %r2375, %r350;
	add.s32 	%r7696, %r2421, 128;
	setp.eq.b32 	%p37, %r4, 0;
$L__BB0_5:                              // %__nv_exp2f.exit392
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd460, %rd644, %rd65;
	add.s64 	%rd459, %rd643, %rd65;
	add.s64 	%rd449, %rd642, %rd65;
	add.s64 	%rd448, %rd641, %rd65;
	bar.sync 	0;
	// begin inline asm
	cp.async.cg.shared.global [ %r5794 + 0 ], [ %rd448 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r5795 + 0 ], [ %rd449 + 0 ], 0x10, 0x10;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r3972, %r3973, %r3974, %r3975}, [%r360];
	ld.shared.v4.b32 	{%r3976, %r3977, %r3978, %r3979}, [%r360+128];
	ld.shared.v4.b32 	{%r3980, %r3981, %r3982, %r3983}, [%r360+256];
	ld.shared.v4.b32 	{%r3984, %r3985, %r3986, %r3987}, [%r360+384];
	ld.shared.v4.b32 	{%r3988, %r3989, %r3990, %r3991}, [%r360+16];
	ld.shared.v4.b32 	{%r3992, %r3993, %r3994, %r3995}, [%r360+144];
	ld.shared.v4.b32 	{%r3996, %r3997, %r3998, %r3999}, [%r360+272];
	ld.shared.v4.b32 	{%r4000, %r4001, %r4002, %r4003}, [%r360+400];
	ld.shared.v4.b32 	{%r4004, %r4005, %r4006, %r4007}, [%r360+32];
	ld.shared.v4.b32 	{%r4008, %r4009, %r4010, %r4011}, [%r360+160];
	ld.shared.v4.b32 	{%r4012, %r4013, %r4014, %r4015}, [%r360+288];
	ld.shared.v4.b32 	{%r4016, %r4017, %r4018, %r4019}, [%r360+416];
	ld.shared.v4.b32 	{%r4020, %r4021, %r4022, %r4023}, [%r360+48];
	ld.shared.v4.b32 	{%r4024, %r4025, %r4026, %r4027}, [%r360+176];
	ld.shared.v4.b32 	{%r4028, %r4029, %r4030, %r4031}, [%r360+304];
	ld.shared.v4.b32 	{%r4032, %r4033, %r4034, %r4035}, [%r360+432];
	ld.shared.v4.b32 	{%r4036, %r4037, %r4038, %r4039}, [%r360+64];
	ld.shared.v4.b32 	{%r4040, %r4041, %r4042, %r4043}, [%r360+192];
	ld.shared.v4.b32 	{%r4044, %r4045, %r4046, %r4047}, [%r360+320];
	ld.shared.v4.b32 	{%r4048, %r4049, %r4050, %r4051}, [%r360+448];
	ld.shared.v4.b32 	{%r4052, %r4053, %r4054, %r4055}, [%r360+80];
	ld.shared.v4.b32 	{%r4056, %r4057, %r4058, %r4059}, [%r360+208];
	ld.shared.v4.b32 	{%r4060, %r4061, %r4062, %r4063}, [%r360+336];
	ld.shared.v4.b32 	{%r4064, %r4065, %r4066, %r4067}, [%r360+464];
	ld.shared.v4.b32 	{%r4068, %r4069, %r4070, %r4071}, [%r360+96];
	ld.shared.v4.b32 	{%r4072, %r4073, %r4074, %r4075}, [%r360+224];
	ld.shared.v4.b32 	{%r4076, %r4077, %r4078, %r4079}, [%r360+352];
	ld.shared.v4.b32 	{%r4080, %r4081, %r4082, %r4083}, [%r360+480];
	ld.shared.v4.b32 	{%r4084, %r4085, %r4086, %r4087}, [%r360+112];
	ld.shared.v4.b32 	{%r4088, %r4089, %r4090, %r4091}, [%r360+240];
	ld.shared.v4.b32 	{%r4092, %r4093, %r4094, %r4095}, [%r360+368];
	ld.shared.v4.b32 	{%r4096, %r4097, %r4098, %r4099}, [%r360+496];
	mov.b32 	{%rs273, %rs274}, %r3976;
	mov.b32 	{%rs275, %rs276}, %r3972;
	mov.b32 	{%rs277, %rs278}, %r3980;
	mov.b32 	{%rs279, %rs280}, %r3984;
	st.shared.v4.b16 	[%r361], {%rs275, %rs273, %rs277, %rs279};
	st.shared.v4.b16 	[%r361+64], {%rs276, %rs274, %rs278, %rs280};
	mov.b32 	{%rs281, %rs282}, %r3992;
	mov.b32 	{%rs283, %rs284}, %r3988;
	mov.b32 	{%rs285, %rs286}, %r3996;
	mov.b32 	{%rs287, %rs288}, %r4000;
	st.shared.v4.b16 	[%r361+512], {%rs283, %rs281, %rs285, %rs287};
	st.shared.v4.b16 	[%r361+576], {%rs284, %rs282, %rs286, %rs288};
	mov.b32 	{%rs289, %rs290}, %r4008;
	mov.b32 	{%rs291, %rs292}, %r4004;
	mov.b32 	{%rs293, %rs294}, %r4012;
	mov.b32 	{%rs295, %rs296}, %r4016;
	st.shared.v4.b16 	[%r361+1024], {%rs291, %rs289, %rs293, %rs295};
	st.shared.v4.b16 	[%r361+1088], {%rs292, %rs290, %rs294, %rs296};
	mov.b32 	{%rs297, %rs298}, %r4024;
	mov.b32 	{%rs299, %rs300}, %r4020;
	mov.b32 	{%rs301, %rs302}, %r4028;
	mov.b32 	{%rs303, %rs304}, %r4032;
	st.shared.v4.b16 	[%r361+1536], {%rs299, %rs297, %rs301, %rs303};
	st.shared.v4.b16 	[%r361+1600], {%rs300, %rs298, %rs302, %rs304};
	mov.b32 	{%rs305, %rs306}, %r4040;
	mov.b32 	{%rs307, %rs308}, %r4036;
	mov.b32 	{%rs309, %rs310}, %r4044;
	mov.b32 	{%rs311, %rs312}, %r4048;
	st.shared.v4.b16 	[%r361+2048], {%rs307, %rs305, %rs309, %rs311};
	st.shared.v4.b16 	[%r361+2112], {%rs308, %rs306, %rs310, %rs312};
	mov.b32 	{%rs313, %rs314}, %r4056;
	mov.b32 	{%rs315, %rs316}, %r4052;
	mov.b32 	{%rs317, %rs318}, %r4060;
	mov.b32 	{%rs319, %rs320}, %r4064;
	st.shared.v4.b16 	[%r361+2560], {%rs315, %rs313, %rs317, %rs319};
	st.shared.v4.b16 	[%r361+2624], {%rs316, %rs314, %rs318, %rs320};
	mov.b32 	{%rs321, %rs322}, %r4072;
	mov.b32 	{%rs323, %rs324}, %r4068;
	mov.b32 	{%rs325, %rs326}, %r4076;
	mov.b32 	{%rs327, %rs328}, %r4080;
	st.shared.v4.b16 	[%r361+3072], {%rs323, %rs321, %rs325, %rs327};
	st.shared.v4.b16 	[%r361+3136], {%rs324, %rs322, %rs326, %rs328};
	mov.b32 	{%rs329, %rs330}, %r4088;
	mov.b32 	{%rs331, %rs332}, %r4084;
	mov.b32 	{%rs333, %rs334}, %r4092;
	mov.b32 	{%rs335, %rs336}, %r4096;
	st.shared.v4.b16 	[%r361+3584], {%rs331, %rs329, %rs333, %rs335};
	st.shared.v4.b16 	[%r361+3648], {%rs332, %rs330, %rs334, %rs336};
	mov.b32 	{%rs337, %rs338}, %r3977;
	mov.b32 	{%rs339, %rs340}, %r3973;
	mov.b32 	{%rs341, %rs342}, %r3981;
	mov.b32 	{%rs343, %rs344}, %r3985;
	st.shared.v4.b16 	[%r362+128], {%rs339, %rs337, %rs341, %rs343};
	st.shared.v4.b16 	[%r362+192], {%rs340, %rs338, %rs342, %rs344};
	mov.b32 	{%rs345, %rs346}, %r3993;
	mov.b32 	{%rs347, %rs348}, %r3989;
	mov.b32 	{%rs349, %rs350}, %r3997;
	mov.b32 	{%rs351, %rs352}, %r4001;
	st.shared.v4.b16 	[%r362+640], {%rs347, %rs345, %rs349, %rs351};
	st.shared.v4.b16 	[%r362+704], {%rs348, %rs346, %rs350, %rs352};
	mov.b32 	{%rs353, %rs354}, %r4009;
	mov.b32 	{%rs355, %rs356}, %r4005;
	mov.b32 	{%rs357, %rs358}, %r4013;
	mov.b32 	{%rs359, %rs360}, %r4017;
	st.shared.v4.b16 	[%r362+1152], {%rs355, %rs353, %rs357, %rs359};
	st.shared.v4.b16 	[%r362+1216], {%rs356, %rs354, %rs358, %rs360};
	mov.b32 	{%rs361, %rs362}, %r4025;
	mov.b32 	{%rs363, %rs364}, %r4021;
	mov.b32 	{%rs365, %rs366}, %r4029;
	mov.b32 	{%rs367, %rs368}, %r4033;
	st.shared.v4.b16 	[%r362+1664], {%rs363, %rs361, %rs365, %rs367};
	st.shared.v4.b16 	[%r362+1728], {%rs364, %rs362, %rs366, %rs368};
	mov.b32 	{%rs369, %rs370}, %r4041;
	mov.b32 	{%rs371, %rs372}, %r4037;
	mov.b32 	{%rs373, %rs374}, %r4045;
	mov.b32 	{%rs375, %rs376}, %r4049;
	st.shared.v4.b16 	[%r362+2176], {%rs371, %rs369, %rs373, %rs375};
	st.shared.v4.b16 	[%r362+2240], {%rs372, %rs370, %rs374, %rs376};
	mov.b32 	{%rs377, %rs378}, %r4057;
	mov.b32 	{%rs379, %rs380}, %r4053;
	mov.b32 	{%rs381, %rs382}, %r4061;
	mov.b32 	{%rs383, %rs384}, %r4065;
	st.shared.v4.b16 	[%r362+2688], {%rs379, %rs377, %rs381, %rs383};
	st.shared.v4.b16 	[%r362+2752], {%rs380, %rs378, %rs382, %rs384};
	mov.b32 	{%rs385, %rs386}, %r4073;
	mov.b32 	{%rs387, %rs388}, %r4069;
	mov.b32 	{%rs389, %rs390}, %r4077;
	mov.b32 	{%rs391, %rs392}, %r4081;
	st.shared.v4.b16 	[%r362+3200], {%rs387, %rs385, %rs389, %rs391};
	st.shared.v4.b16 	[%r362+3264], {%rs388, %rs386, %rs390, %rs392};
	mov.b32 	{%rs393, %rs394}, %r4089;
	mov.b32 	{%rs395, %rs396}, %r4085;
	mov.b32 	{%rs397, %rs398}, %r4093;
	mov.b32 	{%rs399, %rs400}, %r4097;
	st.shared.v4.b16 	[%r362+3712], {%rs395, %rs393, %rs397, %rs399};
	st.shared.v4.b16 	[%r362+3776], {%rs396, %rs394, %rs398, %rs400};
	mov.b32 	{%rs401, %rs402}, %r3978;
	mov.b32 	{%rs403, %rs404}, %r3974;
	mov.b32 	{%rs405, %rs406}, %r3982;
	mov.b32 	{%rs407, %rs408}, %r3986;
	st.shared.v4.b16 	[%r363+256], {%rs403, %rs401, %rs405, %rs407};
	st.shared.v4.b16 	[%r363+320], {%rs404, %rs402, %rs406, %rs408};
	mov.b32 	{%rs409, %rs410}, %r3994;
	mov.b32 	{%rs411, %rs412}, %r3990;
	mov.b32 	{%rs413, %rs414}, %r3998;
	mov.b32 	{%rs415, %rs416}, %r4002;
	st.shared.v4.b16 	[%r363+768], {%rs411, %rs409, %rs413, %rs415};
	st.shared.v4.b16 	[%r363+832], {%rs412, %rs410, %rs414, %rs416};
	mov.b32 	{%rs417, %rs418}, %r4010;
	mov.b32 	{%rs419, %rs420}, %r4006;
	mov.b32 	{%rs421, %rs422}, %r4014;
	mov.b32 	{%rs423, %rs424}, %r4018;
	st.shared.v4.b16 	[%r363+1280], {%rs419, %rs417, %rs421, %rs423};
	st.shared.v4.b16 	[%r363+1344], {%rs420, %rs418, %rs422, %rs424};
	mov.b32 	{%rs425, %rs426}, %r4026;
	mov.b32 	{%rs427, %rs428}, %r4022;
	mov.b32 	{%rs429, %rs430}, %r4030;
	mov.b32 	{%rs431, %rs432}, %r4034;
	st.shared.v4.b16 	[%r363+1792], {%rs427, %rs425, %rs429, %rs431};
	st.shared.v4.b16 	[%r363+1856], {%rs428, %rs426, %rs430, %rs432};
	mov.b32 	{%rs433, %rs434}, %r4042;
	mov.b32 	{%rs435, %rs436}, %r4038;
	mov.b32 	{%rs437, %rs438}, %r4046;
	mov.b32 	{%rs439, %rs440}, %r4050;
	st.shared.v4.b16 	[%r363+2304], {%rs435, %rs433, %rs437, %rs439};
	st.shared.v4.b16 	[%r363+2368], {%rs436, %rs434, %rs438, %rs440};
	mov.b32 	{%rs441, %rs442}, %r4058;
	mov.b32 	{%rs443, %rs444}, %r4054;
	mov.b32 	{%rs445, %rs446}, %r4062;
	mov.b32 	{%rs447, %rs448}, %r4066;
	st.shared.v4.b16 	[%r363+2816], {%rs443, %rs441, %rs445, %rs447};
	st.shared.v4.b16 	[%r363+2880], {%rs444, %rs442, %rs446, %rs448};
	mov.b32 	{%rs449, %rs450}, %r4074;
	mov.b32 	{%rs451, %rs452}, %r4070;
	mov.b32 	{%rs453, %rs454}, %r4078;
	mov.b32 	{%rs455, %rs456}, %r4082;
	st.shared.v4.b16 	[%r363+3328], {%rs451, %rs449, %rs453, %rs455};
	st.shared.v4.b16 	[%r363+3392], {%rs452, %rs450, %rs454, %rs456};
	mov.b32 	{%rs457, %rs458}, %r4090;
	mov.b32 	{%rs459, %rs460}, %r4086;
	mov.b32 	{%rs461, %rs462}, %r4094;
	mov.b32 	{%rs463, %rs464}, %r4098;
	st.shared.v4.b16 	[%r363+3840], {%rs459, %rs457, %rs461, %rs463};
	st.shared.v4.b16 	[%r363+3904], {%rs460, %rs458, %rs462, %rs464};
	mov.b32 	{%rs465, %rs466}, %r3979;
	mov.b32 	{%rs467, %rs468}, %r3975;
	mov.b32 	{%rs469, %rs470}, %r3983;
	mov.b32 	{%rs471, %rs472}, %r3987;
	st.shared.v4.b16 	[%r364+384], {%rs467, %rs465, %rs469, %rs471};
	st.shared.v4.b16 	[%r364+448], {%rs468, %rs466, %rs470, %rs472};
	mov.b32 	{%rs473, %rs474}, %r3995;
	mov.b32 	{%rs475, %rs476}, %r3991;
	mov.b32 	{%rs477, %rs478}, %r3999;
	mov.b32 	{%rs479, %rs480}, %r4003;
	st.shared.v4.b16 	[%r364+896], {%rs475, %rs473, %rs477, %rs479};
	st.shared.v4.b16 	[%r364+960], {%rs476, %rs474, %rs478, %rs480};
	mov.b32 	{%rs481, %rs482}, %r4011;
	mov.b32 	{%rs483, %rs484}, %r4007;
	mov.b32 	{%rs485, %rs486}, %r4015;
	mov.b32 	{%rs487, %rs488}, %r4019;
	st.shared.v4.b16 	[%r364+1408], {%rs483, %rs481, %rs485, %rs487};
	st.shared.v4.b16 	[%r364+1472], {%rs484, %rs482, %rs486, %rs488};
	mov.b32 	{%rs489, %rs490}, %r4027;
	mov.b32 	{%rs491, %rs492}, %r4023;
	mov.b32 	{%rs493, %rs494}, %r4031;
	mov.b32 	{%rs495, %rs496}, %r4035;
	st.shared.v4.b16 	[%r364+1920], {%rs491, %rs489, %rs493, %rs495};
	st.shared.v4.b16 	[%r364+1984], {%rs492, %rs490, %rs494, %rs496};
	mov.b32 	{%rs497, %rs498}, %r4043;
	mov.b32 	{%rs499, %rs500}, %r4039;
	mov.b32 	{%rs501, %rs502}, %r4047;
	mov.b32 	{%rs503, %rs504}, %r4051;
	st.shared.v4.b16 	[%r364+2432], {%rs499, %rs497, %rs501, %rs503};
	st.shared.v4.b16 	[%r364+2496], {%rs500, %rs498, %rs502, %rs504};
	mov.b32 	{%rs505, %rs506}, %r4059;
	mov.b32 	{%rs507, %rs508}, %r4055;
	mov.b32 	{%rs509, %rs510}, %r4063;
	mov.b32 	{%rs511, %rs512}, %r4067;
	st.shared.v4.b16 	[%r364+2944], {%rs507, %rs505, %rs509, %rs511};
	st.shared.v4.b16 	[%r364+3008], {%rs508, %rs506, %rs510, %rs512};
	mov.b32 	{%rs513, %rs514}, %r4075;
	mov.b32 	{%rs515, %rs516}, %r4071;
	mov.b32 	{%rs517, %rs518}, %r4079;
	mov.b32 	{%rs519, %rs520}, %r4083;
	st.shared.v4.b16 	[%r364+3456], {%rs515, %rs513, %rs517, %rs519};
	st.shared.v4.b16 	[%r364+3520], {%rs516, %rs514, %rs518, %rs520};
	mov.b32 	{%rs521, %rs522}, %r4091;
	mov.b32 	{%rs523, %rs524}, %r4087;
	mov.b32 	{%rs525, %rs526}, %r4095;
	mov.b32 	{%rs527, %rs528}, %r4099;
	st.shared.v4.b16 	[%r364+3968], {%rs523, %rs521, %rs525, %rs527};
	st.shared.v4.b16 	[%r364+4032], {%rs524, %rs522, %rs526, %rs528};
	ld.shared.b16 	%rs529, [%r365];
	ld.shared.b16 	%rs530, [%r365+8];
	ld.shared.b16 	%rs531, [%r365+16];
	ld.shared.b16 	%rs532, [%r365+24];
	ld.shared.b16 	%rs533, [%r365+32];
	ld.shared.b16 	%rs534, [%r365+40];
	ld.shared.b16 	%rs535, [%r365+48];
	ld.shared.b16 	%rs536, [%r365+56];
	ld.shared.b16 	%rs537, [%r365+64];
	ld.shared.b16 	%rs538, [%r365+72];
	ld.shared.b16 	%rs539, [%r365+80];
	ld.shared.b16 	%rs540, [%r365+88];
	ld.shared.b16 	%rs541, [%r365+96];
	ld.shared.b16 	%rs542, [%r365+104];
	ld.shared.b16 	%rs543, [%r365+112];
	ld.shared.b16 	%rs544, [%r365+120];
	bar.sync 	0;
	st.shared.b16 	[%r42], %rs529;
	st.shared.b16 	[%r42+512], %rs531;
	st.shared.b16 	[%r42+1024], %rs533;
	st.shared.b16 	[%r42+1536], %rs535;
	st.shared.b16 	[%r42+2048], %rs537;
	st.shared.b16 	[%r42+2560], %rs539;
	st.shared.b16 	[%r42+3072], %rs541;
	st.shared.b16 	[%r42+3584], %rs543;
	st.shared.b16 	[%r366+256], %rs530;
	st.shared.b16 	[%r366+768], %rs532;
	st.shared.b16 	[%r366+1280], %rs534;
	st.shared.b16 	[%r366+1792], %rs536;
	st.shared.b16 	[%r366+2304], %rs538;
	st.shared.b16 	[%r366+2816], %rs540;
	st.shared.b16 	[%r366+3328], %rs542;
	st.shared.b16 	[%r366+3840], %rs544;
	mul.wide.s32 	%rd478, %r7696, 4;
	add.s64 	%rd450, %rd4, %rd478;
	// begin inline asm
	@%p37 cp.async.ca.shared.global [ %r2424 + 0 ], [ %rd450 + 0 ], 0x4, 0x4;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v2.b32 	{%r4100, %r4101}, [%r368];
	ld.shared.v2.b32 	{%r4102, %r4103}, [%r368+32];
	ld.shared.v2.b32 	{%r4104, %r4105}, [%r368+64];
	ld.shared.v2.b32 	{%r4106, %r4107}, [%r368+96];
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2425, %r2426, %r2427, %r2428}, [%r2429];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2430, %r2431, %r2432, %r2433}, [%r2434];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2435, %r2436, %r2437, %r2438}, [%r2439];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2440, %r2441, %r2442, %r2443}, [%r2444];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2445, %r2446, %r2447, %r2448}, [%r2449];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2450, %r2451, %r2452, %r2453}, [%r2454];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2455, %r2456, %r2457, %r2458}, [%r2459];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r2460, %r2461, %r2462, %r2463}, [%r2464];
	// end inline asm
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	shfl.sync.idx.b32 	%r4108, %r2, 0, 31, -1;
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r2521,%r2522,%r2523,%r2524,%r2525,%r2526,%r2527,%r2528,%r2529,%r2530,%r2531,%r2532,%r2533,%r2534,%r2535,%r2536}, {%r2425,%r2426,%r2427,%r2428}, %rd588, 0, 1, 1, 1;
	// end inline asm
	mov.pred 	%p38, -1;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r2521,%r2522,%r2523,%r2524,%r2525,%r2526,%r2527,%r2528,%r2529,%r2530,%r2531,%r2532,%r2533,%r2534,%r2535,%r2536}, {%r2430,%r2431,%r2432,%r2433}, %rd452, %p38, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r2521,%r2522,%r2523,%r2524,%r2525,%r2526,%r2527,%r2528,%r2529,%r2530,%r2531,%r2532,%r2533,%r2534,%r2535,%r2536}, {%r2435,%r2436,%r2437,%r2438}, %rd453, %p38, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r2521,%r2522,%r2523,%r2524,%r2525,%r2526,%r2527,%r2528,%r2529,%r2530,%r2531,%r2532,%r2533,%r2534,%r2535,%r2536}, {%r2440,%r2441,%r2442,%r2443}, %rd454, %p38, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r2649,%r2650,%r2651,%r2652,%r2653,%r2654,%r2655,%r2656,%r2657,%r2658,%r2659,%r2660,%r2661,%r2662,%r2663,%r2664}, {%r2445,%r2446,%r2447,%r2448}, %rd588, 0, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r2649,%r2650,%r2651,%r2652,%r2653,%r2654,%r2655,%r2656,%r2657,%r2658,%r2659,%r2660,%r2661,%r2662,%r2663,%r2664}, {%r2450,%r2451,%r2452,%r2453}, %rd452, %p38, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r2649,%r2650,%r2651,%r2652,%r2653,%r2654,%r2655,%r2656,%r2657,%r2658,%r2659,%r2660,%r2661,%r2662,%r2663,%r2664}, {%r2455,%r2456,%r2457,%r2458}, %rd453, %p38, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r2649,%r2650,%r2651,%r2652,%r2653,%r2654,%r2655,%r2656,%r2657,%r2658,%r2659,%r2660,%r2661,%r2662,%r2663,%r2664}, {%r2460,%r2461,%r2462,%r2463}, %rd454, %p38, 1, 1, 1;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r3903, 0;
	mov.b32 	%r2753, %r2788;
	mov.b32 	%r2754, %r3903;
	mov.b32 	%r2755, %r3903;
	// begin inline asm
	// wait for regs: %r2521,%r2522,%r2523,%r2524,%r2525,%r2526,%r2527,%r2528,%r2529,%r2530,%r2531,%r2532,%r2533,%r2534,%r2535,%r2536,%r2649,%r2650,%r2651,%r2652,%r2653,%r2654,%r2655,%r2656,%r2657,%r2658,%r2659,%r2660,%r2661,%r2662,%r2663,%r2664,%r2753,%r2754,%r2755
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	sub.f32 	%r4110, %r2521, %r4100;
	sub.f32 	%r4111, %r2522, %r4101;
	sub.f32 	%r4112, %r2523, %r4100;
	sub.f32 	%r4113, %r2524, %r4101;
	sub.f32 	%r4114, %r2525, %r4102;
	sub.f32 	%r4115, %r2526, %r4103;
	sub.f32 	%r4116, %r2527, %r4102;
	sub.f32 	%r4117, %r2528, %r4103;
	sub.f32 	%r4118, %r2529, %r4104;
	sub.f32 	%r4119, %r2530, %r4105;
	sub.f32 	%r4120, %r2531, %r4104;
	sub.f32 	%r4121, %r2532, %r4105;
	sub.f32 	%r4122, %r2533, %r4106;
	sub.f32 	%r4123, %r2534, %r4107;
	sub.f32 	%r4124, %r2535, %r4106;
	sub.f32 	%r4125, %r2536, %r4107;
	sub.f32 	%r4126, %r2649, %r4100;
	sub.f32 	%r4127, %r2650, %r4101;
	sub.f32 	%r4128, %r2651, %r4100;
	sub.f32 	%r4129, %r2652, %r4101;
	sub.f32 	%r4130, %r2653, %r4102;
	sub.f32 	%r4131, %r2654, %r4103;
	sub.f32 	%r4132, %r2655, %r4102;
	sub.f32 	%r4133, %r2656, %r4103;
	sub.f32 	%r4134, %r2657, %r4104;
	sub.f32 	%r4135, %r2658, %r4105;
	sub.f32 	%r4136, %r2659, %r4104;
	sub.f32 	%r4137, %r2660, %r4105;
	sub.f32 	%r4138, %r2661, %r4106;
	sub.f32 	%r4139, %r2662, %r4107;
	sub.f32 	%r4140, %r2663, %r4106;
	sub.f32 	%r4141, %r2664, %r4107;
	ex2.approx.ftz.f32 	%r4142, %r4110;
	ex2.approx.ftz.f32 	%r4143, %r4111;
	ex2.approx.ftz.f32 	%r4144, %r4112;
	ex2.approx.ftz.f32 	%r4145, %r4113;
	ex2.approx.ftz.f32 	%r4146, %r4114;
	ex2.approx.ftz.f32 	%r4147, %r4115;
	ex2.approx.ftz.f32 	%r4148, %r4116;
	ex2.approx.ftz.f32 	%r4149, %r4117;
	ex2.approx.ftz.f32 	%r4150, %r4118;
	ex2.approx.ftz.f32 	%r4151, %r4119;
	ex2.approx.ftz.f32 	%r4152, %r4120;
	ex2.approx.ftz.f32 	%r4153, %r4121;
	ex2.approx.ftz.f32 	%r4154, %r4122;
	ex2.approx.ftz.f32 	%r4155, %r4123;
	ex2.approx.ftz.f32 	%r4156, %r4124;
	ex2.approx.ftz.f32 	%r4157, %r4125;
	ex2.approx.ftz.f32 	%r4158, %r4126;
	ex2.approx.ftz.f32 	%r4159, %r4127;
	ex2.approx.ftz.f32 	%r4160, %r4128;
	ex2.approx.ftz.f32 	%r4161, %r4129;
	ex2.approx.ftz.f32 	%r4162, %r4130;
	ex2.approx.ftz.f32 	%r4163, %r4131;
	ex2.approx.ftz.f32 	%r4164, %r4132;
	ex2.approx.ftz.f32 	%r4165, %r4133;
	ex2.approx.ftz.f32 	%r4166, %r4134;
	ex2.approx.ftz.f32 	%r4167, %r4135;
	ex2.approx.ftz.f32 	%r4168, %r4136;
	ex2.approx.ftz.f32 	%r4169, %r4137;
	ex2.approx.ftz.f32 	%r4170, %r4138;
	ex2.approx.ftz.f32 	%r4171, %r4139;
	ex2.approx.ftz.f32 	%r4172, %r4140;
	ex2.approx.ftz.f32 	%r4173, %r4141;
	bar.sync 	0;
	// begin inline asm
	cp.async.cg.shared.global [ %r2791 + 0 ], [ %rd459 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r2792 + 0 ], [ %rd460 + 0 ], 0x10, 0x10;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v2.b32 	{%r4174, %r4175}, [%r59];
	ld.shared.v2.b32 	{%r4176, %r4177}, [%r59+128];
	ld.shared.v2.b32 	{%r4178, %r4179}, [%r59+256];
	ld.shared.v2.b32 	{%r4180, %r4181}, [%r59+384];
	ld.shared.v2.b32 	{%r4182, %r4183}, [%r59+512];
	ld.shared.v2.b32 	{%r4184, %r4185}, [%r59+640];
	ld.shared.v2.b32 	{%r4186, %r4187}, [%r59+768];
	ld.shared.v2.b32 	{%r4188, %r4189}, [%r59+896];
	ld.shared.v2.b32 	{%r4190, %r4191}, [%r59+1024];
	ld.shared.v2.b32 	{%r4192, %r4193}, [%r59+1152];
	ld.shared.v2.b32 	{%r4194, %r4195}, [%r59+1280];
	ld.shared.v2.b32 	{%r4196, %r4197}, [%r59+1408];
	ld.shared.v2.b32 	{%r4198, %r4199}, [%r59+1536];
	ld.shared.v2.b32 	{%r4200, %r4201}, [%r59+1664];
	ld.shared.v2.b32 	{%r4202, %r4203}, [%r59+1792];
	ld.shared.v2.b32 	{%r4204, %r4205}, [%r59+1920];
	ld.shared.v2.b32 	{%r4206, %r4207}, [%r387+2048];
	ld.shared.v2.b32 	{%r4208, %r4209}, [%r59+2176];
	ld.shared.v2.b32 	{%r4210, %r4211}, [%r59+2304];
	ld.shared.v2.b32 	{%r4212, %r4213}, [%r59+2432];
	ld.shared.v2.b32 	{%r4214, %r4215}, [%r59+2560];
	ld.shared.v2.b32 	{%r4216, %r4217}, [%r59+2688];
	ld.shared.v2.b32 	{%r4218, %r4219}, [%r59+2816];
	ld.shared.v2.b32 	{%r4220, %r4221}, [%r59+2944];
	ld.shared.v2.b32 	{%r4222, %r4223}, [%r387+3072];
	ld.shared.v2.b32 	{%r4224, %r4225}, [%r59+3200];
	ld.shared.v2.b32 	{%r4226, %r4227}, [%r59+3328];
	ld.shared.v2.b32 	{%r4228, %r4229}, [%r59+3456];
	ld.shared.v2.b32 	{%r4230, %r4231}, [%r59+3584];
	ld.shared.v2.b32 	{%r4232, %r4233}, [%r59+3712];
	ld.shared.v2.b32 	{%r4234, %r4235}, [%r59+3840];
	ld.shared.v2.b32 	{%r4236, %r4237}, [%r59+3968];
	st.shared.v2.b32 	[%r388], {%r4174, %r4175};
	st.shared.v2.b32 	[%r388+1024], {%r4190, %r4191};
	st.shared.v2.b32 	[%r388+2048], {%r4206, %r4207};
	st.shared.v2.b32 	[%r388+3072], {%r4222, %r4223};
	st.shared.v2.b32 	[%r389+128], {%r4176, %r4177};
	st.shared.v2.b32 	[%r389+1152], {%r4192, %r4193};
	st.shared.v2.b32 	[%r389+2176], {%r4208, %r4209};
	st.shared.v2.b32 	[%r389+3200], {%r4224, %r4225};
	st.shared.v2.b32 	[%r390+256], {%r4178, %r4179};
	st.shared.v2.b32 	[%r390+1280], {%r4194, %r4195};
	st.shared.v2.b32 	[%r390+2304], {%r4210, %r4211};
	st.shared.v2.b32 	[%r390+3328], {%r4226, %r4227};
	st.shared.v2.b32 	[%r391+384], {%r4180, %r4181};
	st.shared.v2.b32 	[%r391+1408], {%r4196, %r4197};
	st.shared.v2.b32 	[%r391+2432], {%r4212, %r4213};
	st.shared.v2.b32 	[%r391+3456], {%r4228, %r4229};
	st.shared.v2.b32 	[%r392+512], {%r4182, %r4183};
	st.shared.v2.b32 	[%r392+1536], {%r4198, %r4199};
	st.shared.v2.b32 	[%r392+2560], {%r4214, %r4215};
	st.shared.v2.b32 	[%r392+3584], {%r4230, %r4231};
	st.shared.v2.b32 	[%r393+640], {%r4184, %r4185};
	st.shared.v2.b32 	[%r393+1664], {%r4200, %r4201};
	st.shared.v2.b32 	[%r393+2688], {%r4216, %r4217};
	st.shared.v2.b32 	[%r393+3712], {%r4232, %r4233};
	st.shared.v2.b32 	[%r394+768], {%r4186, %r4187};
	st.shared.v2.b32 	[%r394+1792], {%r4202, %r4203};
	st.shared.v2.b32 	[%r394+2816], {%r4218, %r4219};
	st.shared.v2.b32 	[%r394+3840], {%r4234, %r4235};
	st.shared.v2.b32 	[%r395+896], {%r4188, %r4189};
	st.shared.v2.b32 	[%r395+1920], {%r4204, %r4205};
	st.shared.v2.b32 	[%r395+2944], {%r4220, %r4221};
	st.shared.v2.b32 	[%r395+3968], {%r4236, %r4237};
	ld.shared.b16 	%rs545, [%r396];
	ld.shared.b16 	%rs546, [%r396+256];
	ld.shared.b16 	%rs547, [%r396+512];
	ld.shared.b16 	%rs548, [%r396+768];
	ld.shared.b16 	%rs549, [%r396+1024];
	ld.shared.b16 	%rs550, [%r396+1280];
	ld.shared.b16 	%rs551, [%r396+1536];
	ld.shared.b16 	%rs552, [%r396+1792];
	ld.shared.b16 	%rs553, [%r396+2048];
	ld.shared.b16 	%rs554, [%r396+2304];
	ld.shared.b16 	%rs555, [%r396+2560];
	ld.shared.b16 	%rs556, [%r396+2816];
	ld.shared.b16 	%rs557, [%r396+3072];
	ld.shared.b16 	%rs558, [%r396+3328];
	ld.shared.b16 	%rs559, [%r396+3584];
	ld.shared.b16 	%rs560, [%r396+3840];
	bar.sync 	0;
	st.shared.b16 	[%r397], %rs545;
	st.shared.b16 	[%r397+1024], %rs549;
	st.shared.b16 	[%r397+2048], %rs553;
	st.shared.b16 	[%r397+3072], %rs557;
	st.shared.b16 	[%r398+256], %rs546;
	st.shared.b16 	[%r398+1280], %rs550;
	st.shared.b16 	[%r398+2304], %rs554;
	st.shared.b16 	[%r398+3328], %rs558;
	st.shared.b16 	[%r399+512], %rs547;
	st.shared.b16 	[%r399+1536], %rs551;
	st.shared.b16 	[%r399+2560], %rs555;
	st.shared.b16 	[%r399+3584], %rs559;
	st.shared.b16 	[%r400+768], %rs548;
	st.shared.b16 	[%r400+1792], %rs552;
	st.shared.b16 	[%r400+2816], %rs556;
	st.shared.b16 	[%r400+3840], %rs560;
	cvt.rn.f16x2.f32 	%r2857, %r4143, %r4142;
	cvt.rn.f16x2.f32 	%r2858, %r4145, %r4144;
	cvt.rn.f16x2.f32 	%r2859, %r4147, %r4146;
	cvt.rn.f16x2.f32 	%r2860, %r4149, %r4148;
	cvt.rn.f16x2.f32 	%r2925, %r4151, %r4150;
	cvt.rn.f16x2.f32 	%r2926, %r4153, %r4152;
	cvt.rn.f16x2.f32 	%r2927, %r4155, %r4154;
	cvt.rn.f16x2.f32 	%r2928, %r4157, %r4156;
	cvt.rn.f16x2.f32 	%r2993, %r4159, %r4158;
	cvt.rn.f16x2.f32 	%r2994, %r4161, %r4160;
	cvt.rn.f16x2.f32 	%r2995, %r4163, %r4162;
	cvt.rn.f16x2.f32 	%r2996, %r4165, %r4164;
	cvt.rn.f16x2.f32 	%r3061, %r4167, %r4166;
	cvt.rn.f16x2.f32 	%r3062, %r4169, %r4168;
	cvt.rn.f16x2.f32 	%r3063, %r4171, %r4170;
	cvt.rn.f16x2.f32 	%r3064, %r4173, %r4172;
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7697,%r7698,%r7699,%r7700,%r7701,%r7702,%r7703,%r7704,%r7705,%r7706,%r7707,%r7708,%r7709,%r7710,%r7711,%r7712,%r7713,%r7714,%r7715,%r7716,%r7717,%r7718,%r7719,%r7720,%r7721,%r7722,%r7723,%r7724,%r7725,%r7726,%r7727,%r7728}, {%r2857,%r2858,%r2859,%r2860}, %rd461, %p38, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7697,%r7698,%r7699,%r7700,%r7701,%r7702,%r7703,%r7704,%r7705,%r7706,%r7707,%r7708,%r7709,%r7710,%r7711,%r7712,%r7713,%r7714,%r7715,%r7716,%r7717,%r7718,%r7719,%r7720,%r7721,%r7722,%r7723,%r7724,%r7725,%r7726,%r7727,%r7728}, {%r2925,%r2926,%r2927,%r2928}, %rd462, %p38, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7729,%r7730,%r7731,%r7732,%r7733,%r7734,%r7735,%r7736,%r7737,%r7738,%r7739,%r7740,%r7741,%r7742,%r7743,%r7744,%r7745,%r7746,%r7747,%r7748,%r7749,%r7750,%r7751,%r7752,%r7753,%r7754,%r7755,%r7756,%r7757,%r7758,%r7759,%r7760}, {%r2993,%r2994,%r2995,%r2996}, %rd461, %p38, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7729,%r7730,%r7731,%r7732,%r7733,%r7734,%r7735,%r7736,%r7737,%r7738,%r7739,%r7740,%r7741,%r7742,%r7743,%r7744,%r7745,%r7746,%r7747,%r7748,%r7749,%r7750,%r7751,%r7752,%r7753,%r7754,%r7755,%r7756,%r7757,%r7758,%r7759,%r7760}, {%r3061,%r3062,%r3063,%r3064}, %rd462, %p38, 1, 1, 1;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r3129, %r2398;
	mov.b32 	%r3130, %r3903;
	mov.b32 	%r3131, %r3903;
	// begin inline asm
	// wait for regs: %r7697,%r7698,%r7699,%r7700,%r7701,%r7702,%r7703,%r7704,%r7705,%r7706,%r7707,%r7708,%r7709,%r7710,%r7711,%r7712,%r7713,%r7714,%r7715,%r7716,%r7717,%r7718,%r7719,%r7720,%r7721,%r7722,%r7723,%r7724,%r7725,%r7726,%r7727,%r7728,%r7729,%r7730,%r7731,%r7732,%r7733,%r7734,%r7735,%r7736,%r7737,%r7738,%r7739,%r7740,%r7741,%r7742,%r7743,%r7744,%r7745,%r7746,%r7747,%r7748,%r7749,%r7750,%r7751,%r7752,%r7753,%r7754,%r7755,%r7756,%r7757,%r7758,%r7759,%r7760,%r3129,%r3130,%r3131
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	add.s64 	%rd465, %rd5, %rd478;
	bar.sync 	0;
	// begin inline asm
	@%p37 cp.async.ca.shared.global [ %r2424 + 0 ], [ %rd465 + 0 ], 0x4, 0x4;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v2.b32 	{%r4238, %r4239}, [%r368+96];
	ld.shared.v2.b32 	{%r4240, %r4241}, [%r368+64];
	ld.shared.v2.b32 	{%r4242, %r4243}, [%r368+32];
	ld.shared.v2.b32 	{%r4244, %r4245}, [%r368];
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3200, %r3201, %r3202, %r3203}, [%r3204];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3205, %r3206, %r3207, %r3208}, [%r3209];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3210, %r3211, %r3212, %r3213}, [%r3214];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3215, %r3216, %r3217, %r3218}, [%r3219];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3220, %r3221, %r3222, %r3223}, [%r3224];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3225, %r3226, %r3227, %r3228}, [%r3229];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3230, %r3231, %r3232, %r3233}, [%r3234];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r3235, %r3236, %r3237, %r3238}, [%r3239];
	// end inline asm
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r3296,%r3297,%r3298,%r3299,%r3300,%r3301,%r3302,%r3303,%r3304,%r3305,%r3306,%r3307,%r3308,%r3309,%r3310,%r3311}, {%r3200,%r3201,%r3202,%r3203}, %rd466, 0, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r3296,%r3297,%r3298,%r3299,%r3300,%r3301,%r3302,%r3303,%r3304,%r3305,%r3306,%r3307,%r3308,%r3309,%r3310,%r3311}, {%r3205,%r3206,%r3207,%r3208}, %rd467, %p38, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r3296,%r3297,%r3298,%r3299,%r3300,%r3301,%r3302,%r3303,%r3304,%r3305,%r3306,%r3307,%r3308,%r3309,%r3310,%r3311}, {%r3210,%r3211,%r3212,%r3213}, %rd468, %p38, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r3296,%r3297,%r3298,%r3299,%r3300,%r3301,%r3302,%r3303,%r3304,%r3305,%r3306,%r3307,%r3308,%r3309,%r3310,%r3311}, {%r3215,%r3216,%r3217,%r3218}, %rd469, %p38, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r3424,%r3425,%r3426,%r3427,%r3428,%r3429,%r3430,%r3431,%r3432,%r3433,%r3434,%r3435,%r3436,%r3437,%r3438,%r3439}, {%r3220,%r3221,%r3222,%r3223}, %rd466, 0, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r3424,%r3425,%r3426,%r3427,%r3428,%r3429,%r3430,%r3431,%r3432,%r3433,%r3434,%r3435,%r3436,%r3437,%r3438,%r3439}, {%r3225,%r3226,%r3227,%r3228}, %rd467, %p38, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r3424,%r3425,%r3426,%r3427,%r3428,%r3429,%r3430,%r3431,%r3432,%r3433,%r3434,%r3435,%r3436,%r3437,%r3438,%r3439}, {%r3230,%r3231,%r3232,%r3233}, %rd468, %p38, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r3424,%r3425,%r3426,%r3427,%r3428,%r3429,%r3430,%r3431,%r3432,%r3433,%r3434,%r3435,%r3436,%r3437,%r3438,%r3439}, {%r3235,%r3236,%r3237,%r3238}, %rd469, %p38, 1, 1, 0;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r3529, %r3903;
	mov.b32 	%r3530, %r3903;
	mov.b32 	%r3528, %r2788;
	// begin inline asm
	// wait for regs: %r3296,%r3297,%r3298,%r3299,%r3300,%r3301,%r3302,%r3303,%r3304,%r3305,%r3306,%r3307,%r3308,%r3309,%r3310,%r3311,%r3424,%r3425,%r3426,%r3427,%r3428,%r3429,%r3430,%r3431,%r3432,%r3433,%r3434,%r3435,%r3436,%r3437,%r3438,%r3439,%r3528,%r3529,%r3530
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	sub.f32 	%r4246, %r3427, %r4245;
	sub.f32 	%r4247, %r3426, %r4244;
	sub.f32 	%r4248, %r3431, %r4243;
	sub.f32 	%r4249, %r3430, %r4242;
	sub.f32 	%r4250, %r3435, %r4241;
	sub.f32 	%r4251, %r3434, %r4240;
	sub.f32 	%r4252, %r3439, %r4239;
	sub.f32 	%r4253, %r3438, %r4238;
	mul.f32 	%r4254, %r4160, %r4247;
	mul.f32 	%r4255, %r4161, %r4246;
	mul.f32 	%r4256, %r4164, %r4249;
	mul.f32 	%r4257, %r4165, %r4248;
	mul.f32 	%r4258, %r4168, %r4251;
	mul.f32 	%r4259, %r4169, %r4250;
	mul.f32 	%r4260, %r4172, %r4253;
	mul.f32 	%r4261, %r4173, %r4252;
	sub.f32 	%r4262, %r3297, %r4245;
	sub.f32 	%r4263, %r3296, %r4244;
	mul.f32 	%r4264, %r4142, %r4263;
	mul.f32 	%r4265, %r4143, %r4262;
	cvt.rn.f16x2.f32 	%r3630, %r4265, %r4264;
	sub.f32 	%r4266, %r3299, %r4245;
	sub.f32 	%r4267, %r3298, %r4244;
	mul.f32 	%r4268, %r4144, %r4267;
	mul.f32 	%r4269, %r4145, %r4266;
	cvt.rn.f16x2.f32 	%r3631, %r4269, %r4268;
	sub.f32 	%r4270, %r3301, %r4243;
	sub.f32 	%r4271, %r3300, %r4242;
	mul.f32 	%r4272, %r4146, %r4271;
	mul.f32 	%r4273, %r4147, %r4270;
	cvt.rn.f16x2.f32 	%r3632, %r4273, %r4272;
	sub.f32 	%r4274, %r3303, %r4243;
	sub.f32 	%r4275, %r3302, %r4242;
	mul.f32 	%r4276, %r4148, %r4275;
	mul.f32 	%r4277, %r4149, %r4274;
	cvt.rn.f16x2.f32 	%r3633, %r4277, %r4276;
	sub.f32 	%r4278, %r3305, %r4241;
	sub.f32 	%r4279, %r3304, %r4240;
	mul.f32 	%r4280, %r4150, %r4279;
	mul.f32 	%r4281, %r4151, %r4278;
	cvt.rn.f16x2.f32 	%r3698, %r4281, %r4280;
	sub.f32 	%r4282, %r3307, %r4241;
	sub.f32 	%r4283, %r3306, %r4240;
	mul.f32 	%r4284, %r4152, %r4283;
	mul.f32 	%r4285, %r4153, %r4282;
	cvt.rn.f16x2.f32 	%r3699, %r4285, %r4284;
	sub.f32 	%r4286, %r3309, %r4239;
	sub.f32 	%r4287, %r3308, %r4238;
	mul.f32 	%r4288, %r4154, %r4287;
	mul.f32 	%r4289, %r4155, %r4286;
	cvt.rn.f16x2.f32 	%r3700, %r4289, %r4288;
	sub.f32 	%r4290, %r3311, %r4239;
	sub.f32 	%r4291, %r3310, %r4238;
	mul.f32 	%r4292, %r4156, %r4291;
	mul.f32 	%r4293, %r4157, %r4290;
	cvt.rn.f16x2.f32 	%r3701, %r4293, %r4292;
	sub.f32 	%r4294, %r3425, %r4245;
	sub.f32 	%r4295, %r3424, %r4244;
	mul.f32 	%r4296, %r4158, %r4295;
	mul.f32 	%r4297, %r4159, %r4294;
	cvt.rn.f16x2.f32 	%r3766, %r4297, %r4296;
	cvt.rn.f16x2.f32 	%r3767, %r4255, %r4254;
	sub.f32 	%r4298, %r3429, %r4243;
	sub.f32 	%r4299, %r3428, %r4242;
	mul.f32 	%r4300, %r4162, %r4299;
	mul.f32 	%r4301, %r4163, %r4298;
	cvt.rn.f16x2.f32 	%r3768, %r4301, %r4300;
	cvt.rn.f16x2.f32 	%r3769, %r4257, %r4256;
	sub.f32 	%r4302, %r3433, %r4241;
	sub.f32 	%r4303, %r3432, %r4240;
	mul.f32 	%r4304, %r4166, %r4303;
	mul.f32 	%r4305, %r4167, %r4302;
	cvt.rn.f16x2.f32 	%r3834, %r4305, %r4304;
	cvt.rn.f16x2.f32 	%r3835, %r4259, %r4258;
	sub.f32 	%r4306, %r3437, %r4239;
	sub.f32 	%r4307, %r3436, %r4238;
	mul.f32 	%r4308, %r4170, %r4307;
	mul.f32 	%r4309, %r4171, %r4306;
	cvt.rn.f16x2.f32 	%r3836, %r4309, %r4308;
	cvt.rn.f16x2.f32 	%r3837, %r4261, %r4260;
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7631,%r7632,%r7633,%r7634,%r7635,%r7636,%r7637,%r7638,%r7639,%r7640,%r7641,%r7642,%r7643,%r7644,%r7645,%r7646,%r7647,%r7648,%r7649,%r7650,%r7651,%r7652,%r7653,%r7654,%r7655,%r7656,%r7657,%r7658,%r7659,%r7660,%r7661,%r7662}, {%r3630,%r3631,%r3632,%r3633}, %rd604, %p38, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7631,%r7632,%r7633,%r7634,%r7635,%r7636,%r7637,%r7638,%r7639,%r7640,%r7641,%r7642,%r7643,%r7644,%r7645,%r7646,%r7647,%r7648,%r7649,%r7650,%r7651,%r7652,%r7653,%r7654,%r7655,%r7656,%r7657,%r7658,%r7659,%r7660,%r7661,%r7662}, {%r3698,%r3699,%r3700,%r3701}, %rd475, %p38, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7663,%r7664,%r7665,%r7666,%r7667,%r7668,%r7669,%r7670,%r7671,%r7672,%r7673,%r7674,%r7675,%r7676,%r7677,%r7678,%r7679,%r7680,%r7681,%r7682,%r7683,%r7684,%r7685,%r7686,%r7687,%r7688,%r7689,%r7690,%r7691,%r7692,%r7693,%r7694}, {%r3766,%r3767,%r3768,%r3769}, %rd604, %p38, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7663,%r7664,%r7665,%r7666,%r7667,%r7668,%r7669,%r7670,%r7671,%r7672,%r7673,%r7674,%r7675,%r7676,%r7677,%r7678,%r7679,%r7680,%r7681,%r7682,%r7683,%r7684,%r7685,%r7686,%r7687,%r7688,%r7689,%r7690,%r7691,%r7692,%r7693,%r7694}, {%r3834,%r3835,%r3836,%r3837}, %rd475, %p38, 1, 1, 0;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r3902, %r1109;
	mov.b32 	%r3904, %r3903;
	// begin inline asm
	// wait for regs: %r7631,%r7632,%r7633,%r7634,%r7635,%r7636,%r7637,%r7638,%r7639,%r7640,%r7641,%r7642,%r7643,%r7644,%r7645,%r7646,%r7647,%r7648,%r7649,%r7650,%r7651,%r7652,%r7653,%r7654,%r7655,%r7656,%r7657,%r7658,%r7659,%r7660,%r7661,%r7662,%r7663,%r7664,%r7665,%r7666,%r7667,%r7668,%r7669,%r7670,%r7671,%r7672,%r7673,%r7674,%r7675,%r7676,%r7677,%r7678,%r7679,%r7680,%r7681,%r7682,%r7683,%r7684,%r7685,%r7686,%r7687,%r7688,%r7689,%r7690,%r7691,%r7692,%r7693,%r7694,%r3902,%r3903,%r3904
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	add.s64 	%rd644, %rd644, %rd637;
	add.s64 	%rd643, %rd643, %rd637;
	add.s64 	%rd642, %rd642, %rd637;
	add.s64 	%rd641, %rd641, %rd637;
	add.s32 	%r7696, %r7696, 32;
	add.s32 	%r7695, %r7695, -1;
	setp.ne.b32 	%p59, %r7695, 0;
	@%p59 bra 	$L__BB0_5;
// %bb.6:                               // %._crit_edge.loopexit
	mov.b64 	%rd677, {%r7747, %r7748};
	mov.b64 	%rd676, {%r7751, %r7752};
	mov.b64 	%rd675, {%r7755, %r7756};
	mov.b64 	%rd674, {%r7759, %r7760};
	mov.b64 	%rd673, {%r7745, %r7746};
	mov.b64 	%rd672, {%r7749, %r7750};
	mov.b64 	%rd671, {%r7753, %r7754};
	mov.b64 	%rd670, {%r7757, %r7758};
	mov.b64 	%rd669, {%r7731, %r7732};
	mov.b64 	%rd668, {%r7735, %r7736};
	mov.b64 	%rd667, {%r7739, %r7740};
	mov.b64 	%rd666, {%r7743, %r7744};
	mov.b64 	%rd665, {%r7729, %r7730};
	mov.b64 	%rd664, {%r7733, %r7734};
	mov.b64 	%rd663, {%r7737, %r7738};
	mov.b64 	%rd662, {%r7741, %r7742};
	mov.b64 	%rd661, {%r7715, %r7716};
	mov.b64 	%rd660, {%r7719, %r7720};
	mov.b64 	%rd659, {%r7723, %r7724};
	mov.b64 	%rd658, {%r7727, %r7728};
	mov.b64 	%rd657, {%r7713, %r7714};
	mov.b64 	%rd656, {%r7717, %r7718};
	mov.b64 	%rd655, {%r7721, %r7722};
	mov.b64 	%rd654, {%r7725, %r7726};
	mov.b64 	%rd653, {%r7699, %r7700};
	mov.b64 	%rd652, {%r7703, %r7704};
	mov.b64 	%rd651, {%r7707, %r7708};
	mov.b64 	%rd650, {%r7711, %r7712};
	mov.b64 	%rd649, {%r7697, %r7698};
	mov.b64 	%rd648, {%r7701, %r7702};
	mov.b64 	%rd647, {%r7705, %r7706};
	mov.b64 	%rd646, {%r7709, %r7710};
	bra.uni 	$L__BB0_7;
$L__BB0_3:                              // %.._crit_edge_crit_edge
	or.b32 	%r2381, %r39, %r46;
	or.b32 	%r7832, %r2381, %r47;
	or.b32 	%r7831, %r7832, 32;
	or.b32 	%r7830, %r7832, 64;
	or.b32 	%r7829, %r7832, 96;
	or.b32 	%r7828, %r7832, 8192;
	or.b32 	%r7827, %r7832, 8224;
	or.b32 	%r7826, %r7832, 8256;
	or.b32 	%r7825, %r7832, 8288;
	add.s32 	%r2383, %r1103, 37888;
	bfe.u32 	%r2384, %r2383, 4, 14;
	cvt.u64.u32 	%rd645, %r2384;
	mov.b64 	%rd646, {%r7709, %r7710};
	mov.b64 	%rd647, {%r7705, %r7706};
	mov.b64 	%rd648, {%r7701, %r7702};
	mov.b64 	%rd649, {%r7697, %r7698};
	mov.b64 	%rd650, {%r7711, %r7712};
	mov.b64 	%rd651, {%r7707, %r7708};
	mov.b64 	%rd652, {%r7703, %r7704};
	mov.b64 	%rd653, {%r7699, %r7700};
	mov.b64 	%rd654, {%r7725, %r7726};
	mov.b64 	%rd655, {%r7721, %r7722};
	mov.b64 	%rd656, {%r7717, %r7718};
	mov.b64 	%rd657, {%r7713, %r7714};
	mov.b64 	%rd658, {%r7727, %r7728};
	mov.b64 	%rd659, {%r7723, %r7724};
	mov.b64 	%rd660, {%r7719, %r7720};
	mov.b64 	%rd661, {%r7715, %r7716};
	mov.b64 	%rd662, {%r7741, %r7742};
	mov.b64 	%rd663, {%r7737, %r7738};
	mov.b64 	%rd664, {%r7733, %r7734};
	mov.b64 	%rd665, {%r7729, %r7730};
	mov.b64 	%rd666, {%r7743, %r7744};
	mov.b64 	%rd667, {%r7739, %r7740};
	mov.b64 	%rd668, {%r7735, %r7736};
	mov.b64 	%rd669, {%r7731, %r7732};
	mov.b64 	%rd670, {%r7757, %r7758};
	mov.b64 	%rd671, {%r7753, %r7754};
	mov.b64 	%rd672, {%r7749, %r7750};
	mov.b64 	%rd673, {%r7745, %r7746};
	mov.b64 	%rd674, {%r7759, %r7760};
	mov.b64 	%rd675, {%r7755, %r7756};
	mov.b64 	%rd676, {%r7751, %r7752};
	mov.b64 	%rd677, {%r7747, %r7748};
$L__BB0_7:                              // %._crit_edge
	shl.b64 	%rd513, %rd6, 1;
	add.s64 	%rd514, %rd75, %rd513;
	shl.b64 	%rd515, %rd7, 1;
	add.s64 	%rd516, %rd75, %rd515;
	shl.b64 	%rd517, %rd8, 1;
	add.s64 	%rd518, %rd75, %rd517;
	shl.b64 	%rd519, %rd9, 1;
	add.s64 	%rd520, %rd75, %rd519;
	shl.b64 	%rd521, %rd10, 1;
	add.s64 	%rd522, %rd75, %rd521;
	shl.b64 	%rd523, %rd11, 1;
	add.s64 	%rd524, %rd75, %rd523;
	shl.b64 	%rd525, %rd12, 1;
	add.s64 	%rd526, %rd75, %rd525;
	shl.b64 	%rd527, %rd13, 1;
	add.s64 	%rd528, %rd75, %rd527;
	shl.b64 	%rd529, %rd14, 1;
	add.s64 	%rd479, %rd514, %rd529;
	add.s64 	%rd480, %rd516, %rd529;
	add.s64 	%rd481, %rd518, %rd529;
	add.s64 	%rd482, %rd520, %rd529;
	add.s64 	%rd483, %rd522, %rd529;
	add.s64 	%rd484, %rd524, %rd529;
	add.s64 	%rd485, %rd526, %rd529;
	add.s64 	%rd486, %rd528, %rd529;
	mov.b64 	{%r4475, %r4476}, %rd649;
	cvt.rn.f16x2.f32 	%r4477, %r4476, %r4475;
	mov.b64 	{%r4478, %r4479}, %rd653;
	cvt.rn.f16x2.f32 	%r4480, %r4479, %r4478;
	mov.b64 	{%r4481, %r4482}, %rd648;
	cvt.rn.f16x2.f32 	%r4483, %r4482, %r4481;
	mov.b64 	{%r4484, %r4485}, %rd652;
	cvt.rn.f16x2.f32 	%r4486, %r4485, %r4484;
	mov.b64 	{%r4487, %r4488}, %rd647;
	cvt.rn.f16x2.f32 	%r4489, %r4488, %r4487;
	mov.b64 	{%r4490, %r4491}, %rd651;
	cvt.rn.f16x2.f32 	%r4492, %r4491, %r4490;
	mov.b64 	{%r4493, %r4494}, %rd646;
	cvt.rn.f16x2.f32 	%r4495, %r4494, %r4493;
	mov.b64 	{%r4496, %r4497}, %rd650;
	cvt.rn.f16x2.f32 	%r4498, %r4497, %r4496;
	mov.b64 	{%r4499, %r4500}, %rd657;
	cvt.rn.f16x2.f32 	%r4501, %r4500, %r4499;
	mov.b64 	{%r4502, %r4503}, %rd661;
	cvt.rn.f16x2.f32 	%r4504, %r4503, %r4502;
	mov.b64 	{%r4505, %r4506}, %rd656;
	cvt.rn.f16x2.f32 	%r4507, %r4506, %r4505;
	mov.b64 	{%r4508, %r4509}, %rd660;
	cvt.rn.f16x2.f32 	%r4510, %r4509, %r4508;
	mov.b64 	{%r4511, %r4512}, %rd655;
	cvt.rn.f16x2.f32 	%r4513, %r4512, %r4511;
	mov.b64 	{%r4514, %r4515}, %rd659;
	cvt.rn.f16x2.f32 	%r4516, %r4515, %r4514;
	mov.b64 	{%r4517, %r4518}, %rd654;
	cvt.rn.f16x2.f32 	%r4519, %r4518, %r4517;
	mov.b64 	{%r4520, %r4521}, %rd658;
	cvt.rn.f16x2.f32 	%r4522, %r4521, %r4520;
	mov.b64 	{%r4523, %r4524}, %rd665;
	cvt.rn.f16x2.f32 	%r4525, %r4524, %r4523;
	mov.b64 	{%r4526, %r4527}, %rd669;
	cvt.rn.f16x2.f32 	%r4528, %r4527, %r4526;
	mov.b64 	{%r4529, %r4530}, %rd664;
	cvt.rn.f16x2.f32 	%r4531, %r4530, %r4529;
	mov.b64 	{%r4532, %r4533}, %rd668;
	cvt.rn.f16x2.f32 	%r4534, %r4533, %r4532;
	mov.b64 	{%r4535, %r4536}, %rd663;
	cvt.rn.f16x2.f32 	%r4537, %r4536, %r4535;
	mov.b64 	{%r4538, %r4539}, %rd667;
	cvt.rn.f16x2.f32 	%r4540, %r4539, %r4538;
	mov.b64 	{%r4541, %r4542}, %rd662;
	cvt.rn.f16x2.f32 	%r4543, %r4542, %r4541;
	mov.b64 	{%r4544, %r4545}, %rd666;
	cvt.rn.f16x2.f32 	%r4546, %r4545, %r4544;
	mov.b64 	{%r4547, %r4548}, %rd673;
	cvt.rn.f16x2.f32 	%r4549, %r4548, %r4547;
	mov.b64 	{%r4550, %r4551}, %rd677;
	cvt.rn.f16x2.f32 	%r4552, %r4551, %r4550;
	mov.b64 	{%r4553, %r4554}, %rd672;
	cvt.rn.f16x2.f32 	%r4555, %r4554, %r4553;
	mov.b64 	{%r4556, %r4557}, %rd676;
	cvt.rn.f16x2.f32 	%r4558, %r4557, %r4556;
	mov.b64 	{%r4559, %r4560}, %rd671;
	cvt.rn.f16x2.f32 	%r4561, %r4560, %r4559;
	mov.b64 	{%r4562, %r4563}, %rd675;
	cvt.rn.f16x2.f32 	%r4564, %r4563, %r4562;
	mov.b64 	{%r4565, %r4566}, %rd670;
	cvt.rn.f16x2.f32 	%r4567, %r4566, %r4565;
	mov.b64 	{%r4568, %r4569}, %rd674;
	cvt.rn.f16x2.f32 	%r4570, %r4569, %r4568;
	shl.b32 	%r4571, %r4, 4;
	and.b32 	%r4572, %r1, 1;
	shl.b32 	%r4573, %r4572, 5;
	and.b32 	%r4574, %r1, 2;
	bfe.s32 	%r4575, %r1, 1, 1;
	and.b32 	%r4576, %r4575, 4160;
	bfe.s32 	%r4577, %r1, 2, 1;
	and.b32 	%r4578, %r1, 4;
	shl.b32 	%r4579, %r4578, 2;
	bfe.s32 	%r4580, %r1, 3, 1;
	and.b32 	%r4581, %r4580, 2080;
	setp.eq.b32 	%p60, %r47, 0;
	shl.b32 	%r4582, %r47, 3;
	or.b32 	%r4583, %r4576, %r4579;
	or.b32 	%r4584, %r4583, %r4582;
	or.b32 	%r4585, %r4571, %r4573;
	xor.b32 	%r4586, %r4585, %r4581;
	or.b32 	%r4587, %r4584, %r4586;
	add.s32 	%r742, %r1103, %r4587;
	st.shared.v4.b32 	[%r742], {%r4477, %r4483, %r4489, %r4495};
	st.shared.v4.b32 	[%r742+256], {%r4480, %r4486, %r4492, %r4498};
	xor.b32 	%r4589, %r4587, 64;
	add.s32 	%r743, %r1103, %r4589;
	st.shared.v4.b32 	[%r743], {%r4501, %r4507, %r4513, %r4519};
	st.shared.v4.b32 	[%r743+256], {%r4504, %r4510, %r4516, %r4522};
	bar.sync 	0;
	shl.b32 	%r4590, %r1, 2;
	and.b32 	%r4591, %r4590, 416;
	shl.b32 	%r4592, %r4572, 6;
	shl.b32 	%r4593, %r4574, 3;
	and.b32 	%r4594, %r4577, 2080;
	selp.b32 	%r4595, 0, 4160, %p60;
	or.b32 	%r4596, %r4591, %r4592;
	or.b32 	%r4597, %r4594, %r4595;
	xor.b32 	%r4598, %r4597, %r4596;
	add.s32 	%r4599, %r1103, %r4593;
	add.s32 	%r7354, %r4599, %r4598;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4350, %r4351, %r4352, %r4353}, [%r7354];
	// end inline asm
	add.s32 	%r7359, %r7354, 512;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4354, %r4355, %r4356, %r4357}, [%r7359];
	// end inline asm
	add.s32 	%r7364, %r7354, 1024;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4358, %r4359, %r4360, %r4361}, [%r7364];
	// end inline asm
	add.s32 	%r7369, %r7354, 1536;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4362, %r4363, %r4364, %r4365}, [%r7369];
	// end inline asm
	bar.sync 	0;
	st.shared.v4.b32 	[%r742], {%r4525, %r4531, %r4537, %r4543};
	st.shared.v4.b32 	[%r742+256], {%r4528, %r4534, %r4540, %r4546};
	st.shared.v4.b32 	[%r743], {%r4549, %r4555, %r4561, %r4567};
	st.shared.v4.b32 	[%r743+256], {%r4552, %r4558, %r4564, %r4570};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4366, %r4367, %r4368, %r4369}, [%r7354];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4370, %r4371, %r4372, %r4373}, [%r7359];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4374, %r4375, %r4376, %r4377}, [%r7364];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4378, %r4379, %r4380, %r4381}, [%r7369];
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd479 + 0 ], { %r4350, %r4351, %r4352, %r4353 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd480 + 0 ], { %r4354, %r4355, %r4356, %r4357 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd481 + 0 ], { %r4358, %r4359, %r4360, %r4361 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd482 + 0 ], { %r4362, %r4363, %r4364, %r4365 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd483 + 0 ], { %r4366, %r4367, %r4368, %r4369 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd484 + 0 ], { %r4370, %r4371, %r4372, %r4373 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd485 + 0 ], { %r4374, %r4375, %r4376, %r4377 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd486 + 0 ], { %r4378, %r4379, %r4380, %r4381 };
	// end inline asm
	mul.f32 	%r4600, %r1053, %r7631;
	mul.f32 	%r4601, %r1053, %r7632;
	mul.f32 	%r4602, %r1053, %r7633;
	mul.f32 	%r4603, %r1053, %r7634;
	mul.f32 	%r4604, %r1053, %r7635;
	mul.f32 	%r4605, %r1053, %r7636;
	mul.f32 	%r4606, %r1053, %r7637;
	mul.f32 	%r4607, %r1053, %r7638;
	mul.f32 	%r4608, %r1053, %r7639;
	mul.f32 	%r4609, %r1053, %r7640;
	mul.f32 	%r4610, %r1053, %r7641;
	mul.f32 	%r4611, %r1053, %r7642;
	mul.f32 	%r4612, %r1053, %r7643;
	mul.f32 	%r4613, %r1053, %r7644;
	mul.f32 	%r4614, %r1053, %r7645;
	mul.f32 	%r4615, %r1053, %r7646;
	mul.f32 	%r4616, %r1053, %r7647;
	mul.f32 	%r4617, %r1053, %r7648;
	mul.f32 	%r4618, %r1053, %r7649;
	mul.f32 	%r4619, %r1053, %r7650;
	mul.f32 	%r4620, %r1053, %r7651;
	mul.f32 	%r4621, %r1053, %r7652;
	mul.f32 	%r4622, %r1053, %r7653;
	mul.f32 	%r4623, %r1053, %r7654;
	mul.f32 	%r4624, %r1053, %r7655;
	mul.f32 	%r4625, %r1053, %r7656;
	mul.f32 	%r4626, %r1053, %r7657;
	mul.f32 	%r4627, %r1053, %r7658;
	mul.f32 	%r4628, %r1053, %r7659;
	mul.f32 	%r4629, %r1053, %r7660;
	mul.f32 	%r4630, %r1053, %r7661;
	mul.f32 	%r4631, %r1053, %r7662;
	mul.f32 	%r4632, %r1053, %r7663;
	mul.f32 	%r4633, %r1053, %r7664;
	mul.f32 	%r4634, %r1053, %r7665;
	mul.f32 	%r4635, %r1053, %r7666;
	mul.f32 	%r4636, %r1053, %r7667;
	mul.f32 	%r4637, %r1053, %r7668;
	mul.f32 	%r4638, %r1053, %r7669;
	mul.f32 	%r4639, %r1053, %r7670;
	mul.f32 	%r4640, %r1053, %r7671;
	mul.f32 	%r4641, %r1053, %r7672;
	mul.f32 	%r4642, %r1053, %r7673;
	mul.f32 	%r4643, %r1053, %r7674;
	mul.f32 	%r4644, %r1053, %r7675;
	mul.f32 	%r4645, %r1053, %r7676;
	mul.f32 	%r4646, %r1053, %r7677;
	mul.f32 	%r4647, %r1053, %r7678;
	mul.f32 	%r4648, %r1053, %r7679;
	mul.f32 	%r4649, %r1053, %r7680;
	mul.f32 	%r4650, %r1053, %r7681;
	mul.f32 	%r4651, %r1053, %r7682;
	mul.f32 	%r4652, %r1053, %r7683;
	mul.f32 	%r4653, %r1053, %r7684;
	mul.f32 	%r4654, %r1053, %r7685;
	mul.f32 	%r4655, %r1053, %r7686;
	mul.f32 	%r4656, %r1053, %r7687;
	mul.f32 	%r4657, %r1053, %r7688;
	mul.f32 	%r4658, %r1053, %r7689;
	mul.f32 	%r4659, %r1053, %r7690;
	mul.f32 	%r4660, %r1053, %r7691;
	mul.f32 	%r4661, %r1053, %r7692;
	mul.f32 	%r4662, %r1053, %r7693;
	mul.f32 	%r4663, %r1053, %r7694;
	add.s64 	%rd530, %rd74, %rd513;
	add.s64 	%rd531, %rd74, %rd515;
	add.s64 	%rd532, %rd74, %rd517;
	add.s64 	%rd533, %rd74, %rd519;
	add.s64 	%rd534, %rd74, %rd521;
	add.s64 	%rd535, %rd74, %rd523;
	add.s64 	%rd536, %rd74, %rd525;
	add.s64 	%rd537, %rd74, %rd527;
	add.s64 	%rd487, %rd530, %rd529;
	add.s64 	%rd488, %rd531, %rd529;
	add.s64 	%rd489, %rd532, %rd529;
	add.s64 	%rd490, %rd533, %rd529;
	add.s64 	%rd491, %rd534, %rd529;
	add.s64 	%rd492, %rd535, %rd529;
	add.s64 	%rd493, %rd536, %rd529;
	add.s64 	%rd494, %rd537, %rd529;
	bar.sync 	0;
	cvt.rn.f16x2.f32 	%r4664, %r4613, %r4612;
	cvt.rn.f16x2.f32 	%r4665, %r4609, %r4608;
	cvt.rn.f16x2.f32 	%r4666, %r4605, %r4604;
	cvt.rn.f16x2.f32 	%r4667, %r4601, %r4600;
	st.shared.v4.b32 	[%r742], {%r4667, %r4666, %r4665, %r4664};
	cvt.rn.f16x2.f32 	%r4668, %r4615, %r4614;
	cvt.rn.f16x2.f32 	%r4669, %r4611, %r4610;
	cvt.rn.f16x2.f32 	%r4670, %r4607, %r4606;
	cvt.rn.f16x2.f32 	%r4671, %r4603, %r4602;
	st.shared.v4.b32 	[%r742+256], {%r4671, %r4670, %r4669, %r4668};
	cvt.rn.f16x2.f32 	%r4672, %r4629, %r4628;
	cvt.rn.f16x2.f32 	%r4673, %r4625, %r4624;
	cvt.rn.f16x2.f32 	%r4674, %r4621, %r4620;
	cvt.rn.f16x2.f32 	%r4675, %r4617, %r4616;
	st.shared.v4.b32 	[%r743], {%r4675, %r4674, %r4673, %r4672};
	cvt.rn.f16x2.f32 	%r4676, %r4631, %r4630;
	cvt.rn.f16x2.f32 	%r4677, %r4627, %r4626;
	cvt.rn.f16x2.f32 	%r4678, %r4623, %r4622;
	cvt.rn.f16x2.f32 	%r4679, %r4619, %r4618;
	st.shared.v4.b32 	[%r743+256], {%r4679, %r4678, %r4677, %r4676};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4422, %r4423, %r4424, %r4425}, [%r7354];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4426, %r4427, %r4428, %r4429}, [%r7359];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4430, %r4431, %r4432, %r4433}, [%r7364];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4434, %r4435, %r4436, %r4437}, [%r7369];
	// end inline asm
	bar.sync 	0;
	cvt.rn.f16x2.f32 	%r4680, %r4645, %r4644;
	cvt.rn.f16x2.f32 	%r4681, %r4641, %r4640;
	cvt.rn.f16x2.f32 	%r4682, %r4637, %r4636;
	cvt.rn.f16x2.f32 	%r4683, %r4633, %r4632;
	st.shared.v4.b32 	[%r742], {%r4683, %r4682, %r4681, %r4680};
	cvt.rn.f16x2.f32 	%r4684, %r4647, %r4646;
	cvt.rn.f16x2.f32 	%r4685, %r4643, %r4642;
	cvt.rn.f16x2.f32 	%r4686, %r4639, %r4638;
	cvt.rn.f16x2.f32 	%r4687, %r4635, %r4634;
	st.shared.v4.b32 	[%r742+256], {%r4687, %r4686, %r4685, %r4684};
	cvt.rn.f16x2.f32 	%r4688, %r4661, %r4660;
	cvt.rn.f16x2.f32 	%r4689, %r4657, %r4656;
	cvt.rn.f16x2.f32 	%r4690, %r4653, %r4652;
	cvt.rn.f16x2.f32 	%r4691, %r4649, %r4648;
	st.shared.v4.b32 	[%r743], {%r4691, %r4690, %r4689, %r4688};
	cvt.rn.f16x2.f32 	%r4692, %r4663, %r4662;
	cvt.rn.f16x2.f32 	%r4693, %r4659, %r4658;
	cvt.rn.f16x2.f32 	%r4694, %r4655, %r4654;
	cvt.rn.f16x2.f32 	%r4695, %r4651, %r4650;
	st.shared.v4.b32 	[%r743+256], {%r4695, %r4694, %r4693, %r4692};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4438, %r4439, %r4440, %r4441}, [%r7354];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4442, %r4443, %r4444, %r4445}, [%r7359];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4446, %r4447, %r4448, %r4449}, [%r7364];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4450, %r4451, %r4452, %r4453}, [%r7369];
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd487 + 0 ], { %r4422, %r4423, %r4424, %r4425 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd488 + 0 ], { %r4426, %r4427, %r4428, %r4429 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd489 + 0 ], { %r4430, %r4431, %r4432, %r4433 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd490 + 0 ], { %r4434, %r4435, %r4436, %r4437 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd491 + 0 ], { %r4438, %r4439, %r4440, %r4441 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd492 + 0 ], { %r4442, %r4443, %r4444, %r4445 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd493 + 0 ], { %r4446, %r4447, %r4448, %r4449 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd494 + 0 ], { %r4450, %r4451, %r4452, %r4453 };
	// end inline asm
	add.s64 	%rd538, %rd2, %rd515;
	add.s64 	%rd539, %rd2, %rd517;
	add.s64 	%rd540, %rd2, %rd519;
	add.s64 	%rd541, %rd2, %rd521;
	add.s64 	%rd542, %rd2, %rd523;
	add.s64 	%rd543, %rd2, %rd525;
	add.s64 	%rd544, %rd2, %rd527;
	add.s64 	%rd496, %rd538, %rd529;
	add.s64 	%rd497, %rd539, %rd529;
	add.s64 	%rd498, %rd540, %rd529;
	add.s64 	%rd499, %rd541, %rd529;
	add.s64 	%rd500, %rd542, %rd529;
	add.s64 	%rd501, %rd543, %rd529;
	add.s64 	%rd502, %rd544, %rd529;
	bar.sync 	0;
	// begin inline asm
	cp.async.cg.shared.global [ %r4454 + 0 ], [ %rd495 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4455 + 0 ], [ %rd496 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4456 + 0 ], [ %rd497 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4457 + 0 ], [ %rd498 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4458 + 0 ], [ %rd499 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4459 + 0 ], [ %rd500 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4460 + 0 ], [ %rd501 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4461 + 0 ], [ %rd502 + 0 ], 0x10, 0x10;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	add.s64 	%rd545, %rd3, %rd515;
	add.s64 	%rd546, %rd3, %rd517;
	add.s64 	%rd547, %rd3, %rd519;
	add.s64 	%rd548, %rd3, %rd521;
	add.s64 	%rd549, %rd3, %rd523;
	add.s64 	%rd550, %rd3, %rd525;
	add.s64 	%rd551, %rd3, %rd527;
	add.s64 	%rd504, %rd545, %rd529;
	add.s64 	%rd505, %rd546, %rd529;
	add.s64 	%rd506, %rd547, %rd529;
	add.s64 	%rd507, %rd548, %rd529;
	add.s64 	%rd508, %rd549, %rd529;
	add.s64 	%rd509, %rd550, %rd529;
	add.s64 	%rd510, %rd551, %rd529;
	// begin inline asm
	cp.async.cg.shared.global [ %r4462 + 0 ], [ %rd503 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4463 + 0 ], [ %rd504 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4464 + 0 ], [ %rd505 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4465 + 0 ], [ %rd506 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4466 + 0 ], [ %rd507 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4467 + 0 ], [ %rd508 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4468 + 0 ], [ %rd509 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r4469 + 0 ], [ %rd510 + 0 ], 0x10, 0x10;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	mul.wide.s32 	%rd552, %r348, 4;
	add.s64 	%rd511, %rd4, %rd552;
	shl.b32 	%r4696, %r6, 2;
	add.s32 	%r4470, %r1109, %r4696;
	// begin inline asm
	cp.async.ca.shared.global [ %r4470 + 0 ], [ %rd511 + 0 ], 0x4, 0x4;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	shl.b32 	%r4698, %r4, 1;
	add.s32 	%r4699, %r1109, %r4698;
	add.s32 	%r4700, %r4699, %r5;
	ld.shared.b32 	%r748, [%r4700];
	ld.shared.b32 	%r749, [%r4700+32];
	ld.shared.b32 	%r750, [%r4700+256];
	ld.shared.b32 	%r751, [%r4700+288];
	add.s64 	%rd512, %rd5, %rd552;
	bar.sync 	0;
	// begin inline asm
	cp.async.ca.shared.global [ %r4470 + 0 ], [ %rd512 + 0 ], 0x4, 0x4;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.b32 	%r752, [%r4700];
	ld.shared.b32 	%r753, [%r4700+32];
	ld.shared.b32 	%r754, [%r4700+256];
	ld.shared.b32 	%r755, [%r4700+288];
	add.s32 	%r4708, %r2788, %r9;
	add.s32 	%r757, %r2788, %r33;
	mad.lo.s32 	%r758, %r26, -504, %r757;
	add.s32 	%r759, %r2788, %r37;
	add.s32 	%r5802, %r1103, %r7832;
	add.s32 	%r5807, %r1103, %r7831;
	add.s32 	%r5812, %r1103, %r7830;
	add.s32 	%r5817, %r1103, %r7829;
	add.s32 	%r5822, %r1103, %r7828;
	add.s32 	%r5827, %r1103, %r7827;
	add.s32 	%r5832, %r1103, %r7826;
	add.s32 	%r5837, %r1103, %r7825;
	add.s32 	%r6168, %r1104, %r7832;
	add.s32 	%r6173, %r1104, %r7831;
	add.s32 	%r6178, %r1104, %r7830;
	add.s32 	%r6183, %r1104, %r7829;
	add.s32 	%r6188, %r1104, %r7828;
	add.s32 	%r6193, %r1104, %r7827;
	add.s32 	%r6198, %r1104, %r7826;
	add.s32 	%r6203, %r1104, %r7825;
	or.b64 	%rd565, %rd21, -4611685949699522560;
	add.s32 	%r4703, %r1103, 37376;
	bfe.u32 	%r4704, %r4703, 4, 14;
	cvt.u64.u32 	%rd553, %r4704;
	or.b64 	%rd566, %rd553, -4611685949699522560;
	or.b64 	%rd567, %rd645, -4611685949699522560;
	add.s32 	%r4705, %r1103, 38400;
	bfe.u32 	%r4706, %r4705, 4, 14;
	cvt.u64.u32 	%rd554, %r4706;
	or.b64 	%rd568, %rd554, -4611685949699522560;
	add.s32 	%r776, %r2375, %r31;
	mov.b32 	%r7963, 0f00000000;
	mov.b32 	%r4929, 0;
	mov.b32 	%r7897, %r4929;
	mov.b32 	%r7964, %r7963;
	mov.b32 	%r7965, %r7963;
	mov.b32 	%r7966, %r7963;
	mov.b32 	%r7967, %r7963;
	mov.b32 	%r7968, %r7963;
	mov.b32 	%r7969, %r7963;
	mov.b32 	%r7970, %r7963;
	mov.b32 	%r7971, %r7963;
	mov.b32 	%r7972, %r7963;
	mov.b32 	%r7973, %r7963;
	mov.b32 	%r7974, %r7963;
	mov.b32 	%r7975, %r7963;
	mov.b32 	%r7976, %r7963;
	mov.b32 	%r7977, %r7963;
	mov.b32 	%r7978, %r7963;
	mov.b32 	%r7979, %r7963;
	mov.b32 	%r7980, %r7963;
	mov.b32 	%r7981, %r7963;
	mov.b32 	%r7982, %r7963;
	mov.b32 	%r7983, %r7963;
	mov.b32 	%r7984, %r7963;
	mov.b32 	%r7985, %r7963;
	mov.b32 	%r7986, %r7963;
	mov.b32 	%r7987, %r7963;
	mov.b32 	%r7988, %r7963;
	mov.b32 	%r7989, %r7963;
	mov.b32 	%r7990, %r7963;
	mov.b32 	%r7991, %r7963;
	mov.b32 	%r7992, %r7963;
	mov.b32 	%r7993, %r7963;
	mov.b32 	%r7994, %r7963;
	mov.b32 	%r7995, %r7963;
	mov.b32 	%r7996, %r7963;
	mov.b32 	%r7997, %r7963;
	mov.b32 	%r7998, %r7963;
	mov.b32 	%r7999, %r7963;
	mov.b32 	%r8000, %r7963;
	mov.b32 	%r8001, %r7963;
	mov.b32 	%r8002, %r7963;
	mov.b32 	%r8003, %r7963;
	mov.b32 	%r8004, %r7963;
	mov.b32 	%r8005, %r7963;
	mov.b32 	%r8006, %r7963;
	mov.b32 	%r8007, %r7963;
	mov.b32 	%r8008, %r7963;
	mov.b32 	%r8009, %r7963;
	mov.b32 	%r8010, %r7963;
	mov.b32 	%r8011, %r7963;
	mov.b32 	%r8012, %r7963;
	mov.b32 	%r8013, %r7963;
	mov.b32 	%r8014, %r7963;
	mov.b32 	%r8015, %r7963;
	mov.b32 	%r8016, %r7963;
	mov.b32 	%r8017, %r7963;
	mov.b32 	%r8018, %r7963;
	mov.b32 	%r8019, %r7963;
	mov.b32 	%r8020, %r7963;
	mov.b32 	%r8021, %r7963;
	mov.b32 	%r8022, %r7963;
	mov.b32 	%r8023, %r7963;
	mov.b32 	%r8024, %r7963;
	mov.b32 	%r8025, %r7963;
	mov.b32 	%r8026, %r7963;
$L__BB0_8:                              // %__nv_exp2f.exit344
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd556, %rd331, %rd678;
	add.s64 	%rd555, %rd330, %rd678;
	bar.sync 	0;
	// begin inline asm
	cp.async.cg.shared.global [ %r5794 + 0 ], [ %rd555 + 0 ], 0x10, 0x10;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r5423, %r5424, %r5425, %r5426}, [%r34];
	ld.shared.v4.b32 	{%r5427, %r5428, %r5429, %r5430}, [%r34+128];
	ld.shared.v4.b32 	{%r5431, %r5432, %r5433, %r5434}, [%r34+256];
	ld.shared.v4.b32 	{%r5435, %r5436, %r5437, %r5438}, [%r34+384];
	ld.shared.v4.b32 	{%r5439, %r5440, %r5441, %r5442}, [%r34+16];
	ld.shared.v4.b32 	{%r5443, %r5444, %r5445, %r5446}, [%r34+144];
	ld.shared.v4.b32 	{%r5447, %r5448, %r5449, %r5450}, [%r34+272];
	ld.shared.v4.b32 	{%r5451, %r5452, %r5453, %r5454}, [%r34+400];
	ld.shared.v4.b32 	{%r5455, %r5456, %r5457, %r5458}, [%r34+32];
	ld.shared.v4.b32 	{%r5459, %r5460, %r5461, %r5462}, [%r34+160];
	ld.shared.v4.b32 	{%r5463, %r5464, %r5465, %r5466}, [%r34+288];
	ld.shared.v4.b32 	{%r5467, %r5468, %r5469, %r5470}, [%r34+416];
	ld.shared.v4.b32 	{%r5471, %r5472, %r5473, %r5474}, [%r34+48];
	ld.shared.v4.b32 	{%r5475, %r5476, %r5477, %r5478}, [%r34+176];
	ld.shared.v4.b32 	{%r5479, %r5480, %r5481, %r5482}, [%r34+304];
	ld.shared.v4.b32 	{%r5483, %r5484, %r5485, %r5486}, [%r34+432];
	ld.shared.v4.b32 	{%r5487, %r5488, %r5489, %r5490}, [%r34+64];
	ld.shared.v4.b32 	{%r5491, %r5492, %r5493, %r5494}, [%r34+192];
	ld.shared.v4.b32 	{%r5495, %r5496, %r5497, %r5498}, [%r34+320];
	ld.shared.v4.b32 	{%r5499, %r5500, %r5501, %r5502}, [%r34+448];
	ld.shared.v4.b32 	{%r5503, %r5504, %r5505, %r5506}, [%r34+80];
	ld.shared.v4.b32 	{%r5507, %r5508, %r5509, %r5510}, [%r34+208];
	ld.shared.v4.b32 	{%r5511, %r5512, %r5513, %r5514}, [%r34+336];
	ld.shared.v4.b32 	{%r5515, %r5516, %r5517, %r5518}, [%r34+464];
	ld.shared.v4.b32 	{%r5519, %r5520, %r5521, %r5522}, [%r34+96];
	ld.shared.v4.b32 	{%r5523, %r5524, %r5525, %r5526}, [%r34+224];
	ld.shared.v4.b32 	{%r5527, %r5528, %r5529, %r5530}, [%r34+352];
	ld.shared.v4.b32 	{%r5531, %r5532, %r5533, %r5534}, [%r34+480];
	ld.shared.v4.b32 	{%r5535, %r5536, %r5537, %r5538}, [%r34+112];
	ld.shared.v4.b32 	{%r5539, %r5540, %r5541, %r5542}, [%r34+240];
	ld.shared.v4.b32 	{%r5543, %r5544, %r5545, %r5546}, [%r34+368];
	ld.shared.v4.b32 	{%r5547, %r5548, %r5549, %r5550}, [%r34+496];
	mov.b32 	{%rs561, %rs562}, %r5427;
	mov.b32 	{%rs563, %rs564}, %r5423;
	mov.b32 	{%rs565, %rs566}, %r5431;
	mov.b32 	{%rs567, %rs568}, %r5435;
	st.shared.v4.b16 	[%r36], {%rs563, %rs561, %rs565, %rs567};
	st.shared.v4.b16 	[%r36+32], {%rs564, %rs562, %rs566, %rs568};
	mov.b32 	{%rs569, %rs570}, %r5428;
	mov.b32 	{%rs571, %rs572}, %r5424;
	mov.b32 	{%rs573, %rs574}, %r5432;
	mov.b32 	{%rs575, %rs576}, %r5436;
	st.shared.v4.b16 	[%r36+64], {%rs571, %rs569, %rs573, %rs575};
	st.shared.v4.b16 	[%r36+96], {%rs572, %rs570, %rs574, %rs576};
	mov.b32 	{%rs577, %rs578}, %r5443;
	mov.b32 	{%rs579, %rs580}, %r5439;
	mov.b32 	{%rs581, %rs582}, %r5447;
	mov.b32 	{%rs583, %rs584}, %r5451;
	st.shared.v4.b16 	[%r36+256], {%rs579, %rs577, %rs581, %rs583};
	st.shared.v4.b16 	[%r36+288], {%rs580, %rs578, %rs582, %rs584};
	mov.b32 	{%rs585, %rs586}, %r5444;
	mov.b32 	{%rs587, %rs588}, %r5440;
	mov.b32 	{%rs589, %rs590}, %r5448;
	mov.b32 	{%rs591, %rs592}, %r5452;
	st.shared.v4.b16 	[%r36+320], {%rs587, %rs585, %rs589, %rs591};
	st.shared.v4.b16 	[%r36+352], {%rs588, %rs586, %rs590, %rs592};
	mov.b32 	{%rs593, %rs594}, %r5459;
	mov.b32 	{%rs595, %rs596}, %r5455;
	mov.b32 	{%rs597, %rs598}, %r5463;
	mov.b32 	{%rs599, %rs600}, %r5467;
	st.shared.v4.b16 	[%r36+512], {%rs595, %rs593, %rs597, %rs599};
	st.shared.v4.b16 	[%r36+544], {%rs596, %rs594, %rs598, %rs600};
	mov.b32 	{%rs601, %rs602}, %r5460;
	mov.b32 	{%rs603, %rs604}, %r5456;
	mov.b32 	{%rs605, %rs606}, %r5464;
	mov.b32 	{%rs607, %rs608}, %r5468;
	st.shared.v4.b16 	[%r36+576], {%rs603, %rs601, %rs605, %rs607};
	st.shared.v4.b16 	[%r36+608], {%rs604, %rs602, %rs606, %rs608};
	mov.b32 	{%rs609, %rs610}, %r5475;
	mov.b32 	{%rs611, %rs612}, %r5471;
	mov.b32 	{%rs613, %rs614}, %r5479;
	mov.b32 	{%rs615, %rs616}, %r5483;
	st.shared.v4.b16 	[%r36+768], {%rs611, %rs609, %rs613, %rs615};
	st.shared.v4.b16 	[%r36+800], {%rs612, %rs610, %rs614, %rs616};
	mov.b32 	{%rs617, %rs618}, %r5476;
	mov.b32 	{%rs619, %rs620}, %r5472;
	mov.b32 	{%rs621, %rs622}, %r5480;
	mov.b32 	{%rs623, %rs624}, %r5484;
	st.shared.v4.b16 	[%r36+832], {%rs619, %rs617, %rs621, %rs623};
	st.shared.v4.b16 	[%r36+864], {%rs620, %rs618, %rs622, %rs624};
	mov.b32 	{%rs625, %rs626}, %r5491;
	mov.b32 	{%rs627, %rs628}, %r5487;
	mov.b32 	{%rs629, %rs630}, %r5495;
	mov.b32 	{%rs631, %rs632}, %r5499;
	st.shared.v4.b16 	[%r36+1024], {%rs627, %rs625, %rs629, %rs631};
	st.shared.v4.b16 	[%r36+1056], {%rs628, %rs626, %rs630, %rs632};
	mov.b32 	{%rs633, %rs634}, %r5492;
	mov.b32 	{%rs635, %rs636}, %r5488;
	mov.b32 	{%rs637, %rs638}, %r5496;
	mov.b32 	{%rs639, %rs640}, %r5500;
	st.shared.v4.b16 	[%r36+1088], {%rs635, %rs633, %rs637, %rs639};
	st.shared.v4.b16 	[%r36+1120], {%rs636, %rs634, %rs638, %rs640};
	mov.b32 	{%rs641, %rs642}, %r5507;
	mov.b32 	{%rs643, %rs644}, %r5503;
	mov.b32 	{%rs645, %rs646}, %r5511;
	mov.b32 	{%rs647, %rs648}, %r5515;
	st.shared.v4.b16 	[%r36+1280], {%rs643, %rs641, %rs645, %rs647};
	st.shared.v4.b16 	[%r36+1312], {%rs644, %rs642, %rs646, %rs648};
	mov.b32 	{%rs649, %rs650}, %r5508;
	mov.b32 	{%rs651, %rs652}, %r5504;
	mov.b32 	{%rs653, %rs654}, %r5512;
	mov.b32 	{%rs655, %rs656}, %r5516;
	st.shared.v4.b16 	[%r36+1344], {%rs651, %rs649, %rs653, %rs655};
	st.shared.v4.b16 	[%r36+1376], {%rs652, %rs650, %rs654, %rs656};
	mov.b32 	{%rs657, %rs658}, %r5523;
	mov.b32 	{%rs659, %rs660}, %r5519;
	mov.b32 	{%rs661, %rs662}, %r5527;
	mov.b32 	{%rs663, %rs664}, %r5531;
	st.shared.v4.b16 	[%r36+1536], {%rs659, %rs657, %rs661, %rs663};
	st.shared.v4.b16 	[%r36+1568], {%rs660, %rs658, %rs662, %rs664};
	mov.b32 	{%rs665, %rs666}, %r5524;
	mov.b32 	{%rs667, %rs668}, %r5520;
	mov.b32 	{%rs669, %rs670}, %r5528;
	mov.b32 	{%rs671, %rs672}, %r5532;
	st.shared.v4.b16 	[%r36+1600], {%rs667, %rs665, %rs669, %rs671};
	st.shared.v4.b16 	[%r36+1632], {%rs668, %rs666, %rs670, %rs672};
	mov.b32 	{%rs673, %rs674}, %r5539;
	mov.b32 	{%rs675, %rs676}, %r5535;
	mov.b32 	{%rs677, %rs678}, %r5543;
	mov.b32 	{%rs679, %rs680}, %r5547;
	st.shared.v4.b16 	[%r36+1792], {%rs675, %rs673, %rs677, %rs679};
	st.shared.v4.b16 	[%r36+1824], {%rs676, %rs674, %rs678, %rs680};
	mov.b32 	{%rs681, %rs682}, %r5540;
	mov.b32 	{%rs683, %rs684}, %r5536;
	mov.b32 	{%rs685, %rs686}, %r5544;
	mov.b32 	{%rs687, %rs688}, %r5548;
	st.shared.v4.b16 	[%r36+1856], {%rs683, %rs681, %rs685, %rs687};
	st.shared.v4.b16 	[%r36+1888], {%rs684, %rs682, %rs686, %rs688};
	mov.b32 	{%rs689, %rs690}, %r5429;
	mov.b32 	{%rs691, %rs692}, %r5425;
	mov.b32 	{%rs693, %rs694}, %r5433;
	mov.b32 	{%rs695, %rs696}, %r5437;
	st.shared.v4.b16 	[%r38+128], {%rs691, %rs689, %rs693, %rs695};
	st.shared.v4.b16 	[%r38+160], {%rs692, %rs690, %rs694, %rs696};
	mov.b32 	{%rs697, %rs698}, %r5430;
	mov.b32 	{%rs699, %rs700}, %r5426;
	mov.b32 	{%rs701, %rs702}, %r5434;
	mov.b32 	{%rs703, %rs704}, %r5438;
	st.shared.v4.b16 	[%r38+192], {%rs699, %rs697, %rs701, %rs703};
	st.shared.v4.b16 	[%r38+224], {%rs700, %rs698, %rs702, %rs704};
	mov.b32 	{%rs705, %rs706}, %r5445;
	mov.b32 	{%rs707, %rs708}, %r5441;
	mov.b32 	{%rs709, %rs710}, %r5449;
	mov.b32 	{%rs711, %rs712}, %r5453;
	st.shared.v4.b16 	[%r38+384], {%rs707, %rs705, %rs709, %rs711};
	st.shared.v4.b16 	[%r38+416], {%rs708, %rs706, %rs710, %rs712};
	mov.b32 	{%rs713, %rs714}, %r5446;
	mov.b32 	{%rs715, %rs716}, %r5442;
	mov.b32 	{%rs717, %rs718}, %r5450;
	mov.b32 	{%rs719, %rs720}, %r5454;
	st.shared.v4.b16 	[%r38+448], {%rs715, %rs713, %rs717, %rs719};
	st.shared.v4.b16 	[%r38+480], {%rs716, %rs714, %rs718, %rs720};
	mov.b32 	{%rs721, %rs722}, %r5461;
	mov.b32 	{%rs723, %rs724}, %r5457;
	mov.b32 	{%rs725, %rs726}, %r5465;
	mov.b32 	{%rs727, %rs728}, %r5469;
	st.shared.v4.b16 	[%r38+640], {%rs723, %rs721, %rs725, %rs727};
	st.shared.v4.b16 	[%r38+672], {%rs724, %rs722, %rs726, %rs728};
	mov.b32 	{%rs729, %rs730}, %r5462;
	mov.b32 	{%rs731, %rs732}, %r5458;
	mov.b32 	{%rs733, %rs734}, %r5466;
	mov.b32 	{%rs735, %rs736}, %r5470;
	st.shared.v4.b16 	[%r38+704], {%rs731, %rs729, %rs733, %rs735};
	st.shared.v4.b16 	[%r38+736], {%rs732, %rs730, %rs734, %rs736};
	mov.b32 	{%rs737, %rs738}, %r5477;
	mov.b32 	{%rs739, %rs740}, %r5473;
	mov.b32 	{%rs741, %rs742}, %r5481;
	mov.b32 	{%rs743, %rs744}, %r5485;
	st.shared.v4.b16 	[%r38+896], {%rs739, %rs737, %rs741, %rs743};
	st.shared.v4.b16 	[%r38+928], {%rs740, %rs738, %rs742, %rs744};
	mov.b32 	{%rs745, %rs746}, %r5478;
	mov.b32 	{%rs747, %rs748}, %r5474;
	mov.b32 	{%rs749, %rs750}, %r5482;
	mov.b32 	{%rs751, %rs752}, %r5486;
	st.shared.v4.b16 	[%r38+960], {%rs747, %rs745, %rs749, %rs751};
	st.shared.v4.b16 	[%r38+992], {%rs748, %rs746, %rs750, %rs752};
	mov.b32 	{%rs753, %rs754}, %r5493;
	mov.b32 	{%rs755, %rs756}, %r5489;
	mov.b32 	{%rs757, %rs758}, %r5497;
	mov.b32 	{%rs759, %rs760}, %r5501;
	st.shared.v4.b16 	[%r38+1152], {%rs755, %rs753, %rs757, %rs759};
	st.shared.v4.b16 	[%r38+1184], {%rs756, %rs754, %rs758, %rs760};
	mov.b32 	{%rs761, %rs762}, %r5494;
	mov.b32 	{%rs763, %rs764}, %r5490;
	mov.b32 	{%rs765, %rs766}, %r5498;
	mov.b32 	{%rs767, %rs768}, %r5502;
	st.shared.v4.b16 	[%r38+1216], {%rs763, %rs761, %rs765, %rs767};
	st.shared.v4.b16 	[%r38+1248], {%rs764, %rs762, %rs766, %rs768};
	mov.b32 	{%rs769, %rs770}, %r5509;
	mov.b32 	{%rs771, %rs772}, %r5505;
	mov.b32 	{%rs773, %rs774}, %r5513;
	mov.b32 	{%rs775, %rs776}, %r5517;
	st.shared.v4.b16 	[%r38+1408], {%rs771, %rs769, %rs773, %rs775};
	st.shared.v4.b16 	[%r38+1440], {%rs772, %rs770, %rs774, %rs776};
	mov.b32 	{%rs777, %rs778}, %r5510;
	mov.b32 	{%rs779, %rs780}, %r5506;
	mov.b32 	{%rs781, %rs782}, %r5514;
	mov.b32 	{%rs783, %rs784}, %r5518;
	st.shared.v4.b16 	[%r38+1472], {%rs779, %rs777, %rs781, %rs783};
	st.shared.v4.b16 	[%r38+1504], {%rs780, %rs778, %rs782, %rs784};
	mov.b32 	{%rs785, %rs786}, %r5525;
	mov.b32 	{%rs787, %rs788}, %r5521;
	mov.b32 	{%rs789, %rs790}, %r5529;
	mov.b32 	{%rs791, %rs792}, %r5533;
	st.shared.v4.b16 	[%r38+1664], {%rs787, %rs785, %rs789, %rs791};
	st.shared.v4.b16 	[%r38+1696], {%rs788, %rs786, %rs790, %rs792};
	mov.b32 	{%rs793, %rs794}, %r5526;
	mov.b32 	{%rs795, %rs796}, %r5522;
	mov.b32 	{%rs797, %rs798}, %r5530;
	mov.b32 	{%rs799, %rs800}, %r5534;
	st.shared.v4.b16 	[%r38+1728], {%rs795, %rs793, %rs797, %rs799};
	st.shared.v4.b16 	[%r38+1760], {%rs796, %rs794, %rs798, %rs800};
	mov.b32 	{%rs801, %rs802}, %r5541;
	mov.b32 	{%rs803, %rs804}, %r5537;
	mov.b32 	{%rs805, %rs806}, %r5545;
	mov.b32 	{%rs807, %rs808}, %r5549;
	st.shared.v4.b16 	[%r38+1920], {%rs803, %rs801, %rs805, %rs807};
	st.shared.v4.b16 	[%r38+1952], {%rs804, %rs802, %rs806, %rs808};
	mov.b32 	{%rs809, %rs810}, %r5542;
	mov.b32 	{%rs811, %rs812}, %r5538;
	mov.b32 	{%rs813, %rs814}, %r5546;
	mov.b32 	{%rs815, %rs816}, %r5550;
	st.shared.v4.b16 	[%r38+1984], {%rs811, %rs809, %rs813, %rs815};
	st.shared.v4.b16 	[%r38+2016], {%rs812, %rs810, %rs814, %rs816};
	ld.shared.b16 	%rs817, [%r40];
	ld.shared.b16 	%rs818, [%r40+16];
	ld.shared.b16 	%rs819, [%r40+32];
	ld.shared.b16 	%rs820, [%r40+48];
	ld.shared.b16 	%rs821, [%r40+64];
	ld.shared.b16 	%rs822, [%r40+80];
	ld.shared.b16 	%rs823, [%r40+96];
	ld.shared.b16 	%rs824, [%r40+112];
	bar.sync 	0;
	st.shared.b16 	[%r42], %rs817;
	st.shared.b16 	[%r42+256], %rs818;
	st.shared.b16 	[%r42+512], %rs819;
	st.shared.b16 	[%r42+768], %rs820;
	st.shared.b16 	[%r42+1024], %rs821;
	st.shared.b16 	[%r42+1280], %rs822;
	st.shared.b16 	[%r42+1536], %rs823;
	st.shared.b16 	[%r42+1792], %rs824;
	// begin inline asm
	cp.async.cg.shared.global [ %r4708 + 0 ], [ %rd556 + 0 ], 0x10, 0x10;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r5551, %r5552, %r5553, %r5554}, [%r757];
	ld.shared.v4.b32 	{%r5555, %r5556, %r5557, %r5558}, [%r757+128];
	ld.shared.v4.b32 	{%r5559, %r5560, %r5561, %r5562}, [%r757+256];
	ld.shared.v4.b32 	{%r5563, %r5564, %r5565, %r5566}, [%r757+384];
	ld.shared.v4.b32 	{%r5567, %r5568, %r5569, %r5570}, [%r757+16];
	ld.shared.v4.b32 	{%r5571, %r5572, %r5573, %r5574}, [%r757+144];
	ld.shared.v4.b32 	{%r5575, %r5576, %r5577, %r5578}, [%r757+272];
	ld.shared.v4.b32 	{%r5579, %r5580, %r5581, %r5582}, [%r757+400];
	ld.shared.v4.b32 	{%r5583, %r5584, %r5585, %r5586}, [%r757+32];
	ld.shared.v4.b32 	{%r5587, %r5588, %r5589, %r5590}, [%r757+160];
	ld.shared.v4.b32 	{%r5591, %r5592, %r5593, %r5594}, [%r757+288];
	ld.shared.v4.b32 	{%r5595, %r5596, %r5597, %r5598}, [%r757+416];
	ld.shared.v4.b32 	{%r5599, %r5600, %r5601, %r5602}, [%r757+48];
	ld.shared.v4.b32 	{%r5603, %r5604, %r5605, %r5606}, [%r757+176];
	ld.shared.v4.b32 	{%r5607, %r5608, %r5609, %r5610}, [%r757+304];
	ld.shared.v4.b32 	{%r5611, %r5612, %r5613, %r5614}, [%r757+432];
	ld.shared.v4.b32 	{%r5615, %r5616, %r5617, %r5618}, [%r757+64];
	ld.shared.v4.b32 	{%r5619, %r5620, %r5621, %r5622}, [%r757+192];
	ld.shared.v4.b32 	{%r5623, %r5624, %r5625, %r5626}, [%r757+320];
	ld.shared.v4.b32 	{%r5627, %r5628, %r5629, %r5630}, [%r757+448];
	ld.shared.v4.b32 	{%r5631, %r5632, %r5633, %r5634}, [%r757+80];
	ld.shared.v4.b32 	{%r5635, %r5636, %r5637, %r5638}, [%r757+208];
	ld.shared.v4.b32 	{%r5639, %r5640, %r5641, %r5642}, [%r757+336];
	ld.shared.v4.b32 	{%r5643, %r5644, %r5645, %r5646}, [%r757+464];
	ld.shared.v4.b32 	{%r5647, %r5648, %r5649, %r5650}, [%r757+96];
	ld.shared.v4.b32 	{%r5651, %r5652, %r5653, %r5654}, [%r757+224];
	ld.shared.v4.b32 	{%r5655, %r5656, %r5657, %r5658}, [%r757+352];
	ld.shared.v4.b32 	{%r5659, %r5660, %r5661, %r5662}, [%r757+480];
	ld.shared.v4.b32 	{%r5663, %r5664, %r5665, %r5666}, [%r757+112];
	ld.shared.v4.b32 	{%r5667, %r5668, %r5669, %r5670}, [%r757+240];
	ld.shared.v4.b32 	{%r5671, %r5672, %r5673, %r5674}, [%r757+368];
	ld.shared.v4.b32 	{%r5675, %r5676, %r5677, %r5678}, [%r757+496];
	bar.sync 	0;
	mov.b32 	{%rs825, %rs826}, %r5555;
	mov.b32 	{%rs827, %rs828}, %r5551;
	mov.b32 	{%rs829, %rs830}, %r5559;
	mov.b32 	{%rs831, %rs832}, %r5563;
	st.shared.v4.b16 	[%r45], {%rs827, %rs825, %rs829, %rs831};
	st.shared.v4.b16 	[%r45+32], {%rs828, %rs826, %rs830, %rs832};
	mov.b32 	{%rs833, %rs834}, %r5556;
	mov.b32 	{%rs835, %rs836}, %r5552;
	mov.b32 	{%rs837, %rs838}, %r5560;
	mov.b32 	{%rs839, %rs840}, %r5564;
	st.shared.v4.b16 	[%r758+64], {%rs835, %rs833, %rs837, %rs839};
	st.shared.v4.b16 	[%r758+96], {%rs836, %rs834, %rs838, %rs840};
	mov.b32 	{%rs841, %rs842}, %r5571;
	mov.b32 	{%rs843, %rs844}, %r5567;
	mov.b32 	{%rs845, %rs846}, %r5575;
	mov.b32 	{%rs847, %rs848}, %r5579;
	st.shared.v4.b16 	[%r758+256], {%rs843, %rs841, %rs845, %rs847};
	st.shared.v4.b16 	[%r758+288], {%rs844, %rs842, %rs846, %rs848};
	mov.b32 	{%rs849, %rs850}, %r5572;
	mov.b32 	{%rs851, %rs852}, %r5568;
	mov.b32 	{%rs853, %rs854}, %r5576;
	mov.b32 	{%rs855, %rs856}, %r5580;
	st.shared.v4.b16 	[%r758+320], {%rs851, %rs849, %rs853, %rs855};
	st.shared.v4.b16 	[%r758+352], {%rs852, %rs850, %rs854, %rs856};
	mov.b32 	{%rs857, %rs858}, %r5587;
	mov.b32 	{%rs859, %rs860}, %r5583;
	mov.b32 	{%rs861, %rs862}, %r5591;
	mov.b32 	{%rs863, %rs864}, %r5595;
	st.shared.v4.b16 	[%r758+512], {%rs859, %rs857, %rs861, %rs863};
	st.shared.v4.b16 	[%r758+544], {%rs860, %rs858, %rs862, %rs864};
	mov.b32 	{%rs865, %rs866}, %r5588;
	mov.b32 	{%rs867, %rs868}, %r5584;
	mov.b32 	{%rs869, %rs870}, %r5592;
	mov.b32 	{%rs871, %rs872}, %r5596;
	st.shared.v4.b16 	[%r758+576], {%rs867, %rs865, %rs869, %rs871};
	st.shared.v4.b16 	[%r758+608], {%rs868, %rs866, %rs870, %rs872};
	mov.b32 	{%rs873, %rs874}, %r5603;
	mov.b32 	{%rs875, %rs876}, %r5599;
	mov.b32 	{%rs877, %rs878}, %r5607;
	mov.b32 	{%rs879, %rs880}, %r5611;
	st.shared.v4.b16 	[%r758+768], {%rs875, %rs873, %rs877, %rs879};
	st.shared.v4.b16 	[%r758+800], {%rs876, %rs874, %rs878, %rs880};
	mov.b32 	{%rs881, %rs882}, %r5604;
	mov.b32 	{%rs883, %rs884}, %r5600;
	mov.b32 	{%rs885, %rs886}, %r5608;
	mov.b32 	{%rs887, %rs888}, %r5612;
	st.shared.v4.b16 	[%r758+832], {%rs883, %rs881, %rs885, %rs887};
	st.shared.v4.b16 	[%r758+864], {%rs884, %rs882, %rs886, %rs888};
	mov.b32 	{%rs889, %rs890}, %r5619;
	mov.b32 	{%rs891, %rs892}, %r5615;
	mov.b32 	{%rs893, %rs894}, %r5623;
	mov.b32 	{%rs895, %rs896}, %r5627;
	st.shared.v4.b16 	[%r758+1024], {%rs891, %rs889, %rs893, %rs895};
	st.shared.v4.b16 	[%r758+1056], {%rs892, %rs890, %rs894, %rs896};
	mov.b32 	{%rs897, %rs898}, %r5620;
	mov.b32 	{%rs899, %rs900}, %r5616;
	mov.b32 	{%rs901, %rs902}, %r5624;
	mov.b32 	{%rs903, %rs904}, %r5628;
	st.shared.v4.b16 	[%r758+1088], {%rs899, %rs897, %rs901, %rs903};
	st.shared.v4.b16 	[%r758+1120], {%rs900, %rs898, %rs902, %rs904};
	mov.b32 	{%rs905, %rs906}, %r5635;
	mov.b32 	{%rs907, %rs908}, %r5631;
	mov.b32 	{%rs909, %rs910}, %r5639;
	mov.b32 	{%rs911, %rs912}, %r5643;
	st.shared.v4.b16 	[%r758+1280], {%rs907, %rs905, %rs909, %rs911};
	st.shared.v4.b16 	[%r758+1312], {%rs908, %rs906, %rs910, %rs912};
	mov.b32 	{%rs913, %rs914}, %r5636;
	mov.b32 	{%rs915, %rs916}, %r5632;
	mov.b32 	{%rs917, %rs918}, %r5640;
	mov.b32 	{%rs919, %rs920}, %r5644;
	st.shared.v4.b16 	[%r758+1344], {%rs915, %rs913, %rs917, %rs919};
	st.shared.v4.b16 	[%r758+1376], {%rs916, %rs914, %rs918, %rs920};
	mov.b32 	{%rs921, %rs922}, %r5651;
	mov.b32 	{%rs923, %rs924}, %r5647;
	mov.b32 	{%rs925, %rs926}, %r5655;
	mov.b32 	{%rs927, %rs928}, %r5659;
	st.shared.v4.b16 	[%r758+1536], {%rs923, %rs921, %rs925, %rs927};
	st.shared.v4.b16 	[%r758+1568], {%rs924, %rs922, %rs926, %rs928};
	mov.b32 	{%rs929, %rs930}, %r5652;
	mov.b32 	{%rs931, %rs932}, %r5648;
	mov.b32 	{%rs933, %rs934}, %r5656;
	mov.b32 	{%rs935, %rs936}, %r5660;
	st.shared.v4.b16 	[%r758+1600], {%rs931, %rs929, %rs933, %rs935};
	st.shared.v4.b16 	[%r758+1632], {%rs932, %rs930, %rs934, %rs936};
	mov.b32 	{%rs937, %rs938}, %r5667;
	mov.b32 	{%rs939, %rs940}, %r5663;
	mov.b32 	{%rs941, %rs942}, %r5671;
	mov.b32 	{%rs943, %rs944}, %r5675;
	st.shared.v4.b16 	[%r758+1792], {%rs939, %rs937, %rs941, %rs943};
	st.shared.v4.b16 	[%r758+1824], {%rs940, %rs938, %rs942, %rs944};
	mov.b32 	{%rs945, %rs946}, %r5668;
	mov.b32 	{%rs947, %rs948}, %r5664;
	mov.b32 	{%rs949, %rs950}, %r5672;
	mov.b32 	{%rs951, %rs952}, %r5676;
	st.shared.v4.b16 	[%r758+1856], {%rs947, %rs945, %rs949, %rs951};
	st.shared.v4.b16 	[%r758+1888], {%rs948, %rs946, %rs950, %rs952};
	mov.b32 	{%rs953, %rs954}, %r5557;
	mov.b32 	{%rs955, %rs956}, %r5553;
	mov.b32 	{%rs957, %rs958}, %r5561;
	mov.b32 	{%rs959, %rs960}, %r5565;
	st.shared.v4.b16 	[%r759+128], {%rs955, %rs953, %rs957, %rs959};
	st.shared.v4.b16 	[%r759+160], {%rs956, %rs954, %rs958, %rs960};
	mov.b32 	{%rs961, %rs962}, %r5558;
	mov.b32 	{%rs963, %rs964}, %r5554;
	mov.b32 	{%rs965, %rs966}, %r5562;
	mov.b32 	{%rs967, %rs968}, %r5566;
	st.shared.v4.b16 	[%r759+192], {%rs963, %rs961, %rs965, %rs967};
	st.shared.v4.b16 	[%r759+224], {%rs964, %rs962, %rs966, %rs968};
	mov.b32 	{%rs969, %rs970}, %r5573;
	mov.b32 	{%rs971, %rs972}, %r5569;
	mov.b32 	{%rs973, %rs974}, %r5577;
	mov.b32 	{%rs975, %rs976}, %r5581;
	st.shared.v4.b16 	[%r759+384], {%rs971, %rs969, %rs973, %rs975};
	st.shared.v4.b16 	[%r759+416], {%rs972, %rs970, %rs974, %rs976};
	mov.b32 	{%rs977, %rs978}, %r5574;
	mov.b32 	{%rs979, %rs980}, %r5570;
	mov.b32 	{%rs981, %rs982}, %r5578;
	mov.b32 	{%rs983, %rs984}, %r5582;
	st.shared.v4.b16 	[%r759+448], {%rs979, %rs977, %rs981, %rs983};
	st.shared.v4.b16 	[%r759+480], {%rs980, %rs978, %rs982, %rs984};
	mov.b32 	{%rs985, %rs986}, %r5589;
	mov.b32 	{%rs987, %rs988}, %r5585;
	mov.b32 	{%rs989, %rs990}, %r5593;
	mov.b32 	{%rs991, %rs992}, %r5597;
	st.shared.v4.b16 	[%r759+640], {%rs987, %rs985, %rs989, %rs991};
	st.shared.v4.b16 	[%r759+672], {%rs988, %rs986, %rs990, %rs992};
	mov.b32 	{%rs993, %rs994}, %r5590;
	mov.b32 	{%rs995, %rs996}, %r5586;
	mov.b32 	{%rs997, %rs998}, %r5594;
	mov.b32 	{%rs999, %rs1000}, %r5598;
	st.shared.v4.b16 	[%r759+704], {%rs995, %rs993, %rs997, %rs999};
	st.shared.v4.b16 	[%r759+736], {%rs996, %rs994, %rs998, %rs1000};
	mov.b32 	{%rs1001, %rs1002}, %r5605;
	mov.b32 	{%rs1003, %rs1004}, %r5601;
	mov.b32 	{%rs1005, %rs1006}, %r5609;
	mov.b32 	{%rs1007, %rs1008}, %r5613;
	st.shared.v4.b16 	[%r759+896], {%rs1003, %rs1001, %rs1005, %rs1007};
	st.shared.v4.b16 	[%r759+928], {%rs1004, %rs1002, %rs1006, %rs1008};
	mov.b32 	{%rs1009, %rs1010}, %r5606;
	mov.b32 	{%rs1011, %rs1012}, %r5602;
	mov.b32 	{%rs1013, %rs1014}, %r5610;
	mov.b32 	{%rs1015, %rs1016}, %r5614;
	st.shared.v4.b16 	[%r759+960], {%rs1011, %rs1009, %rs1013, %rs1015};
	st.shared.v4.b16 	[%r759+992], {%rs1012, %rs1010, %rs1014, %rs1016};
	mov.b32 	{%rs1017, %rs1018}, %r5621;
	mov.b32 	{%rs1019, %rs1020}, %r5617;
	mov.b32 	{%rs1021, %rs1022}, %r5625;
	mov.b32 	{%rs1023, %rs1024}, %r5629;
	st.shared.v4.b16 	[%r759+1152], {%rs1019, %rs1017, %rs1021, %rs1023};
	st.shared.v4.b16 	[%r759+1184], {%rs1020, %rs1018, %rs1022, %rs1024};
	mov.b32 	{%rs1025, %rs1026}, %r5622;
	mov.b32 	{%rs1027, %rs1028}, %r5618;
	mov.b32 	{%rs1029, %rs1030}, %r5626;
	mov.b32 	{%rs1031, %rs1032}, %r5630;
	st.shared.v4.b16 	[%r759+1216], {%rs1027, %rs1025, %rs1029, %rs1031};
	st.shared.v4.b16 	[%r759+1248], {%rs1028, %rs1026, %rs1030, %rs1032};
	mov.b32 	{%rs1033, %rs1034}, %r5637;
	mov.b32 	{%rs1035, %rs1036}, %r5633;
	mov.b32 	{%rs1037, %rs1038}, %r5641;
	mov.b32 	{%rs1039, %rs1040}, %r5645;
	st.shared.v4.b16 	[%r759+1408], {%rs1035, %rs1033, %rs1037, %rs1039};
	st.shared.v4.b16 	[%r759+1440], {%rs1036, %rs1034, %rs1038, %rs1040};
	mov.b32 	{%rs1041, %rs1042}, %r5638;
	mov.b32 	{%rs1043, %rs1044}, %r5634;
	mov.b32 	{%rs1045, %rs1046}, %r5642;
	mov.b32 	{%rs1047, %rs1048}, %r5646;
	st.shared.v4.b16 	[%r759+1472], {%rs1043, %rs1041, %rs1045, %rs1047};
	st.shared.v4.b16 	[%r759+1504], {%rs1044, %rs1042, %rs1046, %rs1048};
	mov.b32 	{%rs1049, %rs1050}, %r5653;
	mov.b32 	{%rs1051, %rs1052}, %r5649;
	mov.b32 	{%rs1053, %rs1054}, %r5657;
	mov.b32 	{%rs1055, %rs1056}, %r5661;
	st.shared.v4.b16 	[%r759+1664], {%rs1051, %rs1049, %rs1053, %rs1055};
	st.shared.v4.b16 	[%r759+1696], {%rs1052, %rs1050, %rs1054, %rs1056};
	mov.b32 	{%rs1057, %rs1058}, %r5654;
	mov.b32 	{%rs1059, %rs1060}, %r5650;
	mov.b32 	{%rs1061, %rs1062}, %r5658;
	mov.b32 	{%rs1063, %rs1064}, %r5662;
	st.shared.v4.b16 	[%r759+1728], {%rs1059, %rs1057, %rs1061, %rs1063};
	st.shared.v4.b16 	[%r759+1760], {%rs1060, %rs1058, %rs1062, %rs1064};
	mov.b32 	{%rs1065, %rs1066}, %r5669;
	mov.b32 	{%rs1067, %rs1068}, %r5665;
	mov.b32 	{%rs1069, %rs1070}, %r5673;
	mov.b32 	{%rs1071, %rs1072}, %r5677;
	st.shared.v4.b16 	[%r759+1920], {%rs1067, %rs1065, %rs1069, %rs1071};
	st.shared.v4.b16 	[%r759+1952], {%rs1068, %rs1066, %rs1070, %rs1072};
	mov.b32 	{%rs1073, %rs1074}, %r5670;
	mov.b32 	{%rs1075, %rs1076}, %r5666;
	mov.b32 	{%rs1077, %rs1078}, %r5674;
	mov.b32 	{%rs1079, %rs1080}, %r5678;
	st.shared.v4.b16 	[%r759+1984], {%rs1075, %rs1073, %rs1077, %rs1079};
	st.shared.v4.b16 	[%r759+2016], {%rs1076, %rs1074, %rs1078, %rs1080};
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4709, %r4710, %r4711, %r4712}, [%r5802];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4714, %r4715, %r4716, %r4717}, [%r5807];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4719, %r4720, %r4721, %r4722}, [%r5812];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4724, %r4725, %r4726, %r4727}, [%r5817];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4729, %r4730, %r4731, %r4732}, [%r5822];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4734, %r4735, %r4736, %r4737}, [%r5827];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4739, %r4740, %r4741, %r4742}, [%r5832];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4744, %r4745, %r4746, %r4747}, [%r5837];
	// end inline asm
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	shfl.sync.idx.b32 	%r5679, %r2, 0, 31, -1;
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r4781,%r4782,%r4783,%r4784,%r4785,%r4786,%r4787,%r4788}, {%r4709,%r4710,%r4711,%r4712}, %rd557, 0, 1, 1, 1;
	// end inline asm
	mov.pred 	%p61, -1;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r4781,%r4782,%r4783,%r4784,%r4785,%r4786,%r4787,%r4788}, {%r4714,%r4715,%r4716,%r4717}, %rd558, %p61, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r4781,%r4782,%r4783,%r4784,%r4785,%r4786,%r4787,%r4788}, {%r4719,%r4720,%r4721,%r4722}, %rd559, %p61, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r4781,%r4782,%r4783,%r4784,%r4785,%r4786,%r4787,%r4788}, {%r4724,%r4725,%r4726,%r4727}, %rd560, %p61, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r4853,%r4854,%r4855,%r4856,%r4857,%r4858,%r4859,%r4860}, {%r4729,%r4730,%r4731,%r4732}, %rd557, 0, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r4853,%r4854,%r4855,%r4856,%r4857,%r4858,%r4859,%r4860}, {%r4734,%r4735,%r4736,%r4737}, %rd558, %p61, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r4853,%r4854,%r4855,%r4856,%r4857,%r4858,%r4859,%r4860}, {%r4739,%r4740,%r4741,%r4742}, %rd559, %p61, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r4853,%r4854,%r4855,%r4856,%r4857,%r4858,%r4859,%r4860}, {%r4744,%r4745,%r4746,%r4747}, %rd560, %p61, 1, 1, 1;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r4909, %r1357;
	mov.b32 	%r4910, %r4929;
	mov.b32 	%r4911, %r4929;
	// begin inline asm
	// wait for regs: %r4781,%r4782,%r4783,%r4784,%r4785,%r4786,%r4787,%r4788,%r4853,%r4854,%r4855,%r4856,%r4857,%r4858,%r4859,%r4860,%r4909,%r4910,%r4911
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	sub.f32 	%r5681, %r4781, %r748;
	sub.f32 	%r5682, %r4782, %r748;
	sub.f32 	%r5683, %r4783, %r749;
	sub.f32 	%r5684, %r4784, %r749;
	sub.f32 	%r5685, %r4785, %r748;
	sub.f32 	%r5686, %r4786, %r748;
	sub.f32 	%r5687, %r4787, %r749;
	sub.f32 	%r5688, %r4788, %r749;
	sub.f32 	%r5689, %r4853, %r750;
	sub.f32 	%r5690, %r4854, %r750;
	sub.f32 	%r5691, %r4855, %r751;
	sub.f32 	%r5692, %r4856, %r751;
	sub.f32 	%r5693, %r4857, %r750;
	sub.f32 	%r5694, %r4858, %r750;
	sub.f32 	%r5695, %r4859, %r751;
	sub.f32 	%r5696, %r4860, %r751;
	ex2.approx.ftz.f32 	%r5697, %r5681;
	ex2.approx.ftz.f32 	%r5698, %r5682;
	ex2.approx.ftz.f32 	%r5699, %r5683;
	ex2.approx.ftz.f32 	%r5700, %r5684;
	ex2.approx.ftz.f32 	%r5701, %r5685;
	ex2.approx.ftz.f32 	%r5702, %r5686;
	ex2.approx.ftz.f32 	%r5703, %r5687;
	ex2.approx.ftz.f32 	%r5704, %r5688;
	ex2.approx.ftz.f32 	%r5705, %r5689;
	ex2.approx.ftz.f32 	%r5706, %r5690;
	ex2.approx.ftz.f32 	%r5707, %r5691;
	ex2.approx.ftz.f32 	%r5708, %r5692;
	ex2.approx.ftz.f32 	%r5709, %r5693;
	ex2.approx.ftz.f32 	%r5710, %r5694;
	ex2.approx.ftz.f32 	%r5711, %r5695;
	ex2.approx.ftz.f32 	%r5712, %r5696;
	add.s32 	%r5713, %r776, %r7897;
	add.s32 	%r5714, %r5713, 1;
	add.s32 	%r5715, %r5713, 8;
	add.s32 	%r5716, %r5713, 9;
	setp.lt.s32 	%p75, %r27, %r5713;
	setp.lt.s32 	%p76, %r27, %r5714;
	setp.lt.s32 	%p77, %r28, %r5713;
	setp.lt.s32 	%p78, %r28, %r5714;
	setp.lt.s32 	%p79, %r27, %r5715;
	setp.lt.s32 	%p80, %r27, %r5716;
	setp.lt.s32 	%p81, %r28, %r5715;
	setp.lt.s32 	%p82, %r28, %r5716;
	setp.lt.s32 	%p83, %r29, %r5713;
	setp.lt.s32 	%p84, %r29, %r5714;
	setp.lt.s32 	%p85, %r30, %r5713;
	setp.lt.s32 	%p86, %r30, %r5714;
	setp.lt.s32 	%p87, %r29, %r5715;
	setp.lt.s32 	%p88, %r29, %r5716;
	setp.lt.s32 	%p89, %r30, %r5715;
	setp.lt.s32 	%p90, %r30, %r5716;
	selp.f32 	%r5717, 0f00000000, %r5697, %p75;
	selp.f32 	%r5718, 0f00000000, %r5698, %p76;
	selp.f32 	%r5719, 0f00000000, %r5699, %p77;
	selp.f32 	%r5720, 0f00000000, %r5700, %p78;
	selp.f32 	%r5721, 0f00000000, %r5701, %p79;
	selp.f32 	%r5722, 0f00000000, %r5702, %p80;
	selp.f32 	%r5723, 0f00000000, %r5703, %p81;
	selp.f32 	%r5724, 0f00000000, %r5704, %p82;
	selp.f32 	%r5725, 0f00000000, %r5705, %p83;
	selp.f32 	%r5726, 0f00000000, %r5706, %p84;
	selp.f32 	%r5727, 0f00000000, %r5707, %p85;
	selp.f32 	%r5728, 0f00000000, %r5708, %p86;
	selp.f32 	%r5729, 0f00000000, %r5709, %p87;
	selp.f32 	%r5730, 0f00000000, %r5710, %p88;
	selp.f32 	%r5731, 0f00000000, %r5711, %p89;
	selp.f32 	%r5732, 0f00000000, %r5712, %p90;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4931, %r4932, %r4933, %r4934}, [%r6168];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4936, %r4937, %r4938, %r4939}, [%r6173];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4941, %r4942, %r4943, %r4944}, [%r6178];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4946, %r4947, %r4948, %r4949}, [%r6183];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4951, %r4952, %r4953, %r4954}, [%r6188];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4956, %r4957, %r4958, %r4959}, [%r6193];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4961, %r4962, %r4963, %r4964}, [%r6198];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r4966, %r4967, %r4968, %r4969}, [%r6203];
	// end inline asm
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	bar.sync 	0;
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r5003,%r5004,%r5005,%r5006,%r5007,%r5008,%r5009,%r5010}, {%r4931,%r4932,%r4933,%r4934}, %rd565, 0, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r5003,%r5004,%r5005,%r5006,%r5007,%r5008,%r5009,%r5010}, {%r4936,%r4937,%r4938,%r4939}, %rd566, %p61, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r5003,%r5004,%r5005,%r5006,%r5007,%r5008,%r5009,%r5010}, {%r4941,%r4942,%r4943,%r4944}, %rd567, %p61, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r5003,%r5004,%r5005,%r5006,%r5007,%r5008,%r5009,%r5010}, {%r4946,%r4947,%r4948,%r4949}, %rd568, %p61, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r5075,%r5076,%r5077,%r5078,%r5079,%r5080,%r5081,%r5082}, {%r4951,%r4952,%r4953,%r4954}, %rd565, 0, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r5075,%r5076,%r5077,%r5078,%r5079,%r5080,%r5081,%r5082}, {%r4956,%r4957,%r4958,%r4959}, %rd566, %p61, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r5075,%r5076,%r5077,%r5078,%r5079,%r5080,%r5081,%r5082}, {%r4961,%r4962,%r4963,%r4964}, %rd567, %p61, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n16k16.f32.f16.f16 {%r5075,%r5076,%r5077,%r5078,%r5079,%r5080,%r5081,%r5082}, {%r4966,%r4967,%r4968,%r4969}, %rd568, %p61, 1, 1, 1;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r5131, %r2788;
	mov.b32 	%r5132, %r4929;
	mov.b32 	%r5133, %r4929;
	// begin inline asm
	// wait for regs: %r5003,%r5004,%r5005,%r5006,%r5007,%r5008,%r5009,%r5010,%r5075,%r5076,%r5077,%r5078,%r5079,%r5080,%r5081,%r5082,%r5131,%r5132,%r5133
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	sub.f32 	%r5733, %r5003, %r752;
	sub.f32 	%r5734, %r5004, %r752;
	sub.f32 	%r5735, %r5005, %r753;
	sub.f32 	%r5736, %r5006, %r753;
	sub.f32 	%r5737, %r5007, %r752;
	sub.f32 	%r5738, %r5008, %r752;
	sub.f32 	%r5739, %r5009, %r753;
	sub.f32 	%r5740, %r5010, %r753;
	sub.f32 	%r5741, %r5075, %r754;
	sub.f32 	%r5742, %r5076, %r754;
	sub.f32 	%r5743, %r5077, %r755;
	sub.f32 	%r5744, %r5078, %r755;
	sub.f32 	%r5745, %r5079, %r754;
	sub.f32 	%r5746, %r5080, %r754;
	sub.f32 	%r5747, %r5081, %r755;
	sub.f32 	%r5748, %r5082, %r755;
	mul.f32 	%r5749, %r5717, %r5733;
	mul.f32 	%r5750, %r5718, %r5734;
	mul.f32 	%r5751, %r5719, %r5735;
	mul.f32 	%r5752, %r5720, %r5736;
	mul.f32 	%r5753, %r5721, %r5737;
	mul.f32 	%r5754, %r5722, %r5738;
	mul.f32 	%r5755, %r5723, %r5739;
	mul.f32 	%r5756, %r5724, %r5740;
	mul.f32 	%r5757, %r5725, %r5741;
	mul.f32 	%r5758, %r5726, %r5742;
	mul.f32 	%r5759, %r5727, %r5743;
	mul.f32 	%r5760, %r5728, %r5744;
	mul.f32 	%r5761, %r5729, %r5745;
	mul.f32 	%r5762, %r5730, %r5746;
	mul.f32 	%r5763, %r5731, %r5747;
	mul.f32 	%r5764, %r5732, %r5748;
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	cvt.rn.f16x2.f32 	%r5217, %r5750, %r5749;
	cvt.rn.f16x2.f32 	%r5218, %r5752, %r5751;
	cvt.rn.f16x2.f32 	%r5219, %r5754, %r5753;
	cvt.rn.f16x2.f32 	%r5220, %r5756, %r5755;
	cvt.rn.f16x2.f32 	%r5285, %r5758, %r5757;
	cvt.rn.f16x2.f32 	%r5286, %r5760, %r5759;
	cvt.rn.f16x2.f32 	%r5287, %r5762, %r5761;
	cvt.rn.f16x2.f32 	%r5288, %r5764, %r5763;
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7963,%r7964,%r7965,%r7966,%r7967,%r7968,%r7969,%r7970,%r7971,%r7972,%r7973,%r7974,%r7975,%r7976,%r7977,%r7978,%r7979,%r7980,%r7981,%r7982,%r7983,%r7984,%r7985,%r7986,%r7987,%r7988,%r7989,%r7990,%r7991,%r7992,%r7993,%r7994}, {%r5217,%r5218,%r5219,%r5220}, %rd573, %p61, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7995,%r7996,%r7997,%r7998,%r7999,%r8000,%r8001,%r8002,%r8003,%r8004,%r8005,%r8006,%r8007,%r8008,%r8009,%r8010,%r8011,%r8012,%r8013,%r8014,%r8015,%r8016,%r8017,%r8018,%r8019,%r8020,%r8021,%r8022,%r8023,%r8024,%r8025,%r8026}, {%r5285,%r5286,%r5287,%r5288}, %rd573, %p61, 1, 1, 0;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r5353, %r1109;
	mov.b32 	%r5355, %r4929;
	mov.b32 	%r5354, %r4929;
	// begin inline asm
	// wait for regs: %r7963,%r7964,%r7965,%r7966,%r7967,%r7968,%r7969,%r7970,%r7971,%r7972,%r7973,%r7974,%r7975,%r7976,%r7977,%r7978,%r7979,%r7980,%r7981,%r7982,%r7983,%r7984,%r7985,%r7986,%r7987,%r7988,%r7989,%r7990,%r7991,%r7992,%r7993,%r7994,%r7995,%r7996,%r7997,%r7998,%r7999,%r8000,%r8001,%r8002,%r8003,%r8004,%r8005,%r8006,%r8007,%r8008,%r8009,%r8010,%r8011,%r8012,%r8013,%r8014,%r8015,%r8016,%r8017,%r8018,%r8019,%r8020,%r8021,%r8022,%r8023,%r8024,%r8025,%r8026,%r5353,%r5354,%r5355
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	add.s64 	%rd678, %rd678, %rd67;
	add.s32 	%r7897, %r7897, 16;
	setp.ne.b32 	%p91, %r7897, 128;
	@%p91 bra 	$L__BB0_8;
// %bb.9:
	shr.s32 	%r7962, %r2375, 5;
	setp.lt.s32 	%p92, %r7962, 1;
	mov.b64 	%rd683, {%r7975, %r7976};
	mov.b64 	%rd684, {%r7971, %r7972};
	mov.b64 	%rd685, {%r7967, %r7968};
	mov.b64 	%rd686, {%r7963, %r7964};
	mov.b64 	%rd687, {%r7977, %r7978};
	mov.b64 	%rd688, {%r7973, %r7974};
	mov.b64 	%rd689, {%r7969, %r7970};
	mov.b64 	%rd690, {%r7965, %r7966};
	mov.b64 	%rd691, {%r7991, %r7992};
	mov.b64 	%rd692, {%r7987, %r7988};
	mov.b64 	%rd693, {%r7983, %r7984};
	mov.b64 	%rd694, {%r7979, %r7980};
	mov.b64 	%rd695, {%r7993, %r7994};
	mov.b64 	%rd696, {%r7989, %r7990};
	mov.b64 	%rd697, {%r7985, %r7986};
	mov.b64 	%rd698, {%r7981, %r7982};
	mov.b64 	%rd699, {%r8007, %r8008};
	mov.b64 	%rd700, {%r8003, %r8004};
	mov.b64 	%rd701, {%r7999, %r8000};
	mov.b64 	%rd702, {%r7995, %r7996};
	mov.b64 	%rd703, {%r8009, %r8010};
	mov.b64 	%rd704, {%r8005, %r8006};
	mov.b64 	%rd705, {%r8001, %r8002};
	mov.b64 	%rd706, {%r7997, %r7998};
	mov.b64 	%rd707, {%r8023, %r8024};
	mov.b64 	%rd708, {%r8019, %r8020};
	mov.b64 	%rd709, {%r8015, %r8016};
	mov.b64 	%rd710, {%r8011, %r8012};
	mov.b64 	%rd711, {%r8025, %r8026};
	mov.b64 	%rd712, {%r8021, %r8022};
	mov.b64 	%rd713, {%r8017, %r8018};
	mov.b64 	%rd714, {%r8013, %r8014};
	@%p92 bra 	$L__BB0_13;
// %bb.10:                              // %.lr.ph553
	mul.lo.s32 	%r5767, %r1054, %r3;
	add.s32 	%r909, %r1109, %r7564;
	add.s32 	%r910, %r2788, %r7562;
	xor.b32 	%r5772, %r7562, 16;
	add.s32 	%r911, %r2788, %r5772;
	xor.b32 	%r5773, %r7562, 32;
	add.s32 	%r912, %r2788, %r5773;
	xor.b32 	%r5774, %r7562, 48;
	add.s32 	%r913, %r2788, %r5774;
	add.s32 	%r5777, %r1109, %r7565;
	add.s32 	%r914, %r5777, %r7566;
	add.s32 	%r915, %r1109, %r77;
	add.s32 	%r5778, %r1103, 40960;
	add.s32 	%r5796, %r5778, %r9;
	add.s32 	%r5797, %r5796, 2048;
	add.s32 	%r918, %r5778, %r7564;
	mad.lo.s32 	%r919, %r8, -504, %r918;
	add.s32 	%r920, %r5778, %r5772;
	add.s32 	%r921, %r5778, %r5773;
	add.s32 	%r922, %r5778, %r5774;
	or.b64 	%rd589, %rd645, -9223371899399045120;
	add.s32 	%r5779, %r1103, 38912;
	bfe.u32 	%r5780, %r5779, 4, 14;
	cvt.u64.u32 	%rd575, %r5780;
	or.b64 	%rd590, %rd575, -9223371899399045120;
	add.s32 	%r5781, %r1103, 39936;
	bfe.u32 	%r5782, %r5781, 4, 14;
	cvt.u64.u32 	%rd576, %r5782;
	or.b64 	%rd591, %rd576, -9223371899399045120;
	bfe.u32 	%r5783, %r5778, 4, 14;
	cvt.u64.u32 	%rd577, %r5783;
	or.b64 	%rd596, %rd577, -9223371899399045120;
	add.s32 	%r5784, %r1103, 41984;
	bfe.u32 	%r5785, %r5784, 4, 14;
	cvt.u64.u32 	%rd578, %r5785;
	or.b64 	%rd597, %rd578, -9223371899399045120;
	add.s32 	%r5786, %r1103, 43008;
	bfe.u32 	%r5787, %r5786, 4, 14;
	cvt.u64.u32 	%rd579, %r5787;
	or.b64 	%rd598, %rd579, -9223371899399045120;
	add.s32 	%r5788, %r1103, 44032;
	bfe.u32 	%r5789, %r5788, 4, 14;
	cvt.u64.u32 	%rd580, %r5789;
	or.b64 	%rd599, %rd580, -9223371899399045120;
	add.s32 	%r5790, %r1103, 32800;
	bfe.u32 	%r5791, %r5790, 4, 14;
	cvt.u64.u32 	%rd581, %r5791;
	or.b64 	%rd605, %rd581, -9223371899399045120;
	mov.b64 	%rd248, {%r755, %r755};
	mov.b64 	%rd249, {%r754, %r754};
	mov.b64 	%rd250, {%r753, %r753};
	mov.b64 	%rd251, {%r752, %r752};
	or.b32 	%r5792, %r3, 16;
	mul.lo.s32 	%r5793, %r1054, %r5792;
	mad.wide.s32 	%rd582, %r5793, 2, %rd64;
	add.s64 	%rd682, %rd331, %rd582;
	mad.wide.s32 	%rd583, %r5767, 2, %rd64;
	add.s64 	%rd681, %rd331, %rd583;
	add.s64 	%rd680, %rd330, %rd582;
	add.s64 	%rd679, %rd330, %rd583;
$L__BB0_11:                             // %__nv_exp2f.exit
                                        // =>This Inner Loop Header: Depth=1
	add.s64 	%rd587, %rd682, %rd65;
	add.s64 	%rd586, %rd681, %rd65;
	add.s64 	%rd585, %rd680, %rd65;
	add.s64 	%rd584, %rd679, %rd65;
	bar.sync 	0;
	// begin inline asm
	cp.async.cg.shared.global [ %r5794 + 0 ], [ %rd584 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r5795 + 0 ], [ %rd585 + 0 ], 0x10, 0x10;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r6936, %r6937, %r6938, %r6939}, [%r909];
	ld.shared.v4.b32 	{%r6940, %r6941, %r6942, %r6943}, [%r909+128];
	ld.shared.v4.b32 	{%r6944, %r6945, %r6946, %r6947}, [%r909+256];
	ld.shared.v4.b32 	{%r6948, %r6949, %r6950, %r6951}, [%r909+384];
	ld.shared.v4.b32 	{%r6952, %r6953, %r6954, %r6955}, [%r909+16];
	ld.shared.v4.b32 	{%r6956, %r6957, %r6958, %r6959}, [%r909+144];
	ld.shared.v4.b32 	{%r6960, %r6961, %r6962, %r6963}, [%r909+272];
	ld.shared.v4.b32 	{%r6964, %r6965, %r6966, %r6967}, [%r909+400];
	ld.shared.v4.b32 	{%r6968, %r6969, %r6970, %r6971}, [%r909+32];
	ld.shared.v4.b32 	{%r6972, %r6973, %r6974, %r6975}, [%r909+160];
	ld.shared.v4.b32 	{%r6976, %r6977, %r6978, %r6979}, [%r909+288];
	ld.shared.v4.b32 	{%r6980, %r6981, %r6982, %r6983}, [%r909+416];
	ld.shared.v4.b32 	{%r6984, %r6985, %r6986, %r6987}, [%r909+48];
	ld.shared.v4.b32 	{%r6988, %r6989, %r6990, %r6991}, [%r909+176];
	ld.shared.v4.b32 	{%r6992, %r6993, %r6994, %r6995}, [%r909+304];
	ld.shared.v4.b32 	{%r6996, %r6997, %r6998, %r6999}, [%r909+432];
	ld.shared.v4.b32 	{%r7000, %r7001, %r7002, %r7003}, [%r909+64];
	ld.shared.v4.b32 	{%r7004, %r7005, %r7006, %r7007}, [%r909+192];
	ld.shared.v4.b32 	{%r7008, %r7009, %r7010, %r7011}, [%r909+320];
	ld.shared.v4.b32 	{%r7012, %r7013, %r7014, %r7015}, [%r909+448];
	ld.shared.v4.b32 	{%r7016, %r7017, %r7018, %r7019}, [%r909+80];
	ld.shared.v4.b32 	{%r7020, %r7021, %r7022, %r7023}, [%r909+208];
	ld.shared.v4.b32 	{%r7024, %r7025, %r7026, %r7027}, [%r909+336];
	ld.shared.v4.b32 	{%r7028, %r7029, %r7030, %r7031}, [%r909+464];
	ld.shared.v4.b32 	{%r7032, %r7033, %r7034, %r7035}, [%r909+96];
	ld.shared.v4.b32 	{%r7036, %r7037, %r7038, %r7039}, [%r909+224];
	ld.shared.v4.b32 	{%r7040, %r7041, %r7042, %r7043}, [%r909+352];
	ld.shared.v4.b32 	{%r7044, %r7045, %r7046, %r7047}, [%r909+480];
	ld.shared.v4.b32 	{%r7048, %r7049, %r7050, %r7051}, [%r909+112];
	ld.shared.v4.b32 	{%r7052, %r7053, %r7054, %r7055}, [%r909+240];
	ld.shared.v4.b32 	{%r7056, %r7057, %r7058, %r7059}, [%r909+368];
	ld.shared.v4.b32 	{%r7060, %r7061, %r7062, %r7063}, [%r909+496];
	mov.b32 	{%rs1081, %rs1082}, %r6940;
	mov.b32 	{%rs1083, %rs1084}, %r6936;
	mov.b32 	{%rs1085, %rs1086}, %r6944;
	mov.b32 	{%rs1087, %rs1088}, %r6948;
	st.shared.v4.b16 	[%r910], {%rs1083, %rs1081, %rs1085, %rs1087};
	st.shared.v4.b16 	[%r910+64], {%rs1084, %rs1082, %rs1086, %rs1088};
	mov.b32 	{%rs1089, %rs1090}, %r6956;
	mov.b32 	{%rs1091, %rs1092}, %r6952;
	mov.b32 	{%rs1093, %rs1094}, %r6960;
	mov.b32 	{%rs1095, %rs1096}, %r6964;
	st.shared.v4.b16 	[%r910+512], {%rs1091, %rs1089, %rs1093, %rs1095};
	st.shared.v4.b16 	[%r910+576], {%rs1092, %rs1090, %rs1094, %rs1096};
	mov.b32 	{%rs1097, %rs1098}, %r6972;
	mov.b32 	{%rs1099, %rs1100}, %r6968;
	mov.b32 	{%rs1101, %rs1102}, %r6976;
	mov.b32 	{%rs1103, %rs1104}, %r6980;
	st.shared.v4.b16 	[%r910+1024], {%rs1099, %rs1097, %rs1101, %rs1103};
	st.shared.v4.b16 	[%r910+1088], {%rs1100, %rs1098, %rs1102, %rs1104};
	mov.b32 	{%rs1105, %rs1106}, %r6988;
	mov.b32 	{%rs1107, %rs1108}, %r6984;
	mov.b32 	{%rs1109, %rs1110}, %r6992;
	mov.b32 	{%rs1111, %rs1112}, %r6996;
	st.shared.v4.b16 	[%r910+1536], {%rs1107, %rs1105, %rs1109, %rs1111};
	st.shared.v4.b16 	[%r910+1600], {%rs1108, %rs1106, %rs1110, %rs1112};
	mov.b32 	{%rs1113, %rs1114}, %r7004;
	mov.b32 	{%rs1115, %rs1116}, %r7000;
	mov.b32 	{%rs1117, %rs1118}, %r7008;
	mov.b32 	{%rs1119, %rs1120}, %r7012;
	st.shared.v4.b16 	[%r910+2048], {%rs1115, %rs1113, %rs1117, %rs1119};
	st.shared.v4.b16 	[%r910+2112], {%rs1116, %rs1114, %rs1118, %rs1120};
	mov.b32 	{%rs1121, %rs1122}, %r7020;
	mov.b32 	{%rs1123, %rs1124}, %r7016;
	mov.b32 	{%rs1125, %rs1126}, %r7024;
	mov.b32 	{%rs1127, %rs1128}, %r7028;
	st.shared.v4.b16 	[%r910+2560], {%rs1123, %rs1121, %rs1125, %rs1127};
	st.shared.v4.b16 	[%r910+2624], {%rs1124, %rs1122, %rs1126, %rs1128};
	mov.b32 	{%rs1129, %rs1130}, %r7036;
	mov.b32 	{%rs1131, %rs1132}, %r7032;
	mov.b32 	{%rs1133, %rs1134}, %r7040;
	mov.b32 	{%rs1135, %rs1136}, %r7044;
	st.shared.v4.b16 	[%r910+3072], {%rs1131, %rs1129, %rs1133, %rs1135};
	st.shared.v4.b16 	[%r910+3136], {%rs1132, %rs1130, %rs1134, %rs1136};
	mov.b32 	{%rs1137, %rs1138}, %r7052;
	mov.b32 	{%rs1139, %rs1140}, %r7048;
	mov.b32 	{%rs1141, %rs1142}, %r7056;
	mov.b32 	{%rs1143, %rs1144}, %r7060;
	st.shared.v4.b16 	[%r910+3584], {%rs1139, %rs1137, %rs1141, %rs1143};
	st.shared.v4.b16 	[%r910+3648], {%rs1140, %rs1138, %rs1142, %rs1144};
	mov.b32 	{%rs1145, %rs1146}, %r6941;
	mov.b32 	{%rs1147, %rs1148}, %r6937;
	mov.b32 	{%rs1149, %rs1150}, %r6945;
	mov.b32 	{%rs1151, %rs1152}, %r6949;
	st.shared.v4.b16 	[%r911+128], {%rs1147, %rs1145, %rs1149, %rs1151};
	st.shared.v4.b16 	[%r911+192], {%rs1148, %rs1146, %rs1150, %rs1152};
	mov.b32 	{%rs1153, %rs1154}, %r6957;
	mov.b32 	{%rs1155, %rs1156}, %r6953;
	mov.b32 	{%rs1157, %rs1158}, %r6961;
	mov.b32 	{%rs1159, %rs1160}, %r6965;
	st.shared.v4.b16 	[%r911+640], {%rs1155, %rs1153, %rs1157, %rs1159};
	st.shared.v4.b16 	[%r911+704], {%rs1156, %rs1154, %rs1158, %rs1160};
	mov.b32 	{%rs1161, %rs1162}, %r6973;
	mov.b32 	{%rs1163, %rs1164}, %r6969;
	mov.b32 	{%rs1165, %rs1166}, %r6977;
	mov.b32 	{%rs1167, %rs1168}, %r6981;
	st.shared.v4.b16 	[%r911+1152], {%rs1163, %rs1161, %rs1165, %rs1167};
	st.shared.v4.b16 	[%r911+1216], {%rs1164, %rs1162, %rs1166, %rs1168};
	mov.b32 	{%rs1169, %rs1170}, %r6989;
	mov.b32 	{%rs1171, %rs1172}, %r6985;
	mov.b32 	{%rs1173, %rs1174}, %r6993;
	mov.b32 	{%rs1175, %rs1176}, %r6997;
	st.shared.v4.b16 	[%r911+1664], {%rs1171, %rs1169, %rs1173, %rs1175};
	st.shared.v4.b16 	[%r911+1728], {%rs1172, %rs1170, %rs1174, %rs1176};
	mov.b32 	{%rs1177, %rs1178}, %r7005;
	mov.b32 	{%rs1179, %rs1180}, %r7001;
	mov.b32 	{%rs1181, %rs1182}, %r7009;
	mov.b32 	{%rs1183, %rs1184}, %r7013;
	st.shared.v4.b16 	[%r911+2176], {%rs1179, %rs1177, %rs1181, %rs1183};
	st.shared.v4.b16 	[%r911+2240], {%rs1180, %rs1178, %rs1182, %rs1184};
	mov.b32 	{%rs1185, %rs1186}, %r7021;
	mov.b32 	{%rs1187, %rs1188}, %r7017;
	mov.b32 	{%rs1189, %rs1190}, %r7025;
	mov.b32 	{%rs1191, %rs1192}, %r7029;
	st.shared.v4.b16 	[%r911+2688], {%rs1187, %rs1185, %rs1189, %rs1191};
	st.shared.v4.b16 	[%r911+2752], {%rs1188, %rs1186, %rs1190, %rs1192};
	mov.b32 	{%rs1193, %rs1194}, %r7037;
	mov.b32 	{%rs1195, %rs1196}, %r7033;
	mov.b32 	{%rs1197, %rs1198}, %r7041;
	mov.b32 	{%rs1199, %rs1200}, %r7045;
	st.shared.v4.b16 	[%r911+3200], {%rs1195, %rs1193, %rs1197, %rs1199};
	st.shared.v4.b16 	[%r911+3264], {%rs1196, %rs1194, %rs1198, %rs1200};
	mov.b32 	{%rs1201, %rs1202}, %r7053;
	mov.b32 	{%rs1203, %rs1204}, %r7049;
	mov.b32 	{%rs1205, %rs1206}, %r7057;
	mov.b32 	{%rs1207, %rs1208}, %r7061;
	st.shared.v4.b16 	[%r911+3712], {%rs1203, %rs1201, %rs1205, %rs1207};
	st.shared.v4.b16 	[%r911+3776], {%rs1204, %rs1202, %rs1206, %rs1208};
	mov.b32 	{%rs1209, %rs1210}, %r6942;
	mov.b32 	{%rs1211, %rs1212}, %r6938;
	mov.b32 	{%rs1213, %rs1214}, %r6946;
	mov.b32 	{%rs1215, %rs1216}, %r6950;
	st.shared.v4.b16 	[%r912+256], {%rs1211, %rs1209, %rs1213, %rs1215};
	st.shared.v4.b16 	[%r912+320], {%rs1212, %rs1210, %rs1214, %rs1216};
	mov.b32 	{%rs1217, %rs1218}, %r6958;
	mov.b32 	{%rs1219, %rs1220}, %r6954;
	mov.b32 	{%rs1221, %rs1222}, %r6962;
	mov.b32 	{%rs1223, %rs1224}, %r6966;
	st.shared.v4.b16 	[%r912+768], {%rs1219, %rs1217, %rs1221, %rs1223};
	st.shared.v4.b16 	[%r912+832], {%rs1220, %rs1218, %rs1222, %rs1224};
	mov.b32 	{%rs1225, %rs1226}, %r6974;
	mov.b32 	{%rs1227, %rs1228}, %r6970;
	mov.b32 	{%rs1229, %rs1230}, %r6978;
	mov.b32 	{%rs1231, %rs1232}, %r6982;
	st.shared.v4.b16 	[%r912+1280], {%rs1227, %rs1225, %rs1229, %rs1231};
	st.shared.v4.b16 	[%r912+1344], {%rs1228, %rs1226, %rs1230, %rs1232};
	mov.b32 	{%rs1233, %rs1234}, %r6990;
	mov.b32 	{%rs1235, %rs1236}, %r6986;
	mov.b32 	{%rs1237, %rs1238}, %r6994;
	mov.b32 	{%rs1239, %rs1240}, %r6998;
	st.shared.v4.b16 	[%r912+1792], {%rs1235, %rs1233, %rs1237, %rs1239};
	st.shared.v4.b16 	[%r912+1856], {%rs1236, %rs1234, %rs1238, %rs1240};
	mov.b32 	{%rs1241, %rs1242}, %r7006;
	mov.b32 	{%rs1243, %rs1244}, %r7002;
	mov.b32 	{%rs1245, %rs1246}, %r7010;
	mov.b32 	{%rs1247, %rs1248}, %r7014;
	st.shared.v4.b16 	[%r912+2304], {%rs1243, %rs1241, %rs1245, %rs1247};
	st.shared.v4.b16 	[%r912+2368], {%rs1244, %rs1242, %rs1246, %rs1248};
	mov.b32 	{%rs1249, %rs1250}, %r7022;
	mov.b32 	{%rs1251, %rs1252}, %r7018;
	mov.b32 	{%rs1253, %rs1254}, %r7026;
	mov.b32 	{%rs1255, %rs1256}, %r7030;
	st.shared.v4.b16 	[%r912+2816], {%rs1251, %rs1249, %rs1253, %rs1255};
	st.shared.v4.b16 	[%r912+2880], {%rs1252, %rs1250, %rs1254, %rs1256};
	mov.b32 	{%rs1257, %rs1258}, %r7038;
	mov.b32 	{%rs1259, %rs1260}, %r7034;
	mov.b32 	{%rs1261, %rs1262}, %r7042;
	mov.b32 	{%rs1263, %rs1264}, %r7046;
	st.shared.v4.b16 	[%r912+3328], {%rs1259, %rs1257, %rs1261, %rs1263};
	st.shared.v4.b16 	[%r912+3392], {%rs1260, %rs1258, %rs1262, %rs1264};
	mov.b32 	{%rs1265, %rs1266}, %r7054;
	mov.b32 	{%rs1267, %rs1268}, %r7050;
	mov.b32 	{%rs1269, %rs1270}, %r7058;
	mov.b32 	{%rs1271, %rs1272}, %r7062;
	st.shared.v4.b16 	[%r912+3840], {%rs1267, %rs1265, %rs1269, %rs1271};
	st.shared.v4.b16 	[%r912+3904], {%rs1268, %rs1266, %rs1270, %rs1272};
	mov.b32 	{%rs1273, %rs1274}, %r6943;
	mov.b32 	{%rs1275, %rs1276}, %r6939;
	mov.b32 	{%rs1277, %rs1278}, %r6947;
	mov.b32 	{%rs1279, %rs1280}, %r6951;
	st.shared.v4.b16 	[%r913+384], {%rs1275, %rs1273, %rs1277, %rs1279};
	st.shared.v4.b16 	[%r913+448], {%rs1276, %rs1274, %rs1278, %rs1280};
	mov.b32 	{%rs1281, %rs1282}, %r6959;
	mov.b32 	{%rs1283, %rs1284}, %r6955;
	mov.b32 	{%rs1285, %rs1286}, %r6963;
	mov.b32 	{%rs1287, %rs1288}, %r6967;
	st.shared.v4.b16 	[%r913+896], {%rs1283, %rs1281, %rs1285, %rs1287};
	st.shared.v4.b16 	[%r913+960], {%rs1284, %rs1282, %rs1286, %rs1288};
	mov.b32 	{%rs1289, %rs1290}, %r6975;
	mov.b32 	{%rs1291, %rs1292}, %r6971;
	mov.b32 	{%rs1293, %rs1294}, %r6979;
	mov.b32 	{%rs1295, %rs1296}, %r6983;
	st.shared.v4.b16 	[%r913+1408], {%rs1291, %rs1289, %rs1293, %rs1295};
	st.shared.v4.b16 	[%r913+1472], {%rs1292, %rs1290, %rs1294, %rs1296};
	mov.b32 	{%rs1297, %rs1298}, %r6991;
	mov.b32 	{%rs1299, %rs1300}, %r6987;
	mov.b32 	{%rs1301, %rs1302}, %r6995;
	mov.b32 	{%rs1303, %rs1304}, %r6999;
	st.shared.v4.b16 	[%r913+1920], {%rs1299, %rs1297, %rs1301, %rs1303};
	st.shared.v4.b16 	[%r913+1984], {%rs1300, %rs1298, %rs1302, %rs1304};
	mov.b32 	{%rs1305, %rs1306}, %r7007;
	mov.b32 	{%rs1307, %rs1308}, %r7003;
	mov.b32 	{%rs1309, %rs1310}, %r7011;
	mov.b32 	{%rs1311, %rs1312}, %r7015;
	st.shared.v4.b16 	[%r913+2432], {%rs1307, %rs1305, %rs1309, %rs1311};
	st.shared.v4.b16 	[%r913+2496], {%rs1308, %rs1306, %rs1310, %rs1312};
	mov.b32 	{%rs1313, %rs1314}, %r7023;
	mov.b32 	{%rs1315, %rs1316}, %r7019;
	mov.b32 	{%rs1317, %rs1318}, %r7027;
	mov.b32 	{%rs1319, %rs1320}, %r7031;
	st.shared.v4.b16 	[%r913+2944], {%rs1315, %rs1313, %rs1317, %rs1319};
	st.shared.v4.b16 	[%r913+3008], {%rs1316, %rs1314, %rs1318, %rs1320};
	mov.b32 	{%rs1321, %rs1322}, %r7039;
	mov.b32 	{%rs1323, %rs1324}, %r7035;
	mov.b32 	{%rs1325, %rs1326}, %r7043;
	mov.b32 	{%rs1327, %rs1328}, %r7047;
	st.shared.v4.b16 	[%r913+3456], {%rs1323, %rs1321, %rs1325, %rs1327};
	st.shared.v4.b16 	[%r913+3520], {%rs1324, %rs1322, %rs1326, %rs1328};
	mov.b32 	{%rs1329, %rs1330}, %r7055;
	mov.b32 	{%rs1331, %rs1332}, %r7051;
	mov.b32 	{%rs1333, %rs1334}, %r7059;
	mov.b32 	{%rs1335, %rs1336}, %r7063;
	st.shared.v4.b16 	[%r913+3968], {%rs1331, %rs1329, %rs1333, %rs1335};
	st.shared.v4.b16 	[%r913+4032], {%rs1332, %rs1330, %rs1334, %rs1336};
	ld.shared.b16 	%rs1337, [%r914];
	ld.shared.b16 	%rs1338, [%r914+8];
	ld.shared.b16 	%rs1339, [%r914+16];
	ld.shared.b16 	%rs1340, [%r914+24];
	ld.shared.b16 	%rs1341, [%r914+32];
	ld.shared.b16 	%rs1342, [%r914+40];
	ld.shared.b16 	%rs1343, [%r914+48];
	ld.shared.b16 	%rs1344, [%r914+56];
	ld.shared.b16 	%rs1345, [%r914+64];
	ld.shared.b16 	%rs1346, [%r914+72];
	ld.shared.b16 	%rs1347, [%r914+80];
	ld.shared.b16 	%rs1348, [%r914+88];
	ld.shared.b16 	%rs1349, [%r914+96];
	ld.shared.b16 	%rs1350, [%r914+104];
	ld.shared.b16 	%rs1351, [%r914+112];
	ld.shared.b16 	%rs1352, [%r914+120];
	bar.sync 	0;
	st.shared.b16 	[%r42], %rs1337;
	st.shared.b16 	[%r42+512], %rs1339;
	st.shared.b16 	[%r42+1024], %rs1341;
	st.shared.b16 	[%r42+1536], %rs1343;
	st.shared.b16 	[%r42+2048], %rs1345;
	st.shared.b16 	[%r42+2560], %rs1347;
	st.shared.b16 	[%r42+3072], %rs1349;
	st.shared.b16 	[%r42+3584], %rs1351;
	st.shared.b16 	[%r915+256], %rs1338;
	st.shared.b16 	[%r915+768], %rs1340;
	st.shared.b16 	[%r915+1280], %rs1342;
	st.shared.b16 	[%r915+1792], %rs1344;
	st.shared.b16 	[%r915+2304], %rs1346;
	st.shared.b16 	[%r915+2816], %rs1348;
	st.shared.b16 	[%r915+3328], %rs1350;
	st.shared.b16 	[%r915+3840], %rs1352;
	// begin inline asm
	cp.async.cg.shared.global [ %r5796 + 0 ], [ %rd586 + 0 ], 0x10, 0x10;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r5797 + 0 ], [ %rd587 + 0 ], 0x10, 0x10;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r7064, %r7065, %r7066, %r7067}, [%r918];
	ld.shared.v4.b32 	{%r7068, %r7069, %r7070, %r7071}, [%r918+128];
	ld.shared.v4.b32 	{%r7072, %r7073, %r7074, %r7075}, [%r918+256];
	ld.shared.v4.b32 	{%r7076, %r7077, %r7078, %r7079}, [%r918+384];
	ld.shared.v4.b32 	{%r7080, %r7081, %r7082, %r7083}, [%r918+16];
	ld.shared.v4.b32 	{%r7084, %r7085, %r7086, %r7087}, [%r918+144];
	ld.shared.v4.b32 	{%r7088, %r7089, %r7090, %r7091}, [%r918+272];
	ld.shared.v4.b32 	{%r7092, %r7093, %r7094, %r7095}, [%r918+400];
	ld.shared.v4.b32 	{%r7096, %r7097, %r7098, %r7099}, [%r918+32];
	ld.shared.v4.b32 	{%r7100, %r7101, %r7102, %r7103}, [%r918+160];
	ld.shared.v4.b32 	{%r7104, %r7105, %r7106, %r7107}, [%r918+288];
	ld.shared.v4.b32 	{%r7108, %r7109, %r7110, %r7111}, [%r918+416];
	ld.shared.v4.b32 	{%r7112, %r7113, %r7114, %r7115}, [%r918+48];
	ld.shared.v4.b32 	{%r7116, %r7117, %r7118, %r7119}, [%r918+176];
	ld.shared.v4.b32 	{%r7120, %r7121, %r7122, %r7123}, [%r918+304];
	ld.shared.v4.b32 	{%r7124, %r7125, %r7126, %r7127}, [%r918+432];
	ld.shared.v4.b32 	{%r7128, %r7129, %r7130, %r7131}, [%r918+64];
	ld.shared.v4.b32 	{%r7132, %r7133, %r7134, %r7135}, [%r918+192];
	ld.shared.v4.b32 	{%r7136, %r7137, %r7138, %r7139}, [%r918+320];
	ld.shared.v4.b32 	{%r7140, %r7141, %r7142, %r7143}, [%r918+448];
	ld.shared.v4.b32 	{%r7144, %r7145, %r7146, %r7147}, [%r918+80];
	ld.shared.v4.b32 	{%r7148, %r7149, %r7150, %r7151}, [%r918+208];
	ld.shared.v4.b32 	{%r7152, %r7153, %r7154, %r7155}, [%r918+336];
	ld.shared.v4.b32 	{%r7156, %r7157, %r7158, %r7159}, [%r918+464];
	ld.shared.v4.b32 	{%r7160, %r7161, %r7162, %r7163}, [%r918+96];
	ld.shared.v4.b32 	{%r7164, %r7165, %r7166, %r7167}, [%r918+224];
	ld.shared.v4.b32 	{%r7168, %r7169, %r7170, %r7171}, [%r918+352];
	ld.shared.v4.b32 	{%r7172, %r7173, %r7174, %r7175}, [%r918+480];
	ld.shared.v4.b32 	{%r7176, %r7177, %r7178, %r7179}, [%r918+112];
	ld.shared.v4.b32 	{%r7180, %r7181, %r7182, %r7183}, [%r918+240];
	ld.shared.v4.b32 	{%r7184, %r7185, %r7186, %r7187}, [%r918+368];
	ld.shared.v4.b32 	{%r7188, %r7189, %r7190, %r7191}, [%r918+496];
	bar.sync 	0;
	mov.b32 	{%rs1353, %rs1354}, %r7068;
	mov.b32 	{%rs1355, %rs1356}, %r7064;
	mov.b32 	{%rs1357, %rs1358}, %r7072;
	mov.b32 	{%rs1359, %rs1360}, %r7076;
	st.shared.v4.b16 	[%r919], {%rs1355, %rs1353, %rs1357, %rs1359};
	st.shared.v4.b16 	[%r919+64], {%rs1356, %rs1354, %rs1358, %rs1360};
	mov.b32 	{%rs1361, %rs1362}, %r7084;
	mov.b32 	{%rs1363, %rs1364}, %r7080;
	mov.b32 	{%rs1365, %rs1366}, %r7088;
	mov.b32 	{%rs1367, %rs1368}, %r7092;
	st.shared.v4.b16 	[%r919+512], {%rs1363, %rs1361, %rs1365, %rs1367};
	st.shared.v4.b16 	[%r919+576], {%rs1364, %rs1362, %rs1366, %rs1368};
	mov.b32 	{%rs1369, %rs1370}, %r7100;
	mov.b32 	{%rs1371, %rs1372}, %r7096;
	mov.b32 	{%rs1373, %rs1374}, %r7104;
	mov.b32 	{%rs1375, %rs1376}, %r7108;
	st.shared.v4.b16 	[%r919+1024], {%rs1371, %rs1369, %rs1373, %rs1375};
	st.shared.v4.b16 	[%r919+1088], {%rs1372, %rs1370, %rs1374, %rs1376};
	mov.b32 	{%rs1377, %rs1378}, %r7116;
	mov.b32 	{%rs1379, %rs1380}, %r7112;
	mov.b32 	{%rs1381, %rs1382}, %r7120;
	mov.b32 	{%rs1383, %rs1384}, %r7124;
	st.shared.v4.b16 	[%r919+1536], {%rs1379, %rs1377, %rs1381, %rs1383};
	st.shared.v4.b16 	[%r919+1600], {%rs1380, %rs1378, %rs1382, %rs1384};
	mov.b32 	{%rs1385, %rs1386}, %r7132;
	mov.b32 	{%rs1387, %rs1388}, %r7128;
	mov.b32 	{%rs1389, %rs1390}, %r7136;
	mov.b32 	{%rs1391, %rs1392}, %r7140;
	st.shared.v4.b16 	[%r919+2048], {%rs1387, %rs1385, %rs1389, %rs1391};
	st.shared.v4.b16 	[%r919+2112], {%rs1388, %rs1386, %rs1390, %rs1392};
	mov.b32 	{%rs1393, %rs1394}, %r7148;
	mov.b32 	{%rs1395, %rs1396}, %r7144;
	mov.b32 	{%rs1397, %rs1398}, %r7152;
	mov.b32 	{%rs1399, %rs1400}, %r7156;
	st.shared.v4.b16 	[%r919+2560], {%rs1395, %rs1393, %rs1397, %rs1399};
	st.shared.v4.b16 	[%r919+2624], {%rs1396, %rs1394, %rs1398, %rs1400};
	mov.b32 	{%rs1401, %rs1402}, %r7164;
	mov.b32 	{%rs1403, %rs1404}, %r7160;
	mov.b32 	{%rs1405, %rs1406}, %r7168;
	mov.b32 	{%rs1407, %rs1408}, %r7172;
	st.shared.v4.b16 	[%r919+3072], {%rs1403, %rs1401, %rs1405, %rs1407};
	st.shared.v4.b16 	[%r919+3136], {%rs1404, %rs1402, %rs1406, %rs1408};
	mov.b32 	{%rs1409, %rs1410}, %r7180;
	mov.b32 	{%rs1411, %rs1412}, %r7176;
	mov.b32 	{%rs1413, %rs1414}, %r7184;
	mov.b32 	{%rs1415, %rs1416}, %r7188;
	st.shared.v4.b16 	[%r919+3584], {%rs1411, %rs1409, %rs1413, %rs1415};
	st.shared.v4.b16 	[%r919+3648], {%rs1412, %rs1410, %rs1414, %rs1416};
	mov.b32 	{%rs1417, %rs1418}, %r7069;
	mov.b32 	{%rs1419, %rs1420}, %r7065;
	mov.b32 	{%rs1421, %rs1422}, %r7073;
	mov.b32 	{%rs1423, %rs1424}, %r7077;
	st.shared.v4.b16 	[%r920+128], {%rs1419, %rs1417, %rs1421, %rs1423};
	st.shared.v4.b16 	[%r920+192], {%rs1420, %rs1418, %rs1422, %rs1424};
	mov.b32 	{%rs1425, %rs1426}, %r7085;
	mov.b32 	{%rs1427, %rs1428}, %r7081;
	mov.b32 	{%rs1429, %rs1430}, %r7089;
	mov.b32 	{%rs1431, %rs1432}, %r7093;
	st.shared.v4.b16 	[%r920+640], {%rs1427, %rs1425, %rs1429, %rs1431};
	st.shared.v4.b16 	[%r920+704], {%rs1428, %rs1426, %rs1430, %rs1432};
	mov.b32 	{%rs1433, %rs1434}, %r7101;
	mov.b32 	{%rs1435, %rs1436}, %r7097;
	mov.b32 	{%rs1437, %rs1438}, %r7105;
	mov.b32 	{%rs1439, %rs1440}, %r7109;
	st.shared.v4.b16 	[%r920+1152], {%rs1435, %rs1433, %rs1437, %rs1439};
	st.shared.v4.b16 	[%r920+1216], {%rs1436, %rs1434, %rs1438, %rs1440};
	mov.b32 	{%rs1441, %rs1442}, %r7117;
	mov.b32 	{%rs1443, %rs1444}, %r7113;
	mov.b32 	{%rs1445, %rs1446}, %r7121;
	mov.b32 	{%rs1447, %rs1448}, %r7125;
	st.shared.v4.b16 	[%r920+1664], {%rs1443, %rs1441, %rs1445, %rs1447};
	st.shared.v4.b16 	[%r920+1728], {%rs1444, %rs1442, %rs1446, %rs1448};
	mov.b32 	{%rs1449, %rs1450}, %r7133;
	mov.b32 	{%rs1451, %rs1452}, %r7129;
	mov.b32 	{%rs1453, %rs1454}, %r7137;
	mov.b32 	{%rs1455, %rs1456}, %r7141;
	st.shared.v4.b16 	[%r920+2176], {%rs1451, %rs1449, %rs1453, %rs1455};
	st.shared.v4.b16 	[%r920+2240], {%rs1452, %rs1450, %rs1454, %rs1456};
	mov.b32 	{%rs1457, %rs1458}, %r7149;
	mov.b32 	{%rs1459, %rs1460}, %r7145;
	mov.b32 	{%rs1461, %rs1462}, %r7153;
	mov.b32 	{%rs1463, %rs1464}, %r7157;
	st.shared.v4.b16 	[%r920+2688], {%rs1459, %rs1457, %rs1461, %rs1463};
	st.shared.v4.b16 	[%r920+2752], {%rs1460, %rs1458, %rs1462, %rs1464};
	mov.b32 	{%rs1465, %rs1466}, %r7165;
	mov.b32 	{%rs1467, %rs1468}, %r7161;
	mov.b32 	{%rs1469, %rs1470}, %r7169;
	mov.b32 	{%rs1471, %rs1472}, %r7173;
	st.shared.v4.b16 	[%r920+3200], {%rs1467, %rs1465, %rs1469, %rs1471};
	st.shared.v4.b16 	[%r920+3264], {%rs1468, %rs1466, %rs1470, %rs1472};
	mov.b32 	{%rs1473, %rs1474}, %r7181;
	mov.b32 	{%rs1475, %rs1476}, %r7177;
	mov.b32 	{%rs1477, %rs1478}, %r7185;
	mov.b32 	{%rs1479, %rs1480}, %r7189;
	st.shared.v4.b16 	[%r920+3712], {%rs1475, %rs1473, %rs1477, %rs1479};
	st.shared.v4.b16 	[%r920+3776], {%rs1476, %rs1474, %rs1478, %rs1480};
	mov.b32 	{%rs1481, %rs1482}, %r7070;
	mov.b32 	{%rs1483, %rs1484}, %r7066;
	mov.b32 	{%rs1485, %rs1486}, %r7074;
	mov.b32 	{%rs1487, %rs1488}, %r7078;
	st.shared.v4.b16 	[%r921+256], {%rs1483, %rs1481, %rs1485, %rs1487};
	st.shared.v4.b16 	[%r921+320], {%rs1484, %rs1482, %rs1486, %rs1488};
	mov.b32 	{%rs1489, %rs1490}, %r7086;
	mov.b32 	{%rs1491, %rs1492}, %r7082;
	mov.b32 	{%rs1493, %rs1494}, %r7090;
	mov.b32 	{%rs1495, %rs1496}, %r7094;
	st.shared.v4.b16 	[%r921+768], {%rs1491, %rs1489, %rs1493, %rs1495};
	st.shared.v4.b16 	[%r921+832], {%rs1492, %rs1490, %rs1494, %rs1496};
	mov.b32 	{%rs1497, %rs1498}, %r7102;
	mov.b32 	{%rs1499, %rs1500}, %r7098;
	mov.b32 	{%rs1501, %rs1502}, %r7106;
	mov.b32 	{%rs1503, %rs1504}, %r7110;
	st.shared.v4.b16 	[%r921+1280], {%rs1499, %rs1497, %rs1501, %rs1503};
	st.shared.v4.b16 	[%r921+1344], {%rs1500, %rs1498, %rs1502, %rs1504};
	mov.b32 	{%rs1505, %rs1506}, %r7118;
	mov.b32 	{%rs1507, %rs1508}, %r7114;
	mov.b32 	{%rs1509, %rs1510}, %r7122;
	mov.b32 	{%rs1511, %rs1512}, %r7126;
	st.shared.v4.b16 	[%r921+1792], {%rs1507, %rs1505, %rs1509, %rs1511};
	st.shared.v4.b16 	[%r921+1856], {%rs1508, %rs1506, %rs1510, %rs1512};
	mov.b32 	{%rs1513, %rs1514}, %r7134;
	mov.b32 	{%rs1515, %rs1516}, %r7130;
	mov.b32 	{%rs1517, %rs1518}, %r7138;
	mov.b32 	{%rs1519, %rs1520}, %r7142;
	st.shared.v4.b16 	[%r921+2304], {%rs1515, %rs1513, %rs1517, %rs1519};
	st.shared.v4.b16 	[%r921+2368], {%rs1516, %rs1514, %rs1518, %rs1520};
	mov.b32 	{%rs1521, %rs1522}, %r7150;
	mov.b32 	{%rs1523, %rs1524}, %r7146;
	mov.b32 	{%rs1525, %rs1526}, %r7154;
	mov.b32 	{%rs1527, %rs1528}, %r7158;
	st.shared.v4.b16 	[%r921+2816], {%rs1523, %rs1521, %rs1525, %rs1527};
	st.shared.v4.b16 	[%r921+2880], {%rs1524, %rs1522, %rs1526, %rs1528};
	mov.b32 	{%rs1529, %rs1530}, %r7166;
	mov.b32 	{%rs1531, %rs1532}, %r7162;
	mov.b32 	{%rs1533, %rs1534}, %r7170;
	mov.b32 	{%rs1535, %rs1536}, %r7174;
	st.shared.v4.b16 	[%r921+3328], {%rs1531, %rs1529, %rs1533, %rs1535};
	st.shared.v4.b16 	[%r921+3392], {%rs1532, %rs1530, %rs1534, %rs1536};
	mov.b32 	{%rs1537, %rs1538}, %r7182;
	mov.b32 	{%rs1539, %rs1540}, %r7178;
	mov.b32 	{%rs1541, %rs1542}, %r7186;
	mov.b32 	{%rs1543, %rs1544}, %r7190;
	st.shared.v4.b16 	[%r921+3840], {%rs1539, %rs1537, %rs1541, %rs1543};
	st.shared.v4.b16 	[%r921+3904], {%rs1540, %rs1538, %rs1542, %rs1544};
	mov.b32 	{%rs1545, %rs1546}, %r7071;
	mov.b32 	{%rs1547, %rs1548}, %r7067;
	mov.b32 	{%rs1549, %rs1550}, %r7075;
	mov.b32 	{%rs1551, %rs1552}, %r7079;
	st.shared.v4.b16 	[%r922+384], {%rs1547, %rs1545, %rs1549, %rs1551};
	st.shared.v4.b16 	[%r922+448], {%rs1548, %rs1546, %rs1550, %rs1552};
	mov.b32 	{%rs1553, %rs1554}, %r7087;
	mov.b32 	{%rs1555, %rs1556}, %r7083;
	mov.b32 	{%rs1557, %rs1558}, %r7091;
	mov.b32 	{%rs1559, %rs1560}, %r7095;
	st.shared.v4.b16 	[%r922+896], {%rs1555, %rs1553, %rs1557, %rs1559};
	st.shared.v4.b16 	[%r922+960], {%rs1556, %rs1554, %rs1558, %rs1560};
	mov.b32 	{%rs1561, %rs1562}, %r7103;
	mov.b32 	{%rs1563, %rs1564}, %r7099;
	mov.b32 	{%rs1565, %rs1566}, %r7107;
	mov.b32 	{%rs1567, %rs1568}, %r7111;
	st.shared.v4.b16 	[%r922+1408], {%rs1563, %rs1561, %rs1565, %rs1567};
	st.shared.v4.b16 	[%r922+1472], {%rs1564, %rs1562, %rs1566, %rs1568};
	mov.b32 	{%rs1569, %rs1570}, %r7119;
	mov.b32 	{%rs1571, %rs1572}, %r7115;
	mov.b32 	{%rs1573, %rs1574}, %r7123;
	mov.b32 	{%rs1575, %rs1576}, %r7127;
	st.shared.v4.b16 	[%r922+1920], {%rs1571, %rs1569, %rs1573, %rs1575};
	st.shared.v4.b16 	[%r922+1984], {%rs1572, %rs1570, %rs1574, %rs1576};
	mov.b32 	{%rs1577, %rs1578}, %r7135;
	mov.b32 	{%rs1579, %rs1580}, %r7131;
	mov.b32 	{%rs1581, %rs1582}, %r7139;
	mov.b32 	{%rs1583, %rs1584}, %r7143;
	st.shared.v4.b16 	[%r922+2432], {%rs1579, %rs1577, %rs1581, %rs1583};
	st.shared.v4.b16 	[%r922+2496], {%rs1580, %rs1578, %rs1582, %rs1584};
	mov.b32 	{%rs1585, %rs1586}, %r7151;
	mov.b32 	{%rs1587, %rs1588}, %r7147;
	mov.b32 	{%rs1589, %rs1590}, %r7155;
	mov.b32 	{%rs1591, %rs1592}, %r7159;
	st.shared.v4.b16 	[%r922+2944], {%rs1587, %rs1585, %rs1589, %rs1591};
	st.shared.v4.b16 	[%r922+3008], {%rs1588, %rs1586, %rs1590, %rs1592};
	mov.b32 	{%rs1593, %rs1594}, %r7167;
	mov.b32 	{%rs1595, %rs1596}, %r7163;
	mov.b32 	{%rs1597, %rs1598}, %r7171;
	mov.b32 	{%rs1599, %rs1600}, %r7175;
	st.shared.v4.b16 	[%r922+3456], {%rs1595, %rs1593, %rs1597, %rs1599};
	st.shared.v4.b16 	[%r922+3520], {%rs1596, %rs1594, %rs1598, %rs1600};
	mov.b32 	{%rs1601, %rs1602}, %r7183;
	mov.b32 	{%rs1603, %rs1604}, %r7179;
	mov.b32 	{%rs1605, %rs1606}, %r7187;
	mov.b32 	{%rs1607, %rs1608}, %r7191;
	st.shared.v4.b16 	[%r922+3968], {%rs1603, %rs1601, %rs1605, %rs1607};
	st.shared.v4.b16 	[%r922+4032], {%rs1604, %rs1602, %rs1606, %rs1608};
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r5798, %r5799, %r5800, %r5801}, [%r5802];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r5803, %r5804, %r5805, %r5806}, [%r5807];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r5808, %r5809, %r5810, %r5811}, [%r5812];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r5813, %r5814, %r5815, %r5816}, [%r5817];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r5818, %r5819, %r5820, %r5821}, [%r5822];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r5823, %r5824, %r5825, %r5826}, [%r5827];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r5828, %r5829, %r5830, %r5831}, [%r5832];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r5833, %r5834, %r5835, %r5836}, [%r5837];
	// end inline asm
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	shfl.sync.idx.b32 	%r7192, %r2, 0, 31, -1;
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r5894,%r5895,%r5896,%r5897,%r5898,%r5899,%r5900,%r5901,%r5902,%r5903,%r5904,%r5905,%r5906,%r5907,%r5908,%r5909}, {%r5798,%r5799,%r5800,%r5801}, %rd588, 0, 1, 1, 1;
	// end inline asm
	mov.pred 	%p93, -1;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r5894,%r5895,%r5896,%r5897,%r5898,%r5899,%r5900,%r5901,%r5902,%r5903,%r5904,%r5905,%r5906,%r5907,%r5908,%r5909}, {%r5803,%r5804,%r5805,%r5806}, %rd589, %p93, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r5894,%r5895,%r5896,%r5897,%r5898,%r5899,%r5900,%r5901,%r5902,%r5903,%r5904,%r5905,%r5906,%r5907,%r5908,%r5909}, {%r5808,%r5809,%r5810,%r5811}, %rd590, %p93, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r5894,%r5895,%r5896,%r5897,%r5898,%r5899,%r5900,%r5901,%r5902,%r5903,%r5904,%r5905,%r5906,%r5907,%r5908,%r5909}, {%r5813,%r5814,%r5815,%r5816}, %rd591, %p93, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r6022,%r6023,%r6024,%r6025,%r6026,%r6027,%r6028,%r6029,%r6030,%r6031,%r6032,%r6033,%r6034,%r6035,%r6036,%r6037}, {%r5818,%r5819,%r5820,%r5821}, %rd588, 0, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r6022,%r6023,%r6024,%r6025,%r6026,%r6027,%r6028,%r6029,%r6030,%r6031,%r6032,%r6033,%r6034,%r6035,%r6036,%r6037}, {%r5823,%r5824,%r5825,%r5826}, %rd589, %p93, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r6022,%r6023,%r6024,%r6025,%r6026,%r6027,%r6028,%r6029,%r6030,%r6031,%r6032,%r6033,%r6034,%r6035,%r6036,%r6037}, {%r5828,%r5829,%r5830,%r5831}, %rd590, %p93, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r6022,%r6023,%r6024,%r6025,%r6026,%r6027,%r6028,%r6029,%r6030,%r6031,%r6032,%r6033,%r6034,%r6035,%r6036,%r6037}, {%r5833,%r5834,%r5835,%r5836}, %rd591, %p93, 1, 1, 1;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r6868, 0;
	mov.b32 	%r6126, %r2788;
	mov.b32 	%r6127, %r6868;
	mov.b32 	%r6128, %r6868;
	// begin inline asm
	// wait for regs: %r5894,%r5895,%r5896,%r5897,%r5898,%r5899,%r5900,%r5901,%r5902,%r5903,%r5904,%r5905,%r5906,%r5907,%r5908,%r5909,%r6022,%r6023,%r6024,%r6025,%r6026,%r6027,%r6028,%r6029,%r6030,%r6031,%r6032,%r6033,%r6034,%r6035,%r6036,%r6037,%r6126,%r6127,%r6128
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	sub.f32 	%r7194, %r5894, %r748;
	sub.f32 	%r7195, %r5895, %r748;
	sub.f32 	%r7196, %r5896, %r749;
	sub.f32 	%r7197, %r5897, %r749;
	sub.f32 	%r7198, %r5898, %r748;
	sub.f32 	%r7199, %r5899, %r748;
	sub.f32 	%r7200, %r5900, %r749;
	sub.f32 	%r7201, %r5901, %r749;
	sub.f32 	%r7202, %r5902, %r748;
	sub.f32 	%r7203, %r5903, %r748;
	sub.f32 	%r7204, %r5904, %r749;
	sub.f32 	%r7205, %r5905, %r749;
	sub.f32 	%r7206, %r5906, %r748;
	sub.f32 	%r7207, %r5907, %r748;
	sub.f32 	%r7208, %r5908, %r749;
	sub.f32 	%r7209, %r5909, %r749;
	sub.f32 	%r7210, %r6022, %r750;
	sub.f32 	%r7211, %r6023, %r750;
	sub.f32 	%r7212, %r6024, %r751;
	sub.f32 	%r7213, %r6025, %r751;
	sub.f32 	%r7214, %r6026, %r750;
	sub.f32 	%r7215, %r6027, %r750;
	sub.f32 	%r7216, %r6028, %r751;
	sub.f32 	%r7217, %r6029, %r751;
	sub.f32 	%r7218, %r6030, %r750;
	sub.f32 	%r7219, %r6031, %r750;
	sub.f32 	%r7220, %r6032, %r751;
	sub.f32 	%r7221, %r6033, %r751;
	sub.f32 	%r7222, %r6034, %r750;
	sub.f32 	%r7223, %r6035, %r750;
	sub.f32 	%r7224, %r6036, %r751;
	sub.f32 	%r7225, %r6037, %r751;
	ex2.approx.ftz.f32 	%r7226, %r7194;
	ex2.approx.ftz.f32 	%r7227, %r7195;
	ex2.approx.ftz.f32 	%r7228, %r7196;
	ex2.approx.ftz.f32 	%r7229, %r7197;
	ex2.approx.ftz.f32 	%r7230, %r7198;
	ex2.approx.ftz.f32 	%r7231, %r7199;
	ex2.approx.ftz.f32 	%r7232, %r7200;
	ex2.approx.ftz.f32 	%r7233, %r7201;
	ex2.approx.ftz.f32 	%r7234, %r7202;
	ex2.approx.ftz.f32 	%r7235, %r7203;
	ex2.approx.ftz.f32 	%r7236, %r7204;
	ex2.approx.ftz.f32 	%r7237, %r7205;
	ex2.approx.ftz.f32 	%r7238, %r7206;
	ex2.approx.ftz.f32 	%r7239, %r7207;
	ex2.approx.ftz.f32 	%r7240, %r7208;
	ex2.approx.ftz.f32 	%r7241, %r7209;
	ex2.approx.ftz.f32 	%r7242, %r7210;
	ex2.approx.ftz.f32 	%r7243, %r7211;
	ex2.approx.ftz.f32 	%r7244, %r7212;
	ex2.approx.ftz.f32 	%r7245, %r7213;
	ex2.approx.ftz.f32 	%r7246, %r7214;
	ex2.approx.ftz.f32 	%r7247, %r7215;
	ex2.approx.ftz.f32 	%r7248, %r7216;
	ex2.approx.ftz.f32 	%r7249, %r7217;
	ex2.approx.ftz.f32 	%r7250, %r7218;
	ex2.approx.ftz.f32 	%r7251, %r7219;
	ex2.approx.ftz.f32 	%r7252, %r7220;
	ex2.approx.ftz.f32 	%r7253, %r7221;
	ex2.approx.ftz.f32 	%r7254, %r7222;
	ex2.approx.ftz.f32 	%r7255, %r7223;
	ex2.approx.ftz.f32 	%r7256, %r7224;
	ex2.approx.ftz.f32 	%r7257, %r7225;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r6164, %r6165, %r6166, %r6167}, [%r6168];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r6169, %r6170, %r6171, %r6172}, [%r6173];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r6174, %r6175, %r6176, %r6177}, [%r6178];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r6179, %r6180, %r6181, %r6182}, [%r6183];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r6184, %r6185, %r6186, %r6187}, [%r6188];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r6189, %r6190, %r6191, %r6192}, [%r6193];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r6194, %r6195, %r6196, %r6197}, [%r6198];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r6199, %r6200, %r6201, %r6202}, [%r6203];
	// end inline asm
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	bar.sync 	0;
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r6260,%r6261,%r6262,%r6263,%r6264,%r6265,%r6266,%r6267,%r6268,%r6269,%r6270,%r6271,%r6272,%r6273,%r6274,%r6275}, {%r6164,%r6165,%r6166,%r6167}, %rd596, 0, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r6260,%r6261,%r6262,%r6263,%r6264,%r6265,%r6266,%r6267,%r6268,%r6269,%r6270,%r6271,%r6272,%r6273,%r6274,%r6275}, {%r6169,%r6170,%r6171,%r6172}, %rd597, %p93, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r6260,%r6261,%r6262,%r6263,%r6264,%r6265,%r6266,%r6267,%r6268,%r6269,%r6270,%r6271,%r6272,%r6273,%r6274,%r6275}, {%r6174,%r6175,%r6176,%r6177}, %rd598, %p93, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r6260,%r6261,%r6262,%r6263,%r6264,%r6265,%r6266,%r6267,%r6268,%r6269,%r6270,%r6271,%r6272,%r6273,%r6274,%r6275}, {%r6179,%r6180,%r6181,%r6182}, %rd599, %p93, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r6388,%r6389,%r6390,%r6391,%r6392,%r6393,%r6394,%r6395,%r6396,%r6397,%r6398,%r6399,%r6400,%r6401,%r6402,%r6403}, {%r6184,%r6185,%r6186,%r6187}, %rd596, 0, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r6388,%r6389,%r6390,%r6391,%r6392,%r6393,%r6394,%r6395,%r6396,%r6397,%r6398,%r6399,%r6400,%r6401,%r6402,%r6403}, {%r6189,%r6190,%r6191,%r6192}, %rd597, %p93, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r6388,%r6389,%r6390,%r6391,%r6392,%r6393,%r6394,%r6395,%r6396,%r6397,%r6398,%r6399,%r6400,%r6401,%r6402,%r6403}, {%r6194,%r6195,%r6196,%r6197}, %rd598, %p93, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n32k16.f32.f16.f16 {%r6388,%r6389,%r6390,%r6391,%r6392,%r6393,%r6394,%r6395,%r6396,%r6397,%r6398,%r6399,%r6400,%r6401,%r6402,%r6403}, {%r6199,%r6200,%r6201,%r6202}, %rd599, %p93, 1, 1, 1;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r6492, %r5778;
	mov.b32 	%r6493, %r6868;
	mov.b32 	%r6494, %r6868;
	// begin inline asm
	// wait for regs: %r6260,%r6261,%r6262,%r6263,%r6264,%r6265,%r6266,%r6267,%r6268,%r6269,%r6270,%r6271,%r6272,%r6273,%r6274,%r6275,%r6388,%r6389,%r6390,%r6391,%r6392,%r6393,%r6394,%r6395,%r6396,%r6397,%r6398,%r6399,%r6400,%r6401,%r6402,%r6403,%r6492,%r6493,%r6494
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	mov.b64 	{%r7258, %r7259}, %rd251;
	sub.f32 	%r7260, %r6261, %r7259;
	sub.f32 	%r7261, %r6260, %r7258;
	mul.f32 	%r7262, %r7226, %r7261;
	mul.f32 	%r7263, %r7227, %r7260;
	cvt.rn.f16x2.f32 	%r6594, %r7263, %r7262;
	mov.b64 	{%r7264, %r7265}, %rd250;
	sub.f32 	%r7266, %r6263, %r7265;
	sub.f32 	%r7267, %r6262, %r7264;
	mul.f32 	%r7268, %r7228, %r7267;
	mul.f32 	%r7269, %r7229, %r7266;
	cvt.rn.f16x2.f32 	%r6595, %r7269, %r7268;
	sub.f32 	%r7270, %r6265, %r7259;
	sub.f32 	%r7271, %r6264, %r7258;
	mul.f32 	%r7272, %r7230, %r7271;
	mul.f32 	%r7273, %r7231, %r7270;
	cvt.rn.f16x2.f32 	%r6596, %r7273, %r7272;
	sub.f32 	%r7274, %r6267, %r7265;
	sub.f32 	%r7275, %r6266, %r7264;
	mul.f32 	%r7276, %r7232, %r7275;
	mul.f32 	%r7277, %r7233, %r7274;
	cvt.rn.f16x2.f32 	%r6597, %r7277, %r7276;
	sub.f32 	%r7278, %r6269, %r7259;
	sub.f32 	%r7279, %r6268, %r7258;
	mul.f32 	%r7280, %r7234, %r7279;
	mul.f32 	%r7281, %r7235, %r7278;
	cvt.rn.f16x2.f32 	%r6662, %r7281, %r7280;
	sub.f32 	%r7282, %r6271, %r7265;
	sub.f32 	%r7283, %r6270, %r7264;
	mul.f32 	%r7284, %r7236, %r7283;
	mul.f32 	%r7285, %r7237, %r7282;
	cvt.rn.f16x2.f32 	%r6663, %r7285, %r7284;
	sub.f32 	%r7286, %r6273, %r7259;
	sub.f32 	%r7287, %r6272, %r7258;
	mul.f32 	%r7288, %r7238, %r7287;
	mul.f32 	%r7289, %r7239, %r7286;
	cvt.rn.f16x2.f32 	%r6664, %r7289, %r7288;
	sub.f32 	%r7290, %r6275, %r7265;
	sub.f32 	%r7291, %r6274, %r7264;
	mul.f32 	%r7292, %r7240, %r7291;
	mul.f32 	%r7293, %r7241, %r7290;
	cvt.rn.f16x2.f32 	%r6665, %r7293, %r7292;
	mov.b64 	{%r7294, %r7295}, %rd249;
	sub.f32 	%r7296, %r6389, %r7295;
	sub.f32 	%r7297, %r6388, %r7294;
	mul.f32 	%r7298, %r7242, %r7297;
	mul.f32 	%r7299, %r7243, %r7296;
	cvt.rn.f16x2.f32 	%r6730, %r7299, %r7298;
	mov.b64 	{%r7300, %r7301}, %rd248;
	sub.f32 	%r7302, %r6391, %r7301;
	sub.f32 	%r7303, %r6390, %r7300;
	mul.f32 	%r7304, %r7244, %r7303;
	mul.f32 	%r7305, %r7245, %r7302;
	cvt.rn.f16x2.f32 	%r6731, %r7305, %r7304;
	sub.f32 	%r7306, %r6393, %r7295;
	sub.f32 	%r7307, %r6392, %r7294;
	mul.f32 	%r7308, %r7246, %r7307;
	mul.f32 	%r7309, %r7247, %r7306;
	cvt.rn.f16x2.f32 	%r6732, %r7309, %r7308;
	sub.f32 	%r7310, %r6395, %r7301;
	sub.f32 	%r7311, %r6394, %r7300;
	mul.f32 	%r7312, %r7248, %r7311;
	mul.f32 	%r7313, %r7249, %r7310;
	cvt.rn.f16x2.f32 	%r6733, %r7313, %r7312;
	sub.f32 	%r7314, %r6397, %r7295;
	sub.f32 	%r7315, %r6396, %r7294;
	mul.f32 	%r7316, %r7250, %r7315;
	mul.f32 	%r7317, %r7251, %r7314;
	cvt.rn.f16x2.f32 	%r6798, %r7317, %r7316;
	sub.f32 	%r7318, %r6399, %r7301;
	sub.f32 	%r7319, %r6398, %r7300;
	mul.f32 	%r7320, %r7252, %r7319;
	mul.f32 	%r7321, %r7253, %r7318;
	cvt.rn.f16x2.f32 	%r6799, %r7321, %r7320;
	sub.f32 	%r7322, %r6401, %r7295;
	sub.f32 	%r7323, %r6400, %r7294;
	mul.f32 	%r7324, %r7254, %r7323;
	mul.f32 	%r7325, %r7255, %r7322;
	cvt.rn.f16x2.f32 	%r6800, %r7325, %r7324;
	sub.f32 	%r7326, %r6403, %r7301;
	sub.f32 	%r7327, %r6402, %r7300;
	mul.f32 	%r7328, %r7256, %r7327;
	mul.f32 	%r7329, %r7257, %r7326;
	cvt.rn.f16x2.f32 	%r6801, %r7329, %r7328;
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	wgmma.fence.sync.aligned;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7963,%r7964,%r7965,%r7966,%r7967,%r7968,%r7969,%r7970,%r7971,%r7972,%r7973,%r7974,%r7975,%r7976,%r7977,%r7978,%r7979,%r7980,%r7981,%r7982,%r7983,%r7984,%r7985,%r7986,%r7987,%r7988,%r7989,%r7990,%r7991,%r7992,%r7993,%r7994}, {%r6594,%r6595,%r6596,%r6597}, %rd604, %p93, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7963,%r7964,%r7965,%r7966,%r7967,%r7968,%r7969,%r7970,%r7971,%r7972,%r7973,%r7974,%r7975,%r7976,%r7977,%r7978,%r7979,%r7980,%r7981,%r7982,%r7983,%r7984,%r7985,%r7986,%r7987,%r7988,%r7989,%r7990,%r7991,%r7992,%r7993,%r7994}, {%r6662,%r6663,%r6664,%r6665}, %rd605, %p93, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7995,%r7996,%r7997,%r7998,%r7999,%r8000,%r8001,%r8002,%r8003,%r8004,%r8005,%r8006,%r8007,%r8008,%r8009,%r8010,%r8011,%r8012,%r8013,%r8014,%r8015,%r8016,%r8017,%r8018,%r8019,%r8020,%r8021,%r8022,%r8023,%r8024,%r8025,%r8026}, {%r6730,%r6731,%r6732,%r6733}, %rd604, %p93, 1, 1, 0;
	// end inline asm
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n64k16.f32.f16.f16 {%r7995,%r7996,%r7997,%r7998,%r7999,%r8000,%r8001,%r8002,%r8003,%r8004,%r8005,%r8006,%r8007,%r8008,%r8009,%r8010,%r8011,%r8012,%r8013,%r8014,%r8015,%r8016,%r8017,%r8018,%r8019,%r8020,%r8021,%r8022,%r8023,%r8024,%r8025,%r8026}, {%r6798,%r6799,%r6800,%r6801}, %rd605, %p93, 1, 1, 0;
	// end inline asm
	wgmma.commit_group.sync.aligned;
	mov.b32 	%r6866, %r1109;
	mov.b32 	%r6867, %r6868;
	// begin inline asm
	// wait for regs: %r7963,%r7964,%r7965,%r7966,%r7967,%r7968,%r7969,%r7970,%r7971,%r7972,%r7973,%r7974,%r7975,%r7976,%r7977,%r7978,%r7979,%r7980,%r7981,%r7982,%r7983,%r7984,%r7985,%r7986,%r7987,%r7988,%r7989,%r7990,%r7991,%r7992,%r7993,%r7994,%r7995,%r7996,%r7997,%r7998,%r7999,%r8000,%r8001,%r8002,%r8003,%r8004,%r8005,%r8006,%r8007,%r8008,%r8009,%r8010,%r8011,%r8012,%r8013,%r8014,%r8015,%r8016,%r8017,%r8018,%r8019,%r8020,%r8021,%r8022,%r8023,%r8024,%r8025,%r8026,%r6866,%r6867,%r6868
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	add.s64 	%rd682, %rd682, %rd637;
	add.s64 	%rd681, %rd681, %rd637;
	add.s64 	%rd680, %rd680, %rd637;
	add.s64 	%rd679, %rd679, %rd637;
	add.s32 	%r7962, %r7962, -1;
	setp.ne.b32 	%p109, %r7962, 0;
	@%p109 bra 	$L__BB0_11;
// %bb.12:                              // %._crit_edge554.loopexit
	mov.b64 	%rd714, {%r8013, %r8014};
	mov.b64 	%rd713, {%r8017, %r8018};
	mov.b64 	%rd712, {%r8021, %r8022};
	mov.b64 	%rd711, {%r8025, %r8026};
	mov.b64 	%rd710, {%r8011, %r8012};
	mov.b64 	%rd709, {%r8015, %r8016};
	mov.b64 	%rd708, {%r8019, %r8020};
	mov.b64 	%rd707, {%r8023, %r8024};
	mov.b64 	%rd706, {%r7997, %r7998};
	mov.b64 	%rd705, {%r8001, %r8002};
	mov.b64 	%rd704, {%r8005, %r8006};
	mov.b64 	%rd703, {%r8009, %r8010};
	mov.b64 	%rd702, {%r7995, %r7996};
	mov.b64 	%rd701, {%r7999, %r8000};
	mov.b64 	%rd700, {%r8003, %r8004};
	mov.b64 	%rd699, {%r8007, %r8008};
	mov.b64 	%rd698, {%r7981, %r7982};
	mov.b64 	%rd697, {%r7985, %r7986};
	mov.b64 	%rd696, {%r7989, %r7990};
	mov.b64 	%rd695, {%r7993, %r7994};
	mov.b64 	%rd694, {%r7979, %r7980};
	mov.b64 	%rd693, {%r7983, %r7984};
	mov.b64 	%rd692, {%r7987, %r7988};
	mov.b64 	%rd691, {%r7991, %r7992};
	mov.b64 	%rd690, {%r7965, %r7966};
	mov.b64 	%rd689, {%r7969, %r7970};
	mov.b64 	%rd688, {%r7973, %r7974};
	mov.b64 	%rd687, {%r7977, %r7978};
	mov.b64 	%rd686, {%r7963, %r7964};
	mov.b64 	%rd685, {%r7967, %r7968};
	mov.b64 	%rd684, {%r7971, %r7972};
	mov.b64 	%rd683, {%r7975, %r7976};
$L__BB0_13:                             // %._crit_edge554
	add.s64 	%rd617, %rd333, %rd437;
	add.s64 	%rd619, %rd617, %rd513;
	add.s64 	%rd621, %rd617, %rd515;
	add.s64 	%rd623, %rd617, %rd517;
	add.s64 	%rd625, %rd617, %rd519;
	add.s64 	%rd627, %rd617, %rd521;
	add.s64 	%rd629, %rd617, %rd523;
	add.s64 	%rd631, %rd617, %rd525;
	add.s64 	%rd633, %rd617, %rd527;
	add.s64 	%rd608, %rd619, %rd529;
	add.s64 	%rd609, %rd621, %rd529;
	add.s64 	%rd610, %rd623, %rd529;
	add.s64 	%rd611, %rd625, %rd529;
	add.s64 	%rd612, %rd627, %rd529;
	add.s64 	%rd613, %rd629, %rd529;
	add.s64 	%rd614, %rd631, %rd529;
	add.s64 	%rd615, %rd633, %rd529;
	mov.b64 	{%r7402, %r7403}, %rd686;
	mul.f32 	%r7404, %r7402, 0f3F317218;
	mul.f32 	%r7405, %r7403, 0f3F317218;
	mov.b64 	{%r7406, %r7407}, %rd690;
	mul.f32 	%r7408, %r7406, 0f3F317218;
	mul.f32 	%r7409, %r7407, 0f3F317218;
	mov.b64 	{%r7410, %r7411}, %rd685;
	mul.f32 	%r7412, %r7410, 0f3F317218;
	mul.f32 	%r7413, %r7411, 0f3F317218;
	mov.b64 	{%r7414, %r7415}, %rd689;
	mul.f32 	%r7416, %r7414, 0f3F317218;
	mul.f32 	%r7417, %r7415, 0f3F317218;
	mov.b64 	{%r7418, %r7419}, %rd684;
	mul.f32 	%r7420, %r7418, 0f3F317218;
	mul.f32 	%r7421, %r7419, 0f3F317218;
	mov.b64 	{%r7422, %r7423}, %rd688;
	mul.f32 	%r7424, %r7422, 0f3F317218;
	mul.f32 	%r7425, %r7423, 0f3F317218;
	mov.b64 	{%r7426, %r7427}, %rd683;
	mul.f32 	%r7428, %r7426, 0f3F317218;
	mul.f32 	%r7429, %r7427, 0f3F317218;
	mov.b64 	{%r7430, %r7431}, %rd687;
	mul.f32 	%r7432, %r7430, 0f3F317218;
	mul.f32 	%r7433, %r7431, 0f3F317218;
	mov.b64 	{%r7434, %r7435}, %rd694;
	mul.f32 	%r7436, %r7434, 0f3F317218;
	mul.f32 	%r7437, %r7435, 0f3F317218;
	mov.b64 	{%r7438, %r7439}, %rd698;
	mul.f32 	%r7440, %r7438, 0f3F317218;
	mul.f32 	%r7441, %r7439, 0f3F317218;
	mov.b64 	{%r7442, %r7443}, %rd693;
	mul.f32 	%r7444, %r7442, 0f3F317218;
	mul.f32 	%r7445, %r7443, 0f3F317218;
	mov.b64 	{%r7446, %r7447}, %rd697;
	mul.f32 	%r7448, %r7446, 0f3F317218;
	mul.f32 	%r7449, %r7447, 0f3F317218;
	mov.b64 	{%r7450, %r7451}, %rd692;
	mul.f32 	%r7452, %r7450, 0f3F317218;
	mul.f32 	%r7453, %r7451, 0f3F317218;
	mov.b64 	{%r7454, %r7455}, %rd696;
	mul.f32 	%r7456, %r7454, 0f3F317218;
	mul.f32 	%r7457, %r7455, 0f3F317218;
	mov.b64 	{%r7458, %r7459}, %rd691;
	mul.f32 	%r7460, %r7458, 0f3F317218;
	mul.f32 	%r7461, %r7459, 0f3F317218;
	mov.b64 	{%r7462, %r7463}, %rd695;
	mul.f32 	%r7464, %r7462, 0f3F317218;
	mul.f32 	%r7465, %r7463, 0f3F317218;
	mov.b64 	{%r7466, %r7467}, %rd702;
	mul.f32 	%r7468, %r7466, 0f3F317218;
	mul.f32 	%r7469, %r7467, 0f3F317218;
	mov.b64 	{%r7470, %r7471}, %rd706;
	mul.f32 	%r7472, %r7470, 0f3F317218;
	mul.f32 	%r7473, %r7471, 0f3F317218;
	mov.b64 	{%r7474, %r7475}, %rd701;
	mul.f32 	%r7476, %r7474, 0f3F317218;
	mul.f32 	%r7477, %r7475, 0f3F317218;
	mov.b64 	{%r7478, %r7479}, %rd705;
	mul.f32 	%r7480, %r7478, 0f3F317218;
	mul.f32 	%r7481, %r7479, 0f3F317218;
	mov.b64 	{%r7482, %r7483}, %rd700;
	mul.f32 	%r7484, %r7482, 0f3F317218;
	mul.f32 	%r7485, %r7483, 0f3F317218;
	mov.b64 	{%r7486, %r7487}, %rd704;
	mul.f32 	%r7488, %r7486, 0f3F317218;
	mul.f32 	%r7489, %r7487, 0f3F317218;
	mov.b64 	{%r7490, %r7491}, %rd699;
	mul.f32 	%r7492, %r7490, 0f3F317218;
	mul.f32 	%r7493, %r7491, 0f3F317218;
	mov.b64 	{%r7494, %r7495}, %rd703;
	mul.f32 	%r7496, %r7494, 0f3F317218;
	mul.f32 	%r7497, %r7495, 0f3F317218;
	mov.b64 	{%r7498, %r7499}, %rd710;
	mul.f32 	%r7500, %r7498, 0f3F317218;
	mul.f32 	%r7501, %r7499, 0f3F317218;
	mov.b64 	{%r7502, %r7503}, %rd714;
	mul.f32 	%r7504, %r7502, 0f3F317218;
	mul.f32 	%r7505, %r7503, 0f3F317218;
	mov.b64 	{%r7506, %r7507}, %rd709;
	mul.f32 	%r7508, %r7506, 0f3F317218;
	mul.f32 	%r7509, %r7507, 0f3F317218;
	mov.b64 	{%r7510, %r7511}, %rd713;
	mul.f32 	%r7512, %r7510, 0f3F317218;
	mul.f32 	%r7513, %r7511, 0f3F317218;
	mov.b64 	{%r7514, %r7515}, %rd708;
	mul.f32 	%r7516, %r7514, 0f3F317218;
	mul.f32 	%r7517, %r7515, 0f3F317218;
	mov.b64 	{%r7518, %r7519}, %rd712;
	mul.f32 	%r7520, %r7518, 0f3F317218;
	mul.f32 	%r7521, %r7519, 0f3F317218;
	mov.b64 	{%r7522, %r7523}, %rd707;
	mul.f32 	%r7524, %r7522, 0f3F317218;
	mul.f32 	%r7525, %r7523, 0f3F317218;
	mov.b64 	{%r7526, %r7527}, %rd711;
	mul.f32 	%r7528, %r7526, 0f3F317218;
	mul.f32 	%r7529, %r7527, 0f3F317218;
	cvt.rn.f16x2.f32 	%r7530, %r7405, %r7404;
	cvt.rn.f16x2.f32 	%r7531, %r7409, %r7408;
	cvt.rn.f16x2.f32 	%r7532, %r7413, %r7412;
	cvt.rn.f16x2.f32 	%r7533, %r7417, %r7416;
	cvt.rn.f16x2.f32 	%r7534, %r7421, %r7420;
	cvt.rn.f16x2.f32 	%r7535, %r7425, %r7424;
	cvt.rn.f16x2.f32 	%r7536, %r7429, %r7428;
	cvt.rn.f16x2.f32 	%r7537, %r7433, %r7432;
	cvt.rn.f16x2.f32 	%r7538, %r7437, %r7436;
	cvt.rn.f16x2.f32 	%r7539, %r7441, %r7440;
	cvt.rn.f16x2.f32 	%r7540, %r7445, %r7444;
	cvt.rn.f16x2.f32 	%r7541, %r7449, %r7448;
	cvt.rn.f16x2.f32 	%r7542, %r7453, %r7452;
	cvt.rn.f16x2.f32 	%r7543, %r7457, %r7456;
	cvt.rn.f16x2.f32 	%r7544, %r7461, %r7460;
	cvt.rn.f16x2.f32 	%r7545, %r7465, %r7464;
	cvt.rn.f16x2.f32 	%r7546, %r7469, %r7468;
	cvt.rn.f16x2.f32 	%r7547, %r7473, %r7472;
	cvt.rn.f16x2.f32 	%r7548, %r7477, %r7476;
	cvt.rn.f16x2.f32 	%r7549, %r7481, %r7480;
	cvt.rn.f16x2.f32 	%r7550, %r7485, %r7484;
	cvt.rn.f16x2.f32 	%r7551, %r7489, %r7488;
	cvt.rn.f16x2.f32 	%r7552, %r7493, %r7492;
	cvt.rn.f16x2.f32 	%r7553, %r7497, %r7496;
	cvt.rn.f16x2.f32 	%r7554, %r7501, %r7500;
	cvt.rn.f16x2.f32 	%r7555, %r7505, %r7504;
	cvt.rn.f16x2.f32 	%r7556, %r7509, %r7508;
	cvt.rn.f16x2.f32 	%r7557, %r7513, %r7512;
	cvt.rn.f16x2.f32 	%r7558, %r7517, %r7516;
	cvt.rn.f16x2.f32 	%r7559, %r7521, %r7520;
	cvt.rn.f16x2.f32 	%r7560, %r7525, %r7524;
	cvt.rn.f16x2.f32 	%r7561, %r7529, %r7528;
	st.shared.v4.b32 	[%r742], {%r7530, %r7532, %r7534, %r7536};
	st.shared.v4.b32 	[%r742+256], {%r7531, %r7533, %r7535, %r7537};
	st.shared.v4.b32 	[%r743], {%r7538, %r7540, %r7542, %r7544};
	st.shared.v4.b32 	[%r743+256], {%r7539, %r7541, %r7543, %r7545};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r7370, %r7371, %r7372, %r7373}, [%r7354];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r7374, %r7375, %r7376, %r7377}, [%r7359];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r7378, %r7379, %r7380, %r7381}, [%r7364];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r7382, %r7383, %r7384, %r7385}, [%r7369];
	// end inline asm
	bar.sync 	0;
	st.shared.v4.b32 	[%r742], {%r7546, %r7548, %r7550, %r7552};
	st.shared.v4.b32 	[%r742+256], {%r7547, %r7549, %r7551, %r7553};
	st.shared.v4.b32 	[%r743], {%r7554, %r7556, %r7558, %r7560};
	st.shared.v4.b32 	[%r743+256], {%r7555, %r7557, %r7559, %r7561};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r7386, %r7387, %r7388, %r7389}, [%r7354];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r7390, %r7391, %r7392, %r7393}, [%r7359];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r7394, %r7395, %r7396, %r7397}, [%r7364];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r7398, %r7399, %r7400, %r7401}, [%r7369];
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd608 + 0 ], { %r7370, %r7371, %r7372, %r7373 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd609 + 0 ], { %r7374, %r7375, %r7376, %r7377 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd610 + 0 ], { %r7378, %r7379, %r7380, %r7381 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd611 + 0 ], { %r7382, %r7383, %r7384, %r7385 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd612 + 0 ], { %r7386, %r7387, %r7388, %r7389 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd613 + 0 ], { %r7390, %r7391, %r7392, %r7393 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd614 + 0 ], { %r7394, %r7395, %r7396, %r7397 };
	// end inline asm
	// begin inline asm
	st.global.v4.b32 [ %rd615 + 0 ], { %r7398, %r7399, %r7400, %r7401 };
	// end inline asm
	ret;
                                        // -- End function
}
