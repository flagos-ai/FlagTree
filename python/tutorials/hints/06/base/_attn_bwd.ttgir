#blocked = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 4], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>
#loc1 = loc("Q")
#loc2 = loc("K")
#loc3 = loc("V")
#loc4 = loc("sm_scale")
#loc5 = loc("DO")
#loc6 = loc("DQ")
#loc7 = loc("DK")
#loc8 = loc("DV")
#loc9 = loc("M")
#loc10 = loc("D")
#loc11 = loc("stride_z")
#loc12 = loc("stride_h")
#loc13 = loc("stride_tok")
#loc14 = loc("H")
#loc15 = loc("N_CTX")
#mma = #ttg.nvidia_mma<{versionMajor = 3, versionMinor = 0, warpsPerCTA = [4, 1], instrShape = [16, 64, 16]}>
#mma1 = #ttg.nvidia_mma<{versionMajor = 3, versionMinor = 0, warpsPerCTA = [4, 1], instrShape = [16, 16, 16]}>
#mma2 = #ttg.nvidia_mma<{versionMajor = 3, versionMinor = 0, warpsPerCTA = [4, 1], instrShape = [16, 32, 16]}>
#shared = #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>
#shared1 = #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = true, elementBitWidth = 16}>
#shared2 = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @_attn_bwd(%Q: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("Q"), %K: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("K"), %V: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("V"), %sm_scale: f32 loc("sm_scale"), %DO: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("DO"), %DQ: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("DQ"), %DK: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("DK"), %DV: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("DV"), %M: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("M"), %D: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("D"), %stride_z: i32 {tt.divisibility = 16 : i32} loc("stride_z"), %stride_h: i32 {tt.divisibility = 16 : i32} loc("stride_h"), %stride_tok: i32 {tt.divisibility = 16 : i32} loc("stride_tok"), %H: i32 {tt.divisibility = 16 : i32} loc("H"), %N_CTX: i32 {tt.divisibility = 16 : i32} loc("N_CTX")) attributes {noinline = false} {
    %cst = arith.constant dense<0.693147182> : tensor<128x64xf32, #mma> loc(#loc)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<128x64xf32, #mma> loc(#loc)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<128x16xf32, #mma1> loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i32 = arith.constant 1 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %c128_i32 = arith.constant 128 : i32 loc(#loc)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<128x32xf32, #mma2> loc(#loc)
    %c-1_i32 = arith.constant -1 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %c5_i32 = arith.constant 5 : i32 loc(#loc)
    %c2_i32 = arith.constant 2 : i32 loc(#loc)
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %cst_3 = arith.constant dense<true> : tensor<64x16xi1, #blocked> loc(#loc)
    %cst_4 = arith.constant dense<true> : tensor<16xi1, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %cst_5 = arith.constant dense<true> : tensor<16x64xi1, #blocked1> loc(#loc)
    %c48_i32 = arith.constant 48 : i32 loc(#loc)
    %c160_i32 = arith.constant 160 : i32 loc(#loc)
    %c192_i32 = arith.constant 192 : i32 loc(#loc)
    %c224_i32 = arith.constant 224 : i32 loc(#loc)
    %0 = tt.get_program_id z : i32 loc(#loc)
    %1 = arith.muli %0, %N_CTX : i32 loc(#loc)
    %2 = arith.extsi %1 : i32 to i64 loc(#loc)
    %3 = arith.remsi %0, %H : i32 loc(#loc)
    %4 = arith.muli %stride_h, %3 : i32 loc(#loc)
    %5 = arith.divsi %0, %H : i32 loc(#loc)
    %6 = arith.muli %stride_z, %5 : i32 loc(#loc)
    %7 = arith.addi %4, %6 : i32 loc(#loc)
    %8 = arith.extsi %7 : i32 to i64 loc(#loc)
    %9 = tt.get_program_id x : i32 loc(#loc)
    %10 = tt.addptr %Q, %8 : !tt.ptr<f16>, i64 loc(#loc)
    %11 = tt.addptr %K, %8 : !tt.ptr<f16>, i64 loc(#loc)
    %12 = tt.addptr %V, %8 : !tt.ptr<f16>, i64 loc(#loc)
    %13 = tt.addptr %DO, %8 : !tt.ptr<f16>, i64 loc(#loc)
    %14 = tt.addptr %DQ, %8 : !tt.ptr<f16>, i64 loc(#loc)
    %15 = tt.addptr %DK, %8 : !tt.ptr<f16>, i64 loc(#loc)
    %16 = tt.addptr %DV, %8 : !tt.ptr<f16>, i64 loc(#loc)
    %17 = tt.addptr %M, %2 : !tt.ptr<f32>, i64 loc(#loc)
    %18 = tt.addptr %D, %2 : !tt.ptr<f32>, i64 loc(#loc)
    %19 = arith.muli %9, %c128_i32 : i32 loc(#loc)
    %20 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
    %21 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #mma1}>> loc(#loc)
    %22 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #blocked2> loc(#loc)
    %23 = tt.splat %19 : i32 -> tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
    %24 = tt.splat %19 : i32 -> tensor<128xi32, #ttg.slice<{dim = 1, parent = #mma1}>> loc(#loc)
    %25 = tt.splat %19 : i32 -> tensor<128xi32, #blocked2> loc(#loc)
    %26 = arith.addi %23, %20 : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
    %27 = arith.addi %24, %21 : tensor<128xi32, #ttg.slice<{dim = 1, parent = #mma1}>> loc(#loc)
    %28 = arith.addi %25, %22 : tensor<128xi32, #blocked2> loc(#loc)
    %29 = tt.expand_dims %26 {axis = 1 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1xi32, #blocked1> loc(#loc)
    %30 = tt.expand_dims %27 {axis = 1 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #mma1}>> -> tensor<128x1xi32, #mma1> loc(#loc)
    %31 = tt.splat %stride_tok : i32 -> tensor<128x1xi32, #blocked1> loc(#loc)
    %32 = arith.muli %29, %31 : tensor<128x1xi32, #blocked1> loc(#loc)
    %33 = tt.splat %11 : !tt.ptr<f16> -> tensor<128x1x!tt.ptr<f16>, #blocked1> loc(#loc)
    %34 = tt.addptr %33, %32 : tensor<128x1x!tt.ptr<f16>, #blocked1>, tensor<128x1xi32, #blocked1> loc(#loc)
    %35 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc)
    %36 = tt.expand_dims %35 {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x64xi32, #blocked1> loc(#loc)
    %37 = tt.broadcast %34 : tensor<128x1x!tt.ptr<f16>, #blocked1> -> tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %38 = tt.broadcast %36 : tensor<1x64xi32, #blocked1> -> tensor<128x64xi32, #blocked1> loc(#loc)
    %39 = tt.addptr %37, %38 : tensor<128x64x!tt.ptr<f16>, #blocked1>, tensor<128x64xi32, #blocked1> loc(#loc)
    %40 = tt.load %39 : tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %41 = ttg.local_alloc %40 : (tensor<128x64xf16, #blocked1>) -> !ttg.memdesc<128x64xf16, #shared, #smem> loc(#loc)
    %42 = tt.splat %12 : !tt.ptr<f16> -> tensor<128x1x!tt.ptr<f16>, #blocked1> loc(#loc)
    %43 = tt.addptr %42, %32 : tensor<128x1x!tt.ptr<f16>, #blocked1>, tensor<128x1xi32, #blocked1> loc(#loc)
    %44 = tt.broadcast %43 : tensor<128x1x!tt.ptr<f16>, #blocked1> -> tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %45 = tt.addptr %44, %38 : tensor<128x64x!tt.ptr<f16>, #blocked1>, tensor<128x64xi32, #blocked1> loc(#loc)
    %46 = tt.load %45 : tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %47 = ttg.local_alloc %46 : (tensor<128x64xf16, #blocked1>) -> !ttg.memdesc<128x64xf16, #shared, #smem> loc(#loc)
    %48 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %49 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %50 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
    %51 = tt.splat %19 : i32 -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %52 = tt.splat %19 : i32 -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
    %53 = arith.addi %51, %48 : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %54 = arith.addi %52, %50 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
    %55 = tt.expand_dims %53 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x16xi32, #blocked> loc(#loc)
    %56 = tt.splat %stride_tok : i32 -> tensor<1x16xi32, #blocked> loc(#loc)
    %57 = arith.muli %55, %56 : tensor<1x16xi32, #blocked> loc(#loc)
    %58 = tt.splat %10 : !tt.ptr<f16> -> tensor<1x16x!tt.ptr<f16>, #blocked> loc(#loc)
    %59 = tt.addptr %58, %57 : tensor<1x16x!tt.ptr<f16>, #blocked>, tensor<1x16xi32, #blocked> loc(#loc)
    %60 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc)
    %61 = tt.expand_dims %60 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<64x1xi32, #blocked> loc(#loc)
    %62 = tt.broadcast %59 : tensor<1x16x!tt.ptr<f16>, #blocked> -> tensor<64x16x!tt.ptr<f16>, #blocked> loc(#loc)
    %63 = tt.broadcast %61 : tensor<64x1xi32, #blocked> -> tensor<64x16xi32, #blocked> loc(#loc)
    %64 = tt.addptr %62, %63 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
    %65 = tt.expand_dims %54 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<16x1xi32, #blocked1> loc(#loc)
    %66 = tt.splat %stride_tok : i32 -> tensor<16x1xi32, #blocked1> loc(#loc)
    %67 = arith.muli %65, %66 : tensor<16x1xi32, #blocked1> loc(#loc)
    %68 = tt.splat %13 : !tt.ptr<f16> -> tensor<16x1x!tt.ptr<f16>, #blocked1> loc(#loc)
    %69 = tt.addptr %68, %67 : tensor<16x1x!tt.ptr<f16>, #blocked1>, tensor<16x1xi32, #blocked1> loc(#loc)
    %70 = tt.broadcast %69 : tensor<16x1x!tt.ptr<f16>, #blocked1> -> tensor<16x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %71 = tt.broadcast %36 : tensor<1x64xi32, #blocked1> -> tensor<16x64xi32, #blocked1> loc(#loc)
    %72 = tt.addptr %70, %71 : tensor<16x64x!tt.ptr<f16>, #blocked1>, tensor<16x64xi32, #blocked1> loc(#loc)
    %73 = tt.splat %17 : !tt.ptr<f32> -> tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %74 = tt.broadcast %30 : tensor<128x1xi32, #mma1> -> tensor<128x16xi32, #mma1> loc(#loc)
    %75 = tt.splat %18 : !tt.ptr<f32> -> tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %76 = arith.muli %stride_tok, %c16_i32 : i32 loc(#loc)
    %77 = tt.splat %76 : i32 -> tensor<64x16xi32, #blocked> loc(#loc)
    %78 = tt.splat %76 : i32 -> tensor<16x64xi32, #blocked1> loc(#loc)
    %79 = ttg.local_alloc : () -> !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> loc(#loc)
    %80 = ttg.local_alloc : () -> !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> loc(#loc)
    %81 = ttg.local_alloc : () -> !ttg.memdesc<5x16x64xf16, #shared, #smem, mutable> loc(#loc)
    %82 = ttg.local_alloc : () -> !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> loc(#loc)
    %83 = ttg.memdesc_index %79[%c0_i32] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %84 = ttg.async_copy_global_to_local %64, %83 mask %cst_3 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %85 = ttg.async_commit_group tokens %84 loc(#loc)
    %86 = tt.splat %19 : i32 -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %87 = arith.addi %86, %49 : tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %88 = tt.addptr %73, %87 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %89 = ttg.memdesc_index %80[%c0_i32] : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> -> !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %90 = ttg.async_copy_global_to_local %88, %89 mask %cst_4 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>> -> <16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %91 = ttg.async_commit_group tokens %90 loc(#loc)
    %92 = ttg.memdesc_index %81[%c0_i32] : !ttg.memdesc<5x16x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
    %93 = ttg.async_copy_global_to_local %72, %92 mask %cst_5 : tensor<16x64x!tt.ptr<f16>, #blocked1> -> <16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
    %94 = ttg.async_commit_group tokens %93 loc(#loc)
    %95 = tt.addptr %75, %87 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %96 = ttg.memdesc_index %82[%c0_i32] : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> -> !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %97 = ttg.async_copy_global_to_local %95, %96 mask %cst_4 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>> -> <16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %98 = ttg.async_commit_group tokens %97 loc(#loc)
    %99 = arith.addi %19, %c16_i32 : i32 loc(#loc)
    %100 = tt.addptr %64, %77 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
    %101 = tt.addptr %72, %78 : tensor<16x64x!tt.ptr<f16>, #blocked1>, tensor<16x64xi32, #blocked1> loc(#loc)
    %102 = ttg.memdesc_index %79[%c1_i32] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %103 = ttg.async_copy_global_to_local %100, %102 mask %cst_3 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %104 = ttg.async_commit_group tokens %103 loc(#loc)
    %105 = tt.splat %99 : i32 -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %106 = arith.addi %105, %49 : tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %107 = tt.addptr %73, %106 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %108 = ttg.memdesc_index %80[%c1_i32] : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> -> !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %109 = ttg.async_copy_global_to_local %107, %108 mask %cst_4 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>> -> <16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %110 = ttg.async_commit_group tokens %109 loc(#loc)
    %111 = ttg.memdesc_index %81[%c1_i32] : !ttg.memdesc<5x16x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
    %112 = ttg.async_copy_global_to_local %101, %111 mask %cst_5 : tensor<16x64x!tt.ptr<f16>, #blocked1> -> <16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
    %113 = ttg.async_commit_group tokens %112 loc(#loc)
    %114 = tt.addptr %75, %106 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %115 = ttg.memdesc_index %82[%c1_i32] : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> -> !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %116 = ttg.async_copy_global_to_local %114, %115 mask %cst_4 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>> -> <16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %117 = ttg.async_commit_group tokens %116 loc(#loc)
    %118 = arith.addi %19, %c32_i32 : i32 loc(#loc)
    %119 = tt.addptr %100, %77 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
    %120 = tt.addptr %101, %78 : tensor<16x64x!tt.ptr<f16>, #blocked1>, tensor<16x64xi32, #blocked1> loc(#loc)
    %121 = ttg.memdesc_index %79[%c2_i32] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %122 = ttg.async_copy_global_to_local %119, %121 mask %cst_3 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %123 = ttg.async_commit_group tokens %122 loc(#loc)
    %124 = tt.splat %118 : i32 -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %125 = arith.addi %124, %49 : tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %126 = tt.addptr %73, %125 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %127 = ttg.memdesc_index %80[%c2_i32] : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> -> !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %128 = ttg.async_copy_global_to_local %126, %127 mask %cst_4 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>> -> <16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %129 = ttg.async_commit_group tokens %128 loc(#loc)
    %130 = ttg.memdesc_index %81[%c2_i32] : !ttg.memdesc<5x16x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
    %131 = ttg.async_copy_global_to_local %120, %130 mask %cst_5 : tensor<16x64x!tt.ptr<f16>, #blocked1> -> <16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
    %132 = ttg.async_commit_group tokens %131 loc(#loc)
    %133 = tt.addptr %75, %125 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %134 = ttg.memdesc_index %82[%c2_i32] : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> -> !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %135 = ttg.async_copy_global_to_local %133, %134 mask %cst_4 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>> -> <16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %136 = ttg.async_commit_group tokens %135 loc(#loc)
    %137 = arith.addi %19, %c48_i32 : i32 loc(#loc)
    %138 = tt.addptr %119, %77 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
    %139 = tt.addptr %120, %78 : tensor<16x64x!tt.ptr<f16>, #blocked1>, tensor<16x64xi32, #blocked1> loc(#loc)
    %140 = ttg.memdesc_index %79[%c3_i32] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %141 = ttg.async_copy_global_to_local %138, %140 mask %cst_3 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %142 = ttg.async_commit_group tokens %141 loc(#loc)
    %143 = tt.splat %137 : i32 -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %144 = arith.addi %143, %49 : tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %145 = tt.addptr %73, %144 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %146 = ttg.memdesc_index %80[%c3_i32] : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> -> !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %147 = ttg.async_copy_global_to_local %145, %146 mask %cst_4 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>> -> <16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %148 = ttg.async_commit_group tokens %147 loc(#loc)
    %149 = ttg.memdesc_index %81[%c3_i32] : !ttg.memdesc<5x16x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
    %150 = ttg.async_copy_global_to_local %139, %149 mask %cst_5 : tensor<16x64x!tt.ptr<f16>, #blocked1> -> <16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
    %151 = ttg.async_commit_group tokens %150 loc(#loc)
    %152 = tt.addptr %75, %144 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
    %153 = ttg.memdesc_index %82[%c3_i32] : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> -> !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %154 = ttg.async_copy_global_to_local %152, %153 mask %cst_4 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>> -> <16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
    %155 = ttg.async_commit_group tokens %154 loc(#loc)
    ttng.fence_async_shared {bCluster = false} loc(#loc)
    %curr_m:29 = scf.for %curr_m_40 = %c0_i32 to %c8_i32 step %c1_i32 iter_args(%arg16 = %cst_0, %arg17 = %cst_0, %arg18 = %137, %arg19 = %138, %arg20 = %139, %arg21 = %c3_i32, %arg22 = %c-1_i32, %arg23 = %c3_i32, %arg24 = %c-1_i32, %arg25 = %85, %arg26 = %104, %arg27 = %123, %arg28 = %142, %arg29 = %91, %arg30 = %110, %arg31 = %129, %arg32 = %148, %arg33 = %87, %arg34 = %106, %arg35 = %125, %arg36 = %144, %arg37 = %94, %arg38 = %113, %arg39 = %132, %arg40 = %151, %arg41 = %98, %arg42 = %117, %arg43 = %136, %arg44 = %155) -> (tensor<128x64xf32, #mma>, tensor<128x64xf32, #mma>, i32, tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<16x64x!tt.ptr<f16>, #blocked1>, i32, i32, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>>, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token)  : i32 {
      %curr_m_41 = arith.cmpi slt, %curr_m_40, %c4_i32 : i32 loc(#loc29)
      %curr_m_42 = arith.addi %arg24, %c1_i32 : i32 loc(#loc29)
      %curr_m_43 = arith.cmpi sge, %curr_m_42, %c4_i32 : i32 loc(#loc29)
      %curr_m_44 = arith.select %curr_m_43, %c0_i32, %curr_m_42 : i32 loc(#loc29)
      %curr_m_45 = arith.addi %arg22, %c1_i32 : i32 loc(#loc29)
      %curr_m_46 = arith.cmpi sge, %curr_m_45, %c5_i32 : i32 loc(#loc29)
      %curr_m_47 = arith.select %curr_m_46, %c0_i32, %curr_m_45 : i32 loc(#loc29)
      %402 = ttg.async_wait %arg25, %arg29, %arg37, %arg41 {num = 12 : i32} loc(#loc)
      %403 = ttg.memdesc_index %79[%curr_m_47] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %404 = ttg.memdesc_trans %403 {order = array<i32: 1, 0>} : !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> -> !ttg.memdesc<16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
      %405 = ttg.memdesc_index %80[%curr_m_44] : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> -> !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
      %406 = ttg.local_load %405 token %402 : !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> -> tensor<16xf32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
      %407 = ttng.warp_group_dot %41, %403, %cst_1 {inputPrecision = 0 : i32, isAsync = true} : !ttg.memdesc<128x64xf16, #shared, #smem> * !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> -> tensor<128x16xf32, #mma1> loc(#loc)
      %408:3 = ttng.warp_group_dot_wait %407, %41, %403 {pendings = 0 : i32} : tensor<128x16xf32, #mma1>, !ttg.memdesc<128x64xf16, #shared, #smem>, !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %409 = tt.expand_dims %406 {axis = 0 : i32} : tensor<16xf32, #ttg.slice<{dim = 0, parent = #mma1}>> -> tensor<1x16xf32, #mma1> loc(#loc)
      %410 = tt.broadcast %409 : tensor<1x16xf32, #mma1> -> tensor<128x16xf32, #mma1> loc(#loc)
      %411 = arith.subf %408#0, %410 : tensor<128x16xf32, #mma1> loc(#loc)
      %412 = math.exp2 %411 : tensor<128x16xf32, #mma1> loc(#loc)
      %413 = tt.expand_dims %arg33 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> -> tensor<1x16xi32, #mma1> loc(#loc)
      %414 = tt.broadcast %413 : tensor<1x16xi32, #mma1> -> tensor<128x16xi32, #mma1> loc(#loc)
      %415 = arith.cmpi sge, %414, %74 : tensor<128x16xi32, #mma1> loc(#loc)
      %416 = arith.select %415, %412, %cst_1 : tensor<128x16xi1, #mma1>, tensor<128x16xf32, #mma1> loc(#loc)
      %417 = ttg.memdesc_index %81[%curr_m_47] : !ttg.memdesc<5x16x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
      %418 = ttg.memdesc_trans %417 {order = array<i32: 1, 0>} : !ttg.memdesc<16x64xf16, #shared, #smem, mutable, 5x16x64> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %419 = arith.truncf %416 : tensor<128x16xf32, #mma1> to tensor<128x16xf16, #mma1> loc(#loc)
      %420 = ttg.convert_layout %419 : tensor<128x16xf16, #mma1> -> tensor<128x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc)
      %421 = ttng.warp_group_dot %420, %417, %arg17 {inputPrecision = 0 : i32, isAsync = true} : tensor<128x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * !ttg.memdesc<16x64xf16, #shared, #smem, mutable, 5x16x64> -> tensor<128x64xf32, #mma> loc(#loc)
      %422 = ttg.memdesc_index %82[%curr_m_44] : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> -> !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
      %423 = ttg.local_load %422 token %402 : !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> -> tensor<16xf32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
      %424 = ttng.warp_group_dot %47, %418, %cst_1 {inputPrecision = 0 : i32, isAsync = true} : !ttg.memdesc<128x64xf16, #shared, #smem> * !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> -> tensor<128x16xf32, #mma1> loc(#loc)
      %425:3 = ttng.warp_group_dot_wait %424, %47, %418 {pendings = 0 : i32} : tensor<128x16xf32, #mma1>, !ttg.memdesc<128x64xf16, #shared, #smem>, !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %426 = tt.expand_dims %423 {axis = 0 : i32} : tensor<16xf32, #ttg.slice<{dim = 0, parent = #mma1}>> -> tensor<1x16xf32, #mma1> loc(#loc)
      %427 = tt.broadcast %426 : tensor<1x16xf32, #mma1> -> tensor<128x16xf32, #mma1> loc(#loc)
      %428 = arith.subf %425#0, %427 : tensor<128x16xf32, #mma1> loc(#loc)
      %429 = arith.mulf %416, %428 : tensor<128x16xf32, #mma1> loc(#loc)
      %430 = arith.truncf %429 : tensor<128x16xf32, #mma1> to tensor<128x16xf16, #mma1> loc(#loc)
      %431 = ttg.convert_layout %430 : tensor<128x16xf16, #mma1> -> tensor<128x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc)
      %432 = ttng.warp_group_dot %431, %404, %arg16 {inputPrecision = 0 : i32, isAsync = true} : tensor<128x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * !ttg.memdesc<16x64xf16, #shared, #smem, mutable, 5x16x64> -> tensor<128x64xf32, #mma> loc(#loc)
      %433 = arith.addi %arg18, %c16_i32 : i32 loc(#loc)
      %434 = tt.addptr %arg19, %77 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
      %435 = tt.addptr %arg20, %78 : tensor<16x64x!tt.ptr<f16>, #blocked1>, tensor<16x64xi32, #blocked1> loc(#loc)
      %curr_m_48 = arith.addi %arg23, %c1_i32 : i32 loc(#loc29)
      %curr_m_49 = arith.cmpi sge, %curr_m_48, %c4_i32 : i32 loc(#loc29)
      %curr_m_50 = arith.select %curr_m_49, %c0_i32, %curr_m_48 : i32 loc(#loc29)
      %curr_m_51 = arith.addi %arg21, %c1_i32 : i32 loc(#loc29)
      %curr_m_52 = arith.cmpi sge, %curr_m_51, %c5_i32 : i32 loc(#loc29)
      %curr_m_53 = arith.select %curr_m_52, %c0_i32, %curr_m_51 : i32 loc(#loc29)
      %436 = ttg.memdesc_index %79[%curr_m_53] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %curr_m_54 = tt.splat %curr_m_41 : i1 -> tensor<64x16xi1, #blocked> loc(#loc29)
      %437 = ttg.async_copy_global_to_local %434, %436 mask %curr_m_54 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %438 = ttg.async_commit_group tokens %437 loc(#loc)
      %439 = tt.splat %433 : i32 -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
      %440 = arith.addi %439, %49 : tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
      %441 = tt.addptr %73, %440 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
      %442 = ttg.memdesc_index %80[%curr_m_50] : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> -> !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
      %curr_m_55 = tt.splat %curr_m_41 : i1 -> tensor<16xi1, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc29)
      %443 = ttg.async_copy_global_to_local %441, %442 mask %curr_m_55 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>> -> <16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
      %444 = ttg.async_commit_group tokens %443 loc(#loc)
      %445 = ttg.memdesc_index %81[%curr_m_53] : !ttg.memdesc<5x16x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
      %curr_m_56 = tt.splat %curr_m_41 : i1 -> tensor<16x64xi1, #blocked1> loc(#loc29)
      %446 = ttg.async_copy_global_to_local %435, %445 mask %curr_m_56 : tensor<16x64x!tt.ptr<f16>, #blocked1> -> <16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
      %447 = ttg.async_commit_group tokens %446 loc(#loc)
      %448 = tt.addptr %75, %440 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
      %449 = ttg.memdesc_index %82[%curr_m_50] : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> -> !ttg.memdesc<16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
      %450 = ttg.async_copy_global_to_local %448, %449 mask %curr_m_55 : tensor<16x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma1}>> -> <16xf32, #shared2, #smem, mutable, 4x16> loc(#loc)
      %451 = ttg.async_commit_group tokens %450 loc(#loc)
      scf.yield %432, %421, %433, %434, %435, %curr_m_53, %curr_m_47, %curr_m_50, %curr_m_44, %arg26, %arg27, %arg28, %438, %arg30, %arg31, %arg32, %444, %arg34, %arg35, %arg36, %440, %arg38, %arg39, %arg40, %447, %arg42, %arg43, %arg44, %451 : tensor<128x64xf32, #mma>, tensor<128x64xf32, #mma>, i32, tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<16x64x!tt.ptr<f16>, #blocked1>, i32, i32, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>>, tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>>, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token loc(#loc29)
    } loc(#loc29)
    %curr_m_6:2 = ttng.warp_group_dot_wait %curr_m#1, %curr_m#0 {pendings = 0 : i32} : tensor<128x64xf32, #mma>, tensor<128x64xf32, #mma> loc(#loc29)
    %curr_m_7 = ttg.async_wait {num = 0 : i32} loc(#loc29)
    ttg.local_dealloc %82 : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> loc(#loc29)
    ttg.local_dealloc %81 : !ttg.memdesc<5x16x64xf16, #shared, #smem, mutable> loc(#loc29)
    ttg.local_dealloc %80 : !ttg.memdesc<4x16xf32, #shared2, #smem, mutable> loc(#loc29)
    ttg.local_dealloc %79 : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> loc(#loc29)
    %156 = arith.addi %19, %c128_i32 : i32 loc(#loc)
    %157 = arith.subi %N_CTX, %156 : i32 loc(#loc)
    %158 = arith.divsi %157, %c32_i32 : i32 loc(#loc)
    %159 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %160 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %161 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
    %162 = tt.splat %156 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %163 = tt.splat %156 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
    %164 = arith.addi %162, %159 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %165 = arith.addi %163, %161 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
    %166 = tt.expand_dims %164 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc)
    %167 = tt.splat %stride_tok : i32 -> tensor<1x32xi32, #blocked> loc(#loc)
    %168 = arith.muli %166, %167 : tensor<1x32xi32, #blocked> loc(#loc)
    %169 = tt.splat %10 : !tt.ptr<f16> -> tensor<1x32x!tt.ptr<f16>, #blocked> loc(#loc)
    %170 = tt.addptr %169, %168 : tensor<1x32x!tt.ptr<f16>, #blocked>, tensor<1x32xi32, #blocked> loc(#loc)
    %171 = tt.broadcast %170 : tensor<1x32x!tt.ptr<f16>, #blocked> -> tensor<64x32x!tt.ptr<f16>, #blocked> loc(#loc)
    %172 = tt.broadcast %61 : tensor<64x1xi32, #blocked> -> tensor<64x32xi32, #blocked> loc(#loc)
    %173 = tt.addptr %171, %172 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
    %174 = tt.expand_dims %165 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc)
    %175 = tt.splat %stride_tok : i32 -> tensor<32x1xi32, #blocked1> loc(#loc)
    %176 = arith.muli %174, %175 : tensor<32x1xi32, #blocked1> loc(#loc)
    %177 = tt.splat %13 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked1> loc(#loc)
    %178 = tt.addptr %177, %176 : tensor<32x1x!tt.ptr<f16>, #blocked1>, tensor<32x1xi32, #blocked1> loc(#loc)
    %179 = tt.broadcast %178 : tensor<32x1x!tt.ptr<f16>, #blocked1> -> tensor<32x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %180 = tt.broadcast %36 : tensor<1x64xi32, #blocked1> -> tensor<32x64xi32, #blocked1> loc(#loc)
    %181 = tt.addptr %179, %180 : tensor<32x64x!tt.ptr<f16>, #blocked1>, tensor<32x64xi32, #blocked1> loc(#loc)
    %182 = tt.splat %17 : !tt.ptr<f32> -> tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %183 = tt.splat %18 : !tt.ptr<f32> -> tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %184 = arith.muli %stride_tok, %c32_i32 : i32 loc(#loc)
    %185 = tt.splat %184 : i32 -> tensor<64x32xi32, #blocked> loc(#loc)
    %186 = tt.splat %184 : i32 -> tensor<32x64xi32, #blocked1> loc(#loc)
    %187 = ttg.local_alloc : () -> !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> loc(#loc)
    %188 = ttg.local_alloc : () -> !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> loc(#loc)
    %189 = ttg.local_alloc : () -> !ttg.memdesc<5x32x64xf16, #shared, #smem, mutable> loc(#loc)
    %190 = ttg.local_alloc : () -> !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> loc(#loc)
    %curr_m_8 = arith.cmpi sgt, %158, %c0_i32 : i32 loc(#loc29)
    %191 = ttg.memdesc_index %187[%c0_i32] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %curr_m_9 = tt.splat %curr_m_8 : i1 -> tensor<64x32xi1, #blocked> loc(#loc29)
    %192 = ttg.async_copy_global_to_local %173, %191 mask %curr_m_9 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %193 = ttg.async_commit_group tokens %192 loc(#loc)
    %194 = tt.splat %156 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %195 = arith.addi %194, %160 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %196 = tt.addptr %182, %195 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>>, tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %197 = ttg.memdesc_index %188[%c0_i32] : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> -> !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %curr_m_10 = tt.splat %curr_m_8 : i1 -> tensor<32xi1, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc29)
    %198 = ttg.async_copy_global_to_local %196, %197 mask %curr_m_10 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>> -> <32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %199 = ttg.async_commit_group tokens %198 loc(#loc)
    %200 = ttg.memdesc_index %189[%c0_i32] : !ttg.memdesc<5x32x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
    %curr_m_11 = tt.splat %curr_m_8 : i1 -> tensor<32x64xi1, #blocked1> loc(#loc29)
    %201 = ttg.async_copy_global_to_local %181, %200 mask %curr_m_11 : tensor<32x64x!tt.ptr<f16>, #blocked1> -> <32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
    %202 = ttg.async_commit_group tokens %201 loc(#loc)
    %203 = tt.addptr %183, %195 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>>, tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %204 = ttg.memdesc_index %190[%c0_i32] : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> -> !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %205 = ttg.async_copy_global_to_local %203, %204 mask %curr_m_10 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>> -> <32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %206 = ttg.async_commit_group tokens %205 loc(#loc)
    %curr_m_12 = arith.cmpi sgt, %158, %c1_i32 : i32 loc(#loc29)
    %207 = arith.addi %19, %c160_i32 : i32 loc(#loc)
    %208 = tt.addptr %173, %185 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
    %209 = tt.addptr %181, %186 : tensor<32x64x!tt.ptr<f16>, #blocked1>, tensor<32x64xi32, #blocked1> loc(#loc)
    %210 = ttg.memdesc_index %187[%c1_i32] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %curr_m_13 = tt.splat %curr_m_12 : i1 -> tensor<64x32xi1, #blocked> loc(#loc29)
    %211 = ttg.async_copy_global_to_local %208, %210 mask %curr_m_13 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %212 = ttg.async_commit_group tokens %211 loc(#loc)
    %213 = tt.splat %207 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %214 = arith.addi %213, %160 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %215 = tt.addptr %182, %214 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>>, tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %216 = ttg.memdesc_index %188[%c1_i32] : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> -> !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %curr_m_14 = tt.splat %curr_m_12 : i1 -> tensor<32xi1, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc29)
    %217 = ttg.async_copy_global_to_local %215, %216 mask %curr_m_14 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>> -> <32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %218 = ttg.async_commit_group tokens %217 loc(#loc)
    %219 = ttg.memdesc_index %189[%c1_i32] : !ttg.memdesc<5x32x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
    %curr_m_15 = tt.splat %curr_m_12 : i1 -> tensor<32x64xi1, #blocked1> loc(#loc29)
    %220 = ttg.async_copy_global_to_local %209, %219 mask %curr_m_15 : tensor<32x64x!tt.ptr<f16>, #blocked1> -> <32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
    %221 = ttg.async_commit_group tokens %220 loc(#loc)
    %222 = tt.addptr %183, %214 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>>, tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %223 = ttg.memdesc_index %190[%c1_i32] : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> -> !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %224 = ttg.async_copy_global_to_local %222, %223 mask %curr_m_14 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>> -> <32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %225 = ttg.async_commit_group tokens %224 loc(#loc)
    %curr_m_16 = arith.cmpi sgt, %158, %c2_i32 : i32 loc(#loc29)
    %226 = arith.addi %19, %c192_i32 : i32 loc(#loc)
    %227 = tt.addptr %208, %185 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
    %228 = tt.addptr %209, %186 : tensor<32x64x!tt.ptr<f16>, #blocked1>, tensor<32x64xi32, #blocked1> loc(#loc)
    %229 = ttg.memdesc_index %187[%c2_i32] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %curr_m_17 = tt.splat %curr_m_16 : i1 -> tensor<64x32xi1, #blocked> loc(#loc29)
    %230 = ttg.async_copy_global_to_local %227, %229 mask %curr_m_17 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %231 = ttg.async_commit_group tokens %230 loc(#loc)
    %232 = tt.splat %226 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %233 = arith.addi %232, %160 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %234 = tt.addptr %182, %233 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>>, tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %235 = ttg.memdesc_index %188[%c2_i32] : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> -> !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %curr_m_18 = tt.splat %curr_m_16 : i1 -> tensor<32xi1, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc29)
    %236 = ttg.async_copy_global_to_local %234, %235 mask %curr_m_18 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>> -> <32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %237 = ttg.async_commit_group tokens %236 loc(#loc)
    %238 = ttg.memdesc_index %189[%c2_i32] : !ttg.memdesc<5x32x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
    %curr_m_19 = tt.splat %curr_m_16 : i1 -> tensor<32x64xi1, #blocked1> loc(#loc29)
    %239 = ttg.async_copy_global_to_local %228, %238 mask %curr_m_19 : tensor<32x64x!tt.ptr<f16>, #blocked1> -> <32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
    %240 = ttg.async_commit_group tokens %239 loc(#loc)
    %241 = tt.addptr %183, %233 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>>, tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %242 = ttg.memdesc_index %190[%c2_i32] : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> -> !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %243 = ttg.async_copy_global_to_local %241, %242 mask %curr_m_18 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>> -> <32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %244 = ttg.async_commit_group tokens %243 loc(#loc)
    %curr_m_20 = arith.cmpi sgt, %158, %c3_i32 : i32 loc(#loc29)
    %245 = arith.addi %19, %c224_i32 : i32 loc(#loc)
    %246 = tt.addptr %227, %185 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
    %247 = tt.addptr %228, %186 : tensor<32x64x!tt.ptr<f16>, #blocked1>, tensor<32x64xi32, #blocked1> loc(#loc)
    %248 = ttg.memdesc_index %187[%c3_i32] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %curr_m_21 = tt.splat %curr_m_20 : i1 -> tensor<64x32xi1, #blocked> loc(#loc29)
    %249 = ttg.async_copy_global_to_local %246, %248 mask %curr_m_21 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %250 = ttg.async_commit_group tokens %249 loc(#loc)
    %251 = tt.splat %245 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %252 = arith.addi %251, %160 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %253 = tt.addptr %182, %252 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>>, tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %254 = ttg.memdesc_index %188[%c3_i32] : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> -> !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %curr_m_22 = tt.splat %curr_m_20 : i1 -> tensor<32xi1, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc29)
    %255 = ttg.async_copy_global_to_local %253, %254 mask %curr_m_22 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>> -> <32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %256 = ttg.async_commit_group tokens %255 loc(#loc)
    %257 = ttg.memdesc_index %189[%c3_i32] : !ttg.memdesc<5x32x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
    %curr_m_23 = tt.splat %curr_m_20 : i1 -> tensor<32x64xi1, #blocked1> loc(#loc29)
    %258 = ttg.async_copy_global_to_local %247, %257 mask %curr_m_23 : tensor<32x64x!tt.ptr<f16>, #blocked1> -> <32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
    %259 = ttg.async_commit_group tokens %258 loc(#loc)
    %260 = tt.addptr %183, %252 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>>, tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
    %261 = ttg.memdesc_index %190[%c3_i32] : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> -> !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %262 = ttg.async_copy_global_to_local %260, %261 mask %curr_m_22 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>> -> <32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
    %263 = ttg.async_commit_group tokens %262 loc(#loc)
    ttng.fence_async_shared {bCluster = false} loc(#loc)
    %curr_m_24:25 = scf.for %curr_m_40 = %c0_i32 to %158 step %c1_i32 iter_args(%curr_m_41 = %curr_m_6#1, %curr_m_42 = %curr_m_6#0, %arg18 = %245, %arg19 = %246, %arg20 = %247, %arg21 = %c3_i32, %arg22 = %c-1_i32, %arg23 = %c3_i32, %arg24 = %c-1_i32, %arg25 = %193, %arg26 = %212, %arg27 = %231, %arg28 = %250, %arg29 = %199, %arg30 = %218, %arg31 = %237, %arg32 = %256, %arg33 = %202, %arg34 = %221, %arg35 = %240, %arg36 = %259, %arg37 = %206, %arg38 = %225, %arg39 = %244, %arg40 = %263) -> (tensor<128x64xf32, #mma>, tensor<128x64xf32, #mma>, i32, tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<32x64x!tt.ptr<f16>, #blocked1>, i32, i32, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token)  : i32 {
      %curr_m_43 = arith.subi %158, %c4_i32 : i32 loc(#loc29)
      %curr_m_44 = arith.cmpi slt, %curr_m_40, %curr_m_43 : i32 loc(#loc29)
      %curr_m_45 = arith.addi %arg24, %c1_i32 : i32 loc(#loc29)
      %curr_m_46 = arith.cmpi sge, %curr_m_45, %c4_i32 : i32 loc(#loc29)
      %curr_m_47 = arith.select %curr_m_46, %c0_i32, %curr_m_45 : i32 loc(#loc29)
      %curr_m_48 = arith.addi %arg22, %c1_i32 : i32 loc(#loc29)
      %curr_m_49 = arith.cmpi sge, %curr_m_48, %c5_i32 : i32 loc(#loc29)
      %curr_m_50 = arith.select %curr_m_49, %c0_i32, %curr_m_48 : i32 loc(#loc29)
      %402 = ttg.async_wait %arg25, %arg29, %arg33, %arg37 {num = 12 : i32} loc(#loc)
      %403 = ttg.memdesc_index %187[%curr_m_50] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %404 = ttg.memdesc_trans %403 {order = array<i32: 1, 0>} : !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> -> !ttg.memdesc<32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
      %405 = ttg.memdesc_index %188[%curr_m_47] : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> -> !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
      %406 = ttg.local_load %405 token %402 : !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> -> tensor<32xf32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
      %407 = ttng.warp_group_dot %41, %403, %cst_2 {inputPrecision = 0 : i32, isAsync = true} : !ttg.memdesc<128x64xf16, #shared, #smem> * !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> -> tensor<128x32xf32, #mma2> loc(#loc)
      %408:3 = ttng.warp_group_dot_wait %407, %41, %403 {pendings = 0 : i32} : tensor<128x32xf32, #mma2>, !ttg.memdesc<128x64xf16, #shared, #smem>, !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %409 = tt.expand_dims %406 {axis = 0 : i32} : tensor<32xf32, #ttg.slice<{dim = 0, parent = #mma2}>> -> tensor<1x32xf32, #mma2> loc(#loc)
      %410 = tt.broadcast %409 : tensor<1x32xf32, #mma2> -> tensor<128x32xf32, #mma2> loc(#loc)
      %411 = arith.subf %408#0, %410 : tensor<128x32xf32, #mma2> loc(#loc)
      %412 = math.exp2 %411 : tensor<128x32xf32, #mma2> loc(#loc)
      %413 = ttg.memdesc_index %189[%curr_m_50] : !ttg.memdesc<5x32x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
      %414 = ttg.memdesc_trans %413 {order = array<i32: 1, 0>} : !ttg.memdesc<32x64xf16, #shared, #smem, mutable, 5x32x64> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %415 = arith.truncf %412 : tensor<128x32xf32, #mma2> to tensor<128x32xf16, #mma2> loc(#loc)
      %416 = ttg.convert_layout %415 : tensor<128x32xf16, #mma2> -> tensor<128x32xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc)
      %417 = ttng.warp_group_dot %416, %413, %curr_m_42 {inputPrecision = 0 : i32, isAsync = true} : tensor<128x32xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * !ttg.memdesc<32x64xf16, #shared, #smem, mutable, 5x32x64> -> tensor<128x64xf32, #mma> loc(#loc)
      %418 = ttg.memdesc_index %190[%curr_m_47] : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> -> !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
      %419 = ttg.local_load %418 token %402 : !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> -> tensor<32xf32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
      %420 = ttng.warp_group_dot %47, %414, %cst_2 {inputPrecision = 0 : i32, isAsync = true} : !ttg.memdesc<128x64xf16, #shared, #smem> * !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> -> tensor<128x32xf32, #mma2> loc(#loc)
      %421:3 = ttng.warp_group_dot_wait %420, %47, %414 {pendings = 0 : i32} : tensor<128x32xf32, #mma2>, !ttg.memdesc<128x64xf16, #shared, #smem>, !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %422 = tt.expand_dims %419 {axis = 0 : i32} : tensor<32xf32, #ttg.slice<{dim = 0, parent = #mma2}>> -> tensor<1x32xf32, #mma2> loc(#loc)
      %423 = tt.broadcast %422 : tensor<1x32xf32, #mma2> -> tensor<128x32xf32, #mma2> loc(#loc)
      %424 = arith.subf %421#0, %423 : tensor<128x32xf32, #mma2> loc(#loc)
      %425 = arith.mulf %412, %424 : tensor<128x32xf32, #mma2> loc(#loc)
      %426 = arith.truncf %425 : tensor<128x32xf32, #mma2> to tensor<128x32xf16, #mma2> loc(#loc)
      %427 = ttg.convert_layout %426 : tensor<128x32xf16, #mma2> -> tensor<128x32xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc)
      %428 = ttng.warp_group_dot %427, %404, %curr_m_41 {inputPrecision = 0 : i32, isAsync = true} : tensor<128x32xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * !ttg.memdesc<32x64xf16, #shared, #smem, mutable, 5x32x64> -> tensor<128x64xf32, #mma> loc(#loc)
      %429 = arith.addi %arg18, %c32_i32 : i32 loc(#loc)
      %430 = tt.addptr %arg19, %185 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
      %431 = tt.addptr %arg20, %186 : tensor<32x64x!tt.ptr<f16>, #blocked1>, tensor<32x64xi32, #blocked1> loc(#loc)
      %curr_m_51 = arith.addi %arg23, %c1_i32 : i32 loc(#loc29)
      %curr_m_52 = arith.cmpi sge, %curr_m_51, %c4_i32 : i32 loc(#loc29)
      %curr_m_53 = arith.select %curr_m_52, %c0_i32, %curr_m_51 : i32 loc(#loc29)
      %curr_m_54 = arith.addi %arg21, %c1_i32 : i32 loc(#loc29)
      %curr_m_55 = arith.cmpi sge, %curr_m_54, %c5_i32 : i32 loc(#loc29)
      %curr_m_56 = arith.select %curr_m_55, %c0_i32, %curr_m_54 : i32 loc(#loc29)
      %432 = ttg.memdesc_index %187[%curr_m_56] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %curr_m_57 = tt.splat %curr_m_44 : i1 -> tensor<64x32xi1, #blocked> loc(#loc29)
      %433 = ttg.async_copy_global_to_local %430, %432 mask %curr_m_57 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %434 = ttg.async_commit_group tokens %433 loc(#loc)
      %435 = tt.splat %429 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
      %436 = arith.addi %435, %160 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
      %437 = tt.addptr %182, %436 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>>, tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
      %438 = ttg.memdesc_index %188[%curr_m_53] : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> -> !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
      %curr_m_58 = tt.splat %curr_m_44 : i1 -> tensor<32xi1, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc29)
      %439 = ttg.async_copy_global_to_local %437, %438 mask %curr_m_58 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>> -> <32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
      %440 = ttg.async_commit_group tokens %439 loc(#loc)
      %441 = ttg.memdesc_index %189[%curr_m_56] : !ttg.memdesc<5x32x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
      %curr_m_59 = tt.splat %curr_m_44 : i1 -> tensor<32x64xi1, #blocked1> loc(#loc29)
      %442 = ttg.async_copy_global_to_local %431, %441 mask %curr_m_59 : tensor<32x64x!tt.ptr<f16>, #blocked1> -> <32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
      %443 = ttg.async_commit_group tokens %442 loc(#loc)
      %444 = tt.addptr %183, %436 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>>, tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma2}>> loc(#loc)
      %445 = ttg.memdesc_index %190[%curr_m_53] : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> -> !ttg.memdesc<32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
      %446 = ttg.async_copy_global_to_local %444, %445 mask %curr_m_58 : tensor<32x!tt.ptr<f32>, #ttg.slice<{dim = 0, parent = #mma2}>> -> <32xf32, #shared2, #smem, mutable, 4x32> loc(#loc)
      %447 = ttg.async_commit_group tokens %446 loc(#loc)
      scf.yield %428, %417, %429, %430, %431, %curr_m_56, %curr_m_50, %curr_m_53, %curr_m_47, %arg26, %arg27, %arg28, %434, %arg30, %arg31, %arg32, %440, %arg34, %arg35, %arg36, %443, %arg38, %arg39, %arg40, %447 : tensor<128x64xf32, #mma>, tensor<128x64xf32, #mma>, i32, tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<32x64x!tt.ptr<f16>, #blocked1>, i32, i32, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token loc(#loc29)
    } loc(#loc29)
    %curr_m_25:2 = ttng.warp_group_dot_wait %curr_m_24#1, %curr_m_24#0 {pendings = 0 : i32} : tensor<128x64xf32, #mma>, tensor<128x64xf32, #mma> loc(#loc29)
    %curr_m_26 = ttg.async_wait {num = 0 : i32} loc(#loc29)
    ttg.local_dealloc %190 : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> loc(#loc29)
    ttg.local_dealloc %189 : !ttg.memdesc<5x32x64xf16, #shared, #smem, mutable> loc(#loc29)
    ttg.local_dealloc %188 : !ttg.memdesc<4x32xf32, #shared2, #smem, mutable> loc(#loc29)
    ttg.local_dealloc %187 : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> loc(#loc29)
    %264 = tt.splat %16 : !tt.ptr<f16> -> tensor<128x1x!tt.ptr<f16>, #blocked1> loc(#loc)
    %265 = tt.addptr %264, %32 : tensor<128x1x!tt.ptr<f16>, #blocked1>, tensor<128x1xi32, #blocked1> loc(#loc)
    %266 = tt.broadcast %265 : tensor<128x1x!tt.ptr<f16>, #blocked1> -> tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %267 = tt.addptr %266, %38 : tensor<128x64x!tt.ptr<f16>, #blocked1>, tensor<128x64xi32, #blocked1> loc(#loc)
    %268 = arith.truncf %curr_m_25#0 : tensor<128x64xf32, #mma> to tensor<128x64xf16, #mma> loc(#loc)
    %269 = ttg.convert_layout %268 : tensor<128x64xf16, #mma> -> tensor<128x64xf16, #blocked1> loc(#loc)
    tt.store %267, %269 : tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %270 = tt.splat %sm_scale : f32 -> tensor<128x64xf32, #mma> loc(#loc)
    %271 = arith.mulf %curr_m_25#1, %270 : tensor<128x64xf32, #mma> loc(#loc)
    %272 = tt.splat %15 : !tt.ptr<f16> -> tensor<128x1x!tt.ptr<f16>, #blocked1> loc(#loc)
    %273 = tt.addptr %272, %32 : tensor<128x1x!tt.ptr<f16>, #blocked1>, tensor<128x1xi32, #blocked1> loc(#loc)
    %274 = tt.broadcast %273 : tensor<128x1x!tt.ptr<f16>, #blocked1> -> tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %275 = tt.addptr %274, %38 : tensor<128x64x!tt.ptr<f16>, #blocked1>, tensor<128x64xi32, #blocked1> loc(#loc)
    %276 = arith.truncf %271 : tensor<128x64xf32, #mma> to tensor<128x64xf16, #mma> loc(#loc)
    %277 = ttg.convert_layout %276 : tensor<128x64xf16, #mma> -> tensor<128x64xf16, #blocked1> loc(#loc)
    tt.store %275, %277 : tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %278 = tt.splat %10 : !tt.ptr<f16> -> tensor<128x1x!tt.ptr<f16>, #blocked1> loc(#loc)
    %279 = tt.addptr %278, %32 : tensor<128x1x!tt.ptr<f16>, #blocked1>, tensor<128x1xi32, #blocked1> loc(#loc)
    %280 = tt.broadcast %279 : tensor<128x1x!tt.ptr<f16>, #blocked1> -> tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %281 = tt.addptr %280, %38 : tensor<128x64x!tt.ptr<f16>, #blocked1>, tensor<128x64xi32, #blocked1> loc(#loc)
    %282 = tt.load %281 : tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %283 = ttg.local_alloc %282 : (tensor<128x64xf16, #blocked1>) -> !ttg.memdesc<128x64xf16, #shared, #smem> loc(#loc)
    %284 = tt.splat %13 : !tt.ptr<f16> -> tensor<128x1x!tt.ptr<f16>, #blocked1> loc(#loc)
    %285 = tt.addptr %284, %32 : tensor<128x1x!tt.ptr<f16>, #blocked1>, tensor<128x1xi32, #blocked1> loc(#loc)
    %286 = tt.broadcast %285 : tensor<128x1x!tt.ptr<f16>, #blocked1> -> tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %287 = tt.addptr %286, %38 : tensor<128x64x!tt.ptr<f16>, #blocked1>, tensor<128x64xi32, #blocked1> loc(#loc)
    %288 = tt.load %287 : tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %289 = ttg.local_alloc %288 : (tensor<128x64xf16, #blocked1>) -> !ttg.memdesc<128x64xf16, #shared, #smem> loc(#loc)
    %290 = tt.splat %17 : !tt.ptr<f32> -> tensor<128x!tt.ptr<f32>, #blocked2> loc(#loc)
    %291 = tt.addptr %290, %28 : tensor<128x!tt.ptr<f32>, #blocked2>, tensor<128xi32, #blocked2> loc(#loc)
    %292 = tt.load %291 : tensor<128x!tt.ptr<f32>, #blocked2> loc(#loc)
    %293 = ttg.convert_layout %292 : tensor<128xf32, #blocked2> -> tensor<128xf32, #ttg.slice<{dim = 1, parent = #mma1}>> loc(#loc)
    %294 = tt.expand_dims %293 {axis = 1 : i32} : tensor<128xf32, #ttg.slice<{dim = 1, parent = #mma1}>> -> tensor<128x1xf32, #mma1> loc(#loc)
    %295 = ttg.convert_layout %292 : tensor<128xf32, #blocked2> -> tensor<128xf32, #ttg.slice<{dim = 1, parent = #mma2}>> loc(#loc)
    %296 = tt.expand_dims %295 {axis = 1 : i32} : tensor<128xf32, #ttg.slice<{dim = 1, parent = #mma2}>> -> tensor<128x1xf32, #mma2> loc(#loc)
    %297 = tt.splat %11 : !tt.ptr<f16> -> tensor<1x16x!tt.ptr<f16>, #blocked> loc(#loc)
    %298 = tt.addptr %297, %57 : tensor<1x16x!tt.ptr<f16>, #blocked>, tensor<1x16xi32, #blocked> loc(#loc)
    %299 = tt.broadcast %298 : tensor<1x16x!tt.ptr<f16>, #blocked> -> tensor<64x16x!tt.ptr<f16>, #blocked> loc(#loc)
    %300 = tt.addptr %299, %63 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
    %301 = tt.splat %12 : !tt.ptr<f16> -> tensor<1x16x!tt.ptr<f16>, #blocked> loc(#loc)
    %302 = tt.addptr %301, %57 : tensor<1x16x!tt.ptr<f16>, #blocked>, tensor<1x16xi32, #blocked> loc(#loc)
    %303 = tt.broadcast %302 : tensor<1x16x!tt.ptr<f16>, #blocked> -> tensor<64x16x!tt.ptr<f16>, #blocked> loc(#loc)
    %304 = tt.addptr %303, %63 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
    %305 = tt.splat %18 : !tt.ptr<f32> -> tensor<128x!tt.ptr<f32>, #blocked2> loc(#loc)
    %306 = tt.addptr %305, %28 : tensor<128x!tt.ptr<f32>, #blocked2>, tensor<128xi32, #blocked2> loc(#loc)
    %307 = tt.load %306 : tensor<128x!tt.ptr<f32>, #blocked2> loc(#loc)
    %308 = ttg.convert_layout %307 : tensor<128xf32, #blocked2> -> tensor<128xf32, #ttg.slice<{dim = 1, parent = #mma1}>> loc(#loc)
    %309 = tt.broadcast %294 : tensor<128x1xf32, #mma1> -> tensor<128x16xf32, #mma1> loc(#loc)
    %310 = tt.expand_dims %308 {axis = 1 : i32} : tensor<128xf32, #ttg.slice<{dim = 1, parent = #mma1}>> -> tensor<128x1xf32, #mma1> loc(#loc)
    %311 = tt.broadcast %310 : tensor<128x1xf32, #mma1> -> tensor<128x16xf32, #mma1> loc(#loc)
    %312 = ttg.local_alloc : () -> !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> loc(#loc)
    %313 = ttg.local_alloc : () -> !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> loc(#loc)
    %314 = ttg.memdesc_index %312[%c0_i32] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %315 = ttg.async_copy_global_to_local %300, %314 mask %cst_3 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %316 = ttg.async_commit_group tokens %315 loc(#loc)
    %317 = ttg.memdesc_index %313[%c0_i32] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %318 = ttg.async_copy_global_to_local %304, %317 mask %cst_3 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %319 = ttg.async_commit_group tokens %318 loc(#loc)
    %320 = tt.addptr %300, %77 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
    %321 = tt.addptr %304, %77 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
    %322 = ttg.memdesc_index %312[%c1_i32] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %323 = ttg.async_copy_global_to_local %320, %322 mask %cst_3 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %324 = ttg.async_commit_group tokens %323 loc(#loc)
    %325 = ttg.memdesc_index %313[%c1_i32] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %326 = ttg.async_copy_global_to_local %321, %325 mask %cst_3 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %327 = ttg.async_commit_group tokens %326 loc(#loc)
    %328 = tt.addptr %320, %77 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
    %329 = tt.addptr %321, %77 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
    %330 = ttg.memdesc_index %312[%c2_i32] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %331 = ttg.async_copy_global_to_local %328, %330 mask %cst_3 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %332 = ttg.async_commit_group tokens %331 loc(#loc)
    %333 = ttg.memdesc_index %313[%c2_i32] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %334 = ttg.async_copy_global_to_local %329, %333 mask %cst_3 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %335 = ttg.async_commit_group tokens %334 loc(#loc)
    %336 = tt.addptr %328, %77 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
    %337 = tt.addptr %329, %77 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
    %338 = ttg.memdesc_index %312[%c3_i32] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %339 = ttg.async_copy_global_to_local %336, %338 mask %cst_3 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %340 = ttg.async_commit_group tokens %339 loc(#loc)
    %341 = ttg.memdesc_index %313[%c3_i32] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %342 = ttg.async_copy_global_to_local %337, %341 mask %cst_3 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
    %343 = ttg.async_commit_group tokens %342 loc(#loc)
    ttng.fence_async_shared {bCluster = false} loc(#loc)
    %curr_n:14 = scf.for %curr_n_40 = %c0_i32 to %c8_i32 step %c1_i32 iter_args(%arg16 = %cst_0, %arg17 = %19, %arg18 = %336, %arg19 = %337, %arg20 = %c3_i32, %arg21 = %c-1_i32, %arg22 = %316, %arg23 = %324, %arg24 = %332, %arg25 = %340, %arg26 = %319, %arg27 = %327, %arg28 = %335, %arg29 = %343) -> (tensor<128x64xf32, #mma>, i32, tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16x!tt.ptr<f16>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token)  : i32 {
      %curr_n_41 = arith.cmpi slt, %curr_n_40, %c4_i32 : i32 loc(#loc28)
      %curr_n_42 = arith.addi %arg21, %c1_i32 : i32 loc(#loc28)
      %curr_n_43 = arith.cmpi sge, %curr_n_42, %c5_i32 : i32 loc(#loc28)
      %curr_n_44 = arith.select %curr_n_43, %c0_i32, %curr_n_42 : i32 loc(#loc28)
      %402 = ttg.async_wait %arg22, %arg26 {num = 6 : i32} loc(#loc)
      %403 = ttg.memdesc_index %312[%curr_n_44] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %404 = ttg.memdesc_trans %403 {order = array<i32: 1, 0>} : !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> -> !ttg.memdesc<16x64xf16, #shared, #smem, mutable, 5x16x64> loc(#loc)
      %405 = ttg.memdesc_index %313[%curr_n_44] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %406 = ttng.warp_group_dot %283, %403, %cst_1 {inputPrecision = 0 : i32, isAsync = true} : !ttg.memdesc<128x64xf16, #shared, #smem> * !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> -> tensor<128x16xf32, #mma1> loc(#loc)
      %407:3 = ttng.warp_group_dot_wait %406, %283, %403 {pendings = 0 : i32} : tensor<128x16xf32, #mma1>, !ttg.memdesc<128x64xf16, #shared, #smem>, !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %408 = arith.subf %407#0, %309 : tensor<128x16xf32, #mma1> loc(#loc)
      %409 = math.exp2 %408 : tensor<128x16xf32, #mma1> loc(#loc)
      %410 = tt.splat %arg17 : i32 -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
      %411 = arith.addi %410, %49 : tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> loc(#loc)
      %412 = tt.expand_dims %411 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #mma1}>> -> tensor<1x16xi32, #mma1> loc(#loc)
      %413 = tt.broadcast %412 : tensor<1x16xi32, #mma1> -> tensor<128x16xi32, #mma1> loc(#loc)
      %414 = arith.cmpi sge, %74, %413 : tensor<128x16xi32, #mma1> loc(#loc)
      %415 = arith.select %414, %409, %cst_1 : tensor<128x16xi1, #mma1>, tensor<128x16xf32, #mma1> loc(#loc)
      %416 = ttng.warp_group_dot %289, %405, %cst_1 {inputPrecision = 0 : i32, isAsync = true} : !ttg.memdesc<128x64xf16, #shared, #smem> * !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> -> tensor<128x16xf32, #mma1> loc(#loc)
      %417:3 = ttng.warp_group_dot_wait %416, %289, %405 {pendings = 0 : i32} : tensor<128x16xf32, #mma1>, !ttg.memdesc<128x64xf16, #shared, #smem>, !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %418 = arith.subf %417#0, %311 : tensor<128x16xf32, #mma1> loc(#loc)
      %419 = arith.mulf %415, %418 : tensor<128x16xf32, #mma1> loc(#loc)
      %420 = arith.truncf %419 : tensor<128x16xf32, #mma1> to tensor<128x16xf16, #mma1> loc(#loc)
      %421 = ttg.convert_layout %420 : tensor<128x16xf16, #mma1> -> tensor<128x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc)
      %422 = ttng.warp_group_dot %421, %404, %arg16 {inputPrecision = 0 : i32, isAsync = true} : tensor<128x16xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * !ttg.memdesc<16x64xf16, #shared, #smem, mutable, 5x16x64> -> tensor<128x64xf32, #mma> loc(#loc)
      %423 = arith.addi %arg17, %c16_i32 : i32 loc(#loc)
      %424 = tt.addptr %arg18, %77 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
      %425 = tt.addptr %arg19, %77 : tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16xi32, #blocked> loc(#loc)
      %curr_n_45 = arith.addi %arg20, %c1_i32 : i32 loc(#loc28)
      %curr_n_46 = arith.cmpi sge, %curr_n_45, %c5_i32 : i32 loc(#loc28)
      %curr_n_47 = arith.select %curr_n_46, %c0_i32, %curr_n_45 : i32 loc(#loc28)
      %426 = ttg.memdesc_index %312[%curr_n_47] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %curr_n_48 = tt.splat %curr_n_41 : i1 -> tensor<64x16xi1, #blocked> loc(#loc28)
      %427 = ttg.async_copy_global_to_local %424, %426 mask %curr_n_48 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %428 = ttg.async_commit_group tokens %427 loc(#loc)
      %429 = ttg.memdesc_index %313[%curr_n_47] : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %430 = ttg.async_copy_global_to_local %425, %429 mask %curr_n_48 : tensor<64x16x!tt.ptr<f16>, #blocked> -> <64x16xf16, #shared1, #smem, mutable, 5x64x16> loc(#loc)
      %431 = ttg.async_commit_group tokens %430 loc(#loc)
      scf.yield %422, %423, %424, %425, %curr_n_47, %curr_n_44, %arg23, %arg24, %arg25, %428, %arg27, %arg28, %arg29, %431 : tensor<128x64xf32, #mma>, i32, tensor<64x16x!tt.ptr<f16>, #blocked>, tensor<64x16x!tt.ptr<f16>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token loc(#loc28)
    } loc(#loc28)
    %curr_n_27 = ttng.warp_group_dot_wait %curr_n#0 {pendings = 0 : i32} : tensor<128x64xf32, #mma> loc(#loc28)
    %curr_n_28 = ttg.async_wait {num = 0 : i32} loc(#loc28)
    ttg.local_dealloc %313 : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> loc(#loc28)
    ttg.local_dealloc %312 : !ttg.memdesc<5x64x16xf16, #shared1, #smem, mutable> loc(#loc28)
    %344 = ttg.convert_layout %307 : tensor<128xf32, #blocked2> -> tensor<128xf32, #ttg.slice<{dim = 1, parent = #mma2}>> loc(#loc)
    %345 = arith.divsi %19, %c32_i32 : i32 loc(#loc)
    %346 = arith.muli %345, %c32_i32 : i32 loc(#loc)
    %347 = arith.subi %19, %346 : i32 loc(#loc)
    %348 = tt.splat %347 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %349 = arith.addi %348, %159 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %350 = tt.expand_dims %349 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc)
    %351 = arith.muli %350, %167 : tensor<1x32xi32, #blocked> loc(#loc)
    %352 = tt.splat %11 : !tt.ptr<f16> -> tensor<1x32x!tt.ptr<f16>, #blocked> loc(#loc)
    %353 = tt.addptr %352, %351 : tensor<1x32x!tt.ptr<f16>, #blocked>, tensor<1x32xi32, #blocked> loc(#loc)
    %354 = tt.broadcast %353 : tensor<1x32x!tt.ptr<f16>, #blocked> -> tensor<64x32x!tt.ptr<f16>, #blocked> loc(#loc)
    %355 = tt.addptr %354, %172 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
    %356 = tt.splat %12 : !tt.ptr<f16> -> tensor<1x32x!tt.ptr<f16>, #blocked> loc(#loc)
    %357 = tt.addptr %356, %351 : tensor<1x32x!tt.ptr<f16>, #blocked>, tensor<1x32xi32, #blocked> loc(#loc)
    %358 = tt.broadcast %357 : tensor<1x32x!tt.ptr<f16>, #blocked> -> tensor<64x32x!tt.ptr<f16>, #blocked> loc(#loc)
    %359 = tt.addptr %358, %172 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
    %360 = tt.broadcast %296 : tensor<128x1xf32, #mma2> -> tensor<128x32xf32, #mma2> loc(#loc)
    %361 = tt.expand_dims %344 {axis = 1 : i32} : tensor<128xf32, #ttg.slice<{dim = 1, parent = #mma2}>> -> tensor<128x1xf32, #mma2> loc(#loc)
    %362 = tt.broadcast %361 : tensor<128x1xf32, #mma2> -> tensor<128x32xf32, #mma2> loc(#loc)
    %363 = ttg.local_alloc : () -> !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> loc(#loc)
    %364 = ttg.local_alloc : () -> !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> loc(#loc)
    %curr_n_29 = arith.cmpi sgt, %345, %c0_i32 : i32 loc(#loc26)
    %365 = ttg.memdesc_index %363[%c0_i32] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %curr_n_30 = tt.splat %curr_n_29 : i1 -> tensor<64x32xi1, #blocked> loc(#loc26)
    %366 = ttg.async_copy_global_to_local %355, %365 mask %curr_n_30 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %367 = ttg.async_commit_group tokens %366 loc(#loc)
    %368 = ttg.memdesc_index %364[%c0_i32] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %369 = ttg.async_copy_global_to_local %359, %368 mask %curr_n_30 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %370 = ttg.async_commit_group tokens %369 loc(#loc)
    %curr_n_31 = arith.cmpi sgt, %345, %c1_i32 : i32 loc(#loc26)
    %371 = tt.addptr %355, %185 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
    %372 = tt.addptr %359, %185 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
    %373 = ttg.memdesc_index %363[%c1_i32] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %curr_n_32 = tt.splat %curr_n_31 : i1 -> tensor<64x32xi1, #blocked> loc(#loc26)
    %374 = ttg.async_copy_global_to_local %371, %373 mask %curr_n_32 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %375 = ttg.async_commit_group tokens %374 loc(#loc)
    %376 = ttg.memdesc_index %364[%c1_i32] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %377 = ttg.async_copy_global_to_local %372, %376 mask %curr_n_32 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %378 = ttg.async_commit_group tokens %377 loc(#loc)
    %curr_n_33 = arith.cmpi sgt, %345, %c2_i32 : i32 loc(#loc26)
    %379 = tt.addptr %371, %185 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
    %380 = tt.addptr %372, %185 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
    %381 = ttg.memdesc_index %363[%c2_i32] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %curr_n_34 = tt.splat %curr_n_33 : i1 -> tensor<64x32xi1, #blocked> loc(#loc26)
    %382 = ttg.async_copy_global_to_local %379, %381 mask %curr_n_34 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %383 = ttg.async_commit_group tokens %382 loc(#loc)
    %384 = ttg.memdesc_index %364[%c2_i32] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %385 = ttg.async_copy_global_to_local %380, %384 mask %curr_n_34 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %386 = ttg.async_commit_group tokens %385 loc(#loc)
    %curr_n_35 = arith.cmpi sgt, %345, %c3_i32 : i32 loc(#loc26)
    %387 = tt.addptr %379, %185 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
    %388 = tt.addptr %380, %185 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
    %389 = ttg.memdesc_index %363[%c3_i32] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %curr_n_36 = tt.splat %curr_n_35 : i1 -> tensor<64x32xi1, #blocked> loc(#loc26)
    %390 = ttg.async_copy_global_to_local %387, %389 mask %curr_n_36 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %391 = ttg.async_commit_group tokens %390 loc(#loc)
    %392 = ttg.memdesc_index %364[%c3_i32] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %393 = ttg.async_copy_global_to_local %388, %392 mask %curr_n_36 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
    %394 = ttg.async_commit_group tokens %393 loc(#loc)
    ttng.fence_async_shared {bCluster = false} loc(#loc)
    %curr_n_37:13 = scf.for %curr_n_40 = %c0_i32 to %345 step %c1_i32 iter_args(%curr_n_41 = %curr_n_27, %arg17 = %387, %arg18 = %388, %arg19 = %c3_i32, %arg20 = %c-1_i32, %arg21 = %367, %arg22 = %375, %arg23 = %383, %arg24 = %391, %arg25 = %370, %arg26 = %378, %arg27 = %386, %arg28 = %394) -> (tensor<128x64xf32, #mma>, tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32x!tt.ptr<f16>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token)  : i32 {
      %curr_n_42 = arith.subi %345, %c4_i32 : i32 loc(#loc26)
      %curr_n_43 = arith.cmpi slt, %curr_n_40, %curr_n_42 : i32 loc(#loc26)
      %curr_n_44 = arith.addi %arg20, %c1_i32 : i32 loc(#loc26)
      %curr_n_45 = arith.cmpi sge, %curr_n_44, %c5_i32 : i32 loc(#loc26)
      %curr_n_46 = arith.select %curr_n_45, %c0_i32, %curr_n_44 : i32 loc(#loc26)
      %402 = ttg.async_wait %arg21, %arg25 {num = 6 : i32} loc(#loc)
      %403 = ttg.memdesc_index %363[%curr_n_46] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %404 = ttg.memdesc_trans %403 {order = array<i32: 1, 0>} : !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> -> !ttg.memdesc<32x64xf16, #shared, #smem, mutable, 5x32x64> loc(#loc)
      %405 = ttg.memdesc_index %364[%curr_n_46] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %406 = ttng.warp_group_dot %283, %403, %cst_2 {inputPrecision = 0 : i32, isAsync = true} : !ttg.memdesc<128x64xf16, #shared, #smem> * !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> -> tensor<128x32xf32, #mma2> loc(#loc)
      %407:3 = ttng.warp_group_dot_wait %406, %283, %403 {pendings = 0 : i32} : tensor<128x32xf32, #mma2>, !ttg.memdesc<128x64xf16, #shared, #smem>, !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %408 = arith.subf %407#0, %360 : tensor<128x32xf32, #mma2> loc(#loc)
      %409 = math.exp2 %408 : tensor<128x32xf32, #mma2> loc(#loc)
      %410 = ttng.warp_group_dot %289, %405, %cst_2 {inputPrecision = 0 : i32, isAsync = true} : !ttg.memdesc<128x64xf16, #shared, #smem> * !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> -> tensor<128x32xf32, #mma2> loc(#loc)
      %411:3 = ttng.warp_group_dot_wait %410, %289, %405 {pendings = 0 : i32} : tensor<128x32xf32, #mma2>, !ttg.memdesc<128x64xf16, #shared, #smem>, !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %412 = arith.subf %411#0, %362 : tensor<128x32xf32, #mma2> loc(#loc)
      %413 = arith.mulf %409, %412 : tensor<128x32xf32, #mma2> loc(#loc)
      %414 = arith.truncf %413 : tensor<128x32xf32, #mma2> to tensor<128x32xf16, #mma2> loc(#loc)
      %415 = ttg.convert_layout %414 : tensor<128x32xf16, #mma2> -> tensor<128x32xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc)
      %416 = ttng.warp_group_dot %415, %404, %curr_n_41 {inputPrecision = 0 : i32, isAsync = true} : tensor<128x32xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * !ttg.memdesc<32x64xf16, #shared, #smem, mutable, 5x32x64> -> tensor<128x64xf32, #mma> loc(#loc)
      %417 = tt.addptr %arg17, %185 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
      %418 = tt.addptr %arg18, %185 : tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32xi32, #blocked> loc(#loc)
      %curr_n_47 = arith.addi %arg19, %c1_i32 : i32 loc(#loc26)
      %curr_n_48 = arith.cmpi sge, %curr_n_47, %c5_i32 : i32 loc(#loc26)
      %curr_n_49 = arith.select %curr_n_48, %c0_i32, %curr_n_47 : i32 loc(#loc26)
      %419 = ttg.memdesc_index %363[%curr_n_49] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %curr_n_50 = tt.splat %curr_n_43 : i1 -> tensor<64x32xi1, #blocked> loc(#loc26)
      %420 = ttg.async_copy_global_to_local %417, %419 mask %curr_n_50 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %421 = ttg.async_commit_group tokens %420 loc(#loc)
      %422 = ttg.memdesc_index %364[%curr_n_49] : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> -> !ttg.memdesc<64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %423 = ttg.async_copy_global_to_local %418, %422 mask %curr_n_50 : tensor<64x32x!tt.ptr<f16>, #blocked> -> <64x32xf16, #shared1, #smem, mutable, 5x64x32> loc(#loc)
      %424 = ttg.async_commit_group tokens %423 loc(#loc)
      scf.yield %416, %417, %418, %curr_n_49, %curr_n_46, %arg22, %arg23, %arg24, %421, %arg26, %arg27, %arg28, %424 : tensor<128x64xf32, #mma>, tensor<64x32x!tt.ptr<f16>, #blocked>, tensor<64x32x!tt.ptr<f16>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token loc(#loc26)
    } loc(#loc26)
    %curr_n_38 = ttng.warp_group_dot_wait %curr_n_37#0 {pendings = 0 : i32} : tensor<128x64xf32, #mma> loc(#loc26)
    %curr_n_39 = ttg.async_wait {num = 0 : i32} loc(#loc26)
    ttg.local_dealloc %364 : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> loc(#loc26)
    ttg.local_dealloc %363 : !ttg.memdesc<5x64x32xf16, #shared1, #smem, mutable> loc(#loc26)
    %395 = tt.splat %14 : !tt.ptr<f16> -> tensor<128x1x!tt.ptr<f16>, #blocked1> loc(#loc)
    %396 = tt.addptr %395, %32 : tensor<128x1x!tt.ptr<f16>, #blocked1>, tensor<128x1xi32, #blocked1> loc(#loc)
    %397 = tt.broadcast %396 : tensor<128x1x!tt.ptr<f16>, #blocked1> -> tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    %398 = tt.addptr %397, %38 : tensor<128x64x!tt.ptr<f16>, #blocked1>, tensor<128x64xi32, #blocked1> loc(#loc)
    %399 = arith.mulf %curr_n_38, %cst : tensor<128x64xf32, #mma> loc(#loc)
    %400 = arith.truncf %399 : tensor<128x64xf32, #mma> to tensor<128x64xf16, #mma> loc(#loc)
    %401 = ttg.convert_layout %400 : tensor<128x64xf16, #mma> -> tensor<128x64xf16, #blocked1> loc(#loc)
    tt.store %398, %401 : tensor<128x64x!tt.ptr<f16>, #blocked1> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc16 = loc("dk")
#loc17 = loc("dq")
#loc18 = loc("dv"(#loc16))
#loc19 = loc("offs_n"(#loc17))
#loc20 = loc("kT_ptrs"(#loc17))
#loc21 = loc("offs_m"(#loc18))
#loc22 = loc("kT_ptrs"(#loc19))
#loc23 = loc("vT_ptrs"(#loc20))
#loc24 = loc("qT_ptrs"(#loc21))
#loc25 = loc("vT_ptrs"(#loc22))
#loc26 = loc("curr_n"(#loc23))
#loc27 = loc("do_ptrs"(#loc24))
#loc28 = loc("curr_n"(#loc25))
#loc29 = loc("curr_m"(#loc27))
