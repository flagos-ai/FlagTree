//
// Generated by LLVM NVPTX Back-End
//

.version 8.7
.target sm_90a
.address_size 64

	// .globl	add_kernel              // -- Begin function add_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @add_kernel
.visible .entry add_kernel(
	.param .u64 .ptr .global .align 1 add_kernel_param_0,
	.param .u64 .ptr .global .align 1 add_kernel_param_1,
	.param .u64 .ptr .global .align 1 add_kernel_param_2,
	.param .u32 add_kernel_param_3,
	.param .u64 .ptr .global .align 1 add_kernel_param_4,
	.param .u64 .ptr .global .align 1 add_kernel_param_5
)
.reqntid 128
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<43>;
	.reg .b64 	%rd<11>;

// %bb.0:
	ld.param.b64 	%rd7, [add_kernel_param_0];
	ld.param.b64 	%rd8, [add_kernel_param_1];
	mov.u32 	%r17, %ctaid.x;
	shl.b32 	%r18, %r17, 10;
	ld.param.b64 	%rd9, [add_kernel_param_2];
	ld.param.b32 	%r19, [add_kernel_param_3];
	mov.u32 	%r20, %tid.x;
	and.b32 	%r21, %r20, 127;
	shl.b32 	%r22, %r21, 2;
	or.b32 	%r23, %r22, %r18;
	or.b32 	%r24, %r23, 512;
	setp.lt.s32 	%p1, %r23, %r19;
	setp.lt.s32 	%p2, %r24, %r19;
	mul.wide.s32 	%rd10, %r23, 4;
	add.s64 	%rd1, %rd7, %rd10;
	add.s64 	%rd2, %rd1, 2048;
	shl.b32 	%r25, %r21, 4;
	mov.b32 	%r26, global_smem;
	add.s32 	%r1, %r26, %r25;
	selp.b32 	%r2, 16, 0, %p1;
	// begin inline asm
	cp.async.cg.shared.global [ %r1 + 0 ], [ %rd1 + 0 ], 0x10, %r2;
	// end inline asm
	add.s32 	%r3, %r1, 2048;
	selp.b32 	%r4, 16, 0, %p2;
	// begin inline asm
	cp.async.cg.shared.global [ %r3 + 0 ], [ %rd2 + 0 ], 0x10, %r4;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r27, %r28, %r29, %r30}, [%r1];
	ld.shared.v4.b32 	{%r31, %r32, %r33, %r34}, [%r1+2048];
	add.s64 	%rd3, %rd8, %rd10;
	add.s64 	%rd4, %rd3, 2048;
	bar.sync 	0;
	// begin inline asm
	cp.async.cg.shared.global [ %r1 + 0 ], [ %rd3 + 0 ], 0x10, %r2;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r3 + 0 ], [ %rd4 + 0 ], 0x10, %r4;
	// end inline asm
	cp.async.commit_group;
	cp.async.wait_group 	0;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r35, %r36, %r37, %r38}, [%r1];
	ld.shared.v4.b32 	{%r39, %r40, %r41, %r42}, [%r1+2048];
	add.f32 	%r9, %r27, %r35;
	add.f32 	%r10, %r28, %r36;
	add.f32 	%r11, %r29, %r37;
	add.f32 	%r12, %r30, %r38;
	add.f32 	%r13, %r31, %r39;
	add.f32 	%r14, %r32, %r40;
	add.f32 	%r15, %r33, %r41;
	add.f32 	%r16, %r34, %r42;
	add.s64 	%rd5, %rd9, %rd10;
	add.s64 	%rd6, %rd5, 2048;
	// begin inline asm
	@%p1 st.global.v4.b32 [ %rd5 + 0 ], { %r9, %r10, %r11, %r12 };
	// end inline asm
	// begin inline asm
	@%p2 st.global.v4.b32 [ %rd6 + 0 ], { %r13, %r14, %r15, %r16 };
	// end inline asm
	ret;
                                        // -- End function
}
