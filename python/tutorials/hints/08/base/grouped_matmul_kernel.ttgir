#blocked = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc1 = loc("group_a_ptrs")
#loc2 = loc("group_b_ptrs")
#loc3 = loc("group_c_ptrs")
#loc4 = loc("group_gemm_sizes")
#loc5 = loc("g_lds")
#loc6 = loc("group_size")
#loc7 = loc("tile_idx")
#mma = #ttg.nvidia_mma<{versionMajor = 3, versionMinor = 0, warpsPerCTA = [4, 1], instrShape = [16, 128, 16]}>
#shared = #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @grouped_matmul_kernel(%group_a_ptrs: !tt.ptr<i64> {tt.divisibility = 16 : i32} loc("group_a_ptrs"), %group_b_ptrs: !tt.ptr<i64> {tt.divisibility = 16 : i32} loc("group_b_ptrs"), %group_c_ptrs: !tt.ptr<i64> {tt.divisibility = 16 : i32} loc("group_c_ptrs"), %group_gemm_sizes: !tt.ptr<i32> {tt.divisibility = 16 : i32} loc("group_gemm_sizes"), %g_lds: !tt.ptr<i32> {tt.divisibility = 16 : i32} loc("g_lds"), %group_size: i32 loc("group_size")) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<128x128xf32, #mma> loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i32 = arith.constant 1 : i32 loc(#loc)
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %c2_i32 = arith.constant 2 : i32 loc(#loc)
    %c128_i32 = arith.constant 128 : i32 loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %c127_i32 = arith.constant 127 : i32 loc(#loc)
    %c132_i32 = arith.constant 132 : i32 loc(#loc)
    %cst_0 = arith.constant dense<64> : tensor<128x64xi32, #blocked> loc(#loc)
    %c-1_i32 = arith.constant -1 : i32 loc(#loc)
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc)
    %2 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
    %3 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc)
    %4 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc)
    %5 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %6 = tt.expand_dims %5 {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x64xi32, #blocked> loc(#loc)
    %7 = tt.broadcast %6 : tensor<1x64xi32, #blocked> -> tensor<128x64xi32, #blocked> loc(#loc)
    %8 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc)
    %9 = tt.expand_dims %8 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1xi32, #blocked2> loc(#loc)
    %last_problem_end:2 = scf.for %g = %c0_i32 to %group_size step %c1_i32 iter_args(%tile_idx = %0, %last_problem_end_1 = %c0_i32) -> (i32, i32)  : i32 {
      %10 = arith.muli %g, %c3_i32 : i32 loc(#loc)
      %11 = tt.addptr %group_gemm_sizes, %10 : !tt.ptr<i32>, i32 loc(#loc)
      %12 = tt.load %11 : !tt.ptr<i32> loc(#loc)
      %13 = tt.addptr %11, %c1_i32 : !tt.ptr<i32>, i32 loc(#loc)
      %14 = tt.load %13 : !tt.ptr<i32> loc(#loc)
      %15 = tt.addptr %11, %c2_i32 : !tt.ptr<i32>, i32 loc(#loc)
      %16 = tt.load %15 : !tt.ptr<i32> loc(#loc)
      %17 = arith.addi %12, %c127_i32 : i32 loc(#loc)
      %18 = arith.divsi %17, %c128_i32 : i32 loc(#loc)
      %19 = arith.addi %14, %c127_i32 : i32 loc(#loc)
      %20 = arith.divsi %19, %c128_i32 : i32 loc(#loc)
      %21 = arith.muli %18, %20 : i32 loc(#loc)
      %22 = arith.addi %last_problem_end_1, %21 : i32 loc(#loc)
      %23 = tt.addptr %g_lds, %10 : !tt.ptr<i32>, i32 loc(#loc)
      %24 = tt.addptr %23, %c1_i32 : !tt.ptr<i32>, i32 loc(#loc)
      %25 = tt.addptr %23, %c2_i32 : !tt.ptr<i32>, i32 loc(#loc)
      %26 = tt.addptr %group_a_ptrs, %g : !tt.ptr<i64>, i32 loc(#loc)
      %27 = tt.addptr %group_b_ptrs, %g : !tt.ptr<i64>, i32 loc(#loc)
      %28 = tt.addptr %group_c_ptrs, %g : !tt.ptr<i64>, i32 loc(#loc)
      %29 = arith.addi %16, %c63_i32 : i32 loc(#loc)
      %30 = arith.divsi %29, %c64_i32 : i32 loc(#loc)
      %tile_idx_2 = scf.while (%tile_idx_3 = %tile_idx) : (i32) -> i32 {
        %31 = arith.cmpi sge, %tile_idx_3, %last_problem_end_1 : i32 loc(#loc)
        %32 = arith.cmpi slt, %tile_idx_3, %22 : i32 loc(#loc)
        %33 = arith.andi %31, %32 : i1 loc(#loc)
        scf.condition(%33) %tile_idx_3 : i32 loc(#loc)
      } do {
      ^bb0(%tile_idx_3: i32 loc("tile_idx")):
        %31 = tt.load %23 : !tt.ptr<i32> loc(#loc)
        %32 = tt.load %24 : !tt.ptr<i32> loc(#loc)
        %33 = tt.load %25 : !tt.ptr<i32> loc(#loc)
        %34 = tt.load %26 : !tt.ptr<i64> loc(#loc)
        %35 = tt.int_to_ptr %34 : i64 -> !tt.ptr<f16> loc(#loc)
        %36 = tt.load %27 : !tt.ptr<i64> loc(#loc)
        %37 = tt.int_to_ptr %36 : i64 -> !tt.ptr<f16> loc(#loc)
        %38 = tt.load %28 : !tt.ptr<i64> loc(#loc)
        %39 = tt.int_to_ptr %38 : i64 -> !tt.ptr<f16> loc(#loc)
        %40 = arith.subi %tile_idx_3, %last_problem_end_1 : i32 loc(#loc)
        %41 = arith.divsi %40, %20 : i32 loc(#loc)
        %42 = arith.remsi %40, %20 : i32 loc(#loc)
        %43 = arith.muli %41, %c128_i32 : i32 loc(#loc)
        %44 = tt.splat %43 : i32 -> tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc)
        %45 = tt.splat %43 : i32 -> tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
        %46 = arith.addi %44, %1 : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc)
        %47 = arith.addi %45, %2 : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
        %48 = arith.muli %42, %c128_i32 : i32 loc(#loc)
        %49 = tt.splat %48 : i32 -> tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc)
        %50 = tt.splat %48 : i32 -> tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc)
        %51 = arith.addi %49, %3 : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc)
        %52 = arith.addi %50, %4 : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc)
        %53 = tt.expand_dims %46 {axis = 1 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<128x1xi32, #blocked> loc(#loc)
        %54 = tt.expand_dims %47 {axis = 1 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1xi32, #blocked1> loc(#loc)
        %55 = tt.splat %31 : i32 -> tensor<128x1xi32, #blocked> loc(#loc)
        %56 = arith.muli %53, %55 : tensor<128x1xi32, #blocked> loc(#loc)
        %57 = tt.splat %35 : !tt.ptr<f16> -> tensor<128x1x!tt.ptr<f16>, #blocked> loc(#loc)
        %58 = tt.addptr %57, %56 : tensor<128x1x!tt.ptr<f16>, #blocked>, tensor<128x1xi32, #blocked> loc(#loc)
        %59 = tt.broadcast %58 : tensor<128x1x!tt.ptr<f16>, #blocked> -> tensor<128x64x!tt.ptr<f16>, #blocked> loc(#loc)
        %60 = tt.addptr %59, %7 {tt.divisibility = dense<16> : tensor<2xi32>} : tensor<128x64x!tt.ptr<f16>, #blocked>, tensor<128x64xi32, #blocked> loc(#loc)
        %61 = tt.splat %32 : i32 -> tensor<64x1xi32, #blocked2> loc(#loc)
        %62 = arith.muli %9, %61 : tensor<64x1xi32, #blocked2> loc(#loc)
        %63 = tt.splat %37 : !tt.ptr<f16> -> tensor<64x1x!tt.ptr<f16>, #blocked2> loc(#loc)
        %64 = tt.addptr %63, %62 : tensor<64x1x!tt.ptr<f16>, #blocked2>, tensor<64x1xi32, #blocked2> loc(#loc)
        %65 = tt.expand_dims %51 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x128xi32, #blocked2> loc(#loc)
        %66 = tt.expand_dims %52 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x128xi32, #blocked1> loc(#loc)
        %67 = tt.broadcast %64 : tensor<64x1x!tt.ptr<f16>, #blocked2> -> tensor<64x128x!tt.ptr<f16>, #blocked2> loc(#loc)
        %68 = tt.broadcast %65 : tensor<1x128xi32, #blocked2> -> tensor<64x128xi32, #blocked2> loc(#loc)
        %69 = tt.addptr %67, %68 {tt.divisibility = dense<16> : tensor<2xi32>} : tensor<64x128x!tt.ptr<f16>, #blocked2>, tensor<64x128xi32, #blocked2> loc(#loc)
        %70 = arith.muli %32, %c64_i32 : i32 loc(#loc)
        %71 = tt.splat %70 : i32 -> tensor<64x128xi32, #blocked2> loc(#loc)
        %72 = ttg.local_alloc : () -> !ttg.memdesc<3x128x64xf16, #shared, #smem, mutable> loc(#loc)
        %73 = ttg.local_alloc : () -> !ttg.memdesc<3x64x128xf16, #shared, #smem, mutable> loc(#loc)
        %accumulator = arith.cmpi sgt, %30, %c0_i32 : i32 loc(#loc11)
        %74 = ttg.memdesc_index %72[%c0_i32] : !ttg.memdesc<3x128x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<128x64xf16, #shared, #smem, mutable, 3x128x64> loc(#loc)
        %accumulator_4 = tt.splat %accumulator : i1 -> tensor<128x64xi1, #blocked> loc(#loc11)
        %75 = ttg.async_copy_global_to_local %60, %74 mask %accumulator_4 : tensor<128x64x!tt.ptr<f16>, #blocked> -> <128x64xf16, #shared, #smem, mutable, 3x128x64> loc(#loc)
        %76 = ttg.async_commit_group tokens %75 loc(#loc)
        %77 = ttg.memdesc_index %73[%c0_i32] : !ttg.memdesc<3x64x128xf16, #shared, #smem, mutable> -> !ttg.memdesc<64x128xf16, #shared, #smem, mutable, 3x64x128> loc(#loc)
        %accumulator_5 = tt.splat %accumulator : i1 -> tensor<64x128xi1, #blocked2> loc(#loc11)
        %78 = ttg.async_copy_global_to_local %69, %77 mask %accumulator_5 : tensor<64x128x!tt.ptr<f16>, #blocked2> -> <64x128xf16, #shared, #smem, mutable, 3x64x128> loc(#loc)
        %79 = ttg.async_commit_group tokens %78 loc(#loc)
        %accumulator_6 = arith.cmpi sgt, %30, %c1_i32 : i32 loc(#loc11)
        %80 = tt.addptr %60, %cst_0 : tensor<128x64x!tt.ptr<f16>, #blocked>, tensor<128x64xi32, #blocked> loc(#loc)
        %81 = tt.addptr %69, %71 : tensor<64x128x!tt.ptr<f16>, #blocked2>, tensor<64x128xi32, #blocked2> loc(#loc)
        %82 = ttg.memdesc_index %72[%c1_i32] : !ttg.memdesc<3x128x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<128x64xf16, #shared, #smem, mutable, 3x128x64> loc(#loc)
        %accumulator_7 = tt.splat %accumulator_6 : i1 -> tensor<128x64xi1, #blocked> loc(#loc11)
        %83 = ttg.async_copy_global_to_local %80, %82 mask %accumulator_7 : tensor<128x64x!tt.ptr<f16>, #blocked> -> <128x64xf16, #shared, #smem, mutable, 3x128x64> loc(#loc)
        %84 = ttg.async_commit_group tokens %83 loc(#loc)
        %85 = ttg.memdesc_index %73[%c1_i32] : !ttg.memdesc<3x64x128xf16, #shared, #smem, mutable> -> !ttg.memdesc<64x128xf16, #shared, #smem, mutable, 3x64x128> loc(#loc)
        %accumulator_8 = tt.splat %accumulator_6 : i1 -> tensor<64x128xi1, #blocked2> loc(#loc11)
        %86 = ttg.async_copy_global_to_local %81, %85 mask %accumulator_8 : tensor<64x128x!tt.ptr<f16>, #blocked2> -> <64x128xf16, #shared, #smem, mutable, 3x64x128> loc(#loc)
        %87 = ttg.async_commit_group tokens %86 loc(#loc)
        %accumulator_9:9 = scf.for %accumulator_12 = %c0_i32 to %30 step %c1_i32 iter_args(%arg11 = %cst, %arg12 = %80, %arg13 = %81, %arg14 = %c1_i32, %arg15 = %c-1_i32, %arg16 = %76, %arg17 = %84, %arg18 = %79, %arg19 = %87) -> (tensor<128x128xf32, #mma>, tensor<128x64x!tt.ptr<f16>, #blocked>, tensor<64x128x!tt.ptr<f16>, #blocked2>, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token)  : i32 {
          %accumulator_13 = arith.subi %30, %c2_i32 : i32 loc(#loc11)
          %accumulator_14 = arith.cmpi slt, %accumulator_12, %accumulator_13 : i32 loc(#loc11)
          %accumulator_15 = arith.addi %arg15, %c1_i32 : i32 loc(#loc11)
          %accumulator_16 = arith.cmpi sge, %accumulator_15, %c3_i32 : i32 loc(#loc11)
          %accumulator_17 = arith.select %accumulator_16, %c0_i32, %accumulator_15 : i32 loc(#loc11)
          %98 = ttg.async_wait %arg16, %arg18 {num = 2 : i32} loc(#loc)
          %99 = ttg.memdesc_index %72[%accumulator_17] : !ttg.memdesc<3x128x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<128x64xf16, #shared, #smem, mutable, 3x128x64> loc(#loc)
          %100 = ttg.memdesc_index %73[%accumulator_17] : !ttg.memdesc<3x64x128xf16, #shared, #smem, mutable> -> !ttg.memdesc<64x128xf16, #shared, #smem, mutable, 3x64x128> loc(#loc)
          %101 = ttng.warp_group_dot %99, %100, %arg11 {inputPrecision = 0 : i32, isAsync = true} : !ttg.memdesc<128x64xf16, #shared, #smem, mutable, 3x128x64> * !ttg.memdesc<64x128xf16, #shared, #smem, mutable, 3x64x128> -> tensor<128x128xf32, #mma> loc(#loc)
          %102:3 = ttng.warp_group_dot_wait %101, %99, %100 {pendings = 1 : i32} : tensor<128x128xf32, #mma>, !ttg.memdesc<128x64xf16, #shared, #smem, mutable, 3x128x64>, !ttg.memdesc<64x128xf16, #shared, #smem, mutable, 3x64x128> loc(#loc)
          %103 = tt.addptr %arg12, %cst_0 : tensor<128x64x!tt.ptr<f16>, #blocked>, tensor<128x64xi32, #blocked> loc(#loc)
          %104 = tt.addptr %arg13, %71 : tensor<64x128x!tt.ptr<f16>, #blocked2>, tensor<64x128xi32, #blocked2> loc(#loc)
          %accumulator_18 = arith.addi %arg14, %c1_i32 : i32 loc(#loc11)
          %accumulator_19 = arith.cmpi sge, %accumulator_18, %c3_i32 : i32 loc(#loc11)
          %accumulator_20 = arith.select %accumulator_19, %c0_i32, %accumulator_18 : i32 loc(#loc11)
          %105 = ttg.memdesc_index %72[%accumulator_20] : !ttg.memdesc<3x128x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<128x64xf16, #shared, #smem, mutable, 3x128x64> loc(#loc)
          %accumulator_21 = tt.splat %accumulator_14 : i1 -> tensor<128x64xi1, #blocked> loc(#loc11)
          %106 = ttg.async_copy_global_to_local %103, %105 mask %accumulator_21 : tensor<128x64x!tt.ptr<f16>, #blocked> -> <128x64xf16, #shared, #smem, mutable, 3x128x64> loc(#loc)
          %107 = ttg.async_commit_group tokens %106 loc(#loc)
          %108 = ttg.memdesc_index %73[%accumulator_20] : !ttg.memdesc<3x64x128xf16, #shared, #smem, mutable> -> !ttg.memdesc<64x128xf16, #shared, #smem, mutable, 3x64x128> loc(#loc)
          %accumulator_22 = tt.splat %accumulator_14 : i1 -> tensor<64x128xi1, #blocked2> loc(#loc11)
          %109 = ttg.async_copy_global_to_local %104, %108 mask %accumulator_22 : tensor<64x128x!tt.ptr<f16>, #blocked2> -> <64x128xf16, #shared, #smem, mutable, 3x64x128> loc(#loc)
          %110 = ttg.async_commit_group tokens %109 loc(#loc)
          scf.yield %102#0, %103, %104, %accumulator_20, %accumulator_17, %arg17, %107, %arg19, %110 : tensor<128x128xf32, #mma>, tensor<128x64x!tt.ptr<f16>, #blocked>, tensor<64x128x!tt.ptr<f16>, #blocked2>, i32, i32, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token loc(#loc11)
        } {tt.divisibility_arg1 = dense<16> : tensor<2xi32>, tt.divisibility_arg2 = dense<16> : tensor<2xi32>} loc(#loc11)
        %accumulator_10 = ttng.warp_group_dot_wait %accumulator_9#0 {pendings = 0 : i32} : tensor<128x128xf32, #mma> loc(#loc11)
        %accumulator_11 = ttg.async_wait {num = 0 : i32} loc(#loc11)
        ttg.local_dealloc %73 : !ttg.memdesc<3x64x128xf16, #shared, #smem, mutable> loc(#loc11)
        ttg.local_dealloc %72 : !ttg.memdesc<3x128x64xf16, #shared, #smem, mutable> loc(#loc11)
        %88 = arith.truncf %accumulator_10 : tensor<128x128xf32, #mma> to tensor<128x128xf16, #mma> loc(#loc)
        %89 = tt.splat %33 : i32 -> tensor<128x1xi32, #blocked1> loc(#loc)
        %90 = arith.muli %89, %54 : tensor<128x1xi32, #blocked1> loc(#loc)
        %91 = tt.splat %39 : !tt.ptr<f16> -> tensor<128x1x!tt.ptr<f16>, #blocked1> loc(#loc)
        %92 = tt.addptr %91, %90 : tensor<128x1x!tt.ptr<f16>, #blocked1>, tensor<128x1xi32, #blocked1> loc(#loc)
        %93 = tt.broadcast %92 : tensor<128x1x!tt.ptr<f16>, #blocked1> -> tensor<128x128x!tt.ptr<f16>, #blocked1> loc(#loc)
        %94 = tt.broadcast %66 : tensor<1x128xi32, #blocked1> -> tensor<128x128xi32, #blocked1> loc(#loc)
        %95 = tt.addptr %93, %94 : tensor<128x128x!tt.ptr<f16>, #blocked1>, tensor<128x128xi32, #blocked1> loc(#loc)
        %96 = ttg.convert_layout %88 : tensor<128x128xf16, #mma> -> tensor<128x128xf16, #blocked1> loc(#loc)
        tt.store %95, %96 : tensor<128x128x!tt.ptr<f16>, #blocked1> loc(#loc)
        %97 = arith.addi %tile_idx_3, %c132_i32 : i32 loc(#loc)
        scf.yield %97 : i32 loc(#loc)
      } loc(#loc7)
      scf.yield %tile_idx_2, %22 : i32, i32 loc(#loc)
    } loc(#loc9)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc8 = loc("a_ptrs")
#loc9 = loc("last_problem_end"(#loc7))
#loc10 = loc("b_ptrs"(#loc8))
#loc11 = loc("accumulator"(#loc10))
