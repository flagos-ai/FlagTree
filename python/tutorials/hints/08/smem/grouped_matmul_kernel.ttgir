#blocked = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [4, 4], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc1 = loc("group_a_ptrs")
#loc2 = loc("group_b_ptrs")
#loc3 = loc("group_c_ptrs")
#loc4 = loc("group_gemm_sizes")
#loc5 = loc("g_lds")
#loc6 = loc("group_size")
#loc7 = loc("tile_idx")
#mma = #ttg.nvidia_mma<{versionMajor = 3, versionMinor = 0, warpsPerCTA = [4, 1], instrShape = [16, 128, 16]}>
#shared = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>
#shared1 = #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:90", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @grouped_matmul_kernel(%group_a_ptrs: !tt.ptr<i64> {tt.divisibility = 16 : i32} loc("group_a_ptrs"), %group_b_ptrs: !tt.ptr<i64> {tt.divisibility = 16 : i32} loc("group_b_ptrs"), %group_c_ptrs: !tt.ptr<i64> {tt.divisibility = 16 : i32} loc("group_c_ptrs"), %group_gemm_sizes: !tt.ptr<i32> {tt.divisibility = 16 : i32} loc("group_gemm_sizes"), %g_lds: !tt.ptr<i32> {tt.divisibility = 16 : i32} loc("g_lds"), %group_size: i32 loc("group_size")) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<128x128xf32, #mma> loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i32 = arith.constant 1 : i32 loc(#loc)
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %c2_i32 = arith.constant 2 : i32 loc(#loc)
    %c128_i32 = arith.constant 128 : i32 loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %c127_i32 = arith.constant 127 : i32 loc(#loc)
    %c132_i32 = arith.constant 132 : i32 loc(#loc)
    %cst_0 = arith.constant dense<64> : tensor<128x64xi32, #blocked> loc(#loc)
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc)
    %2 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
    %3 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc)
    %4 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc)
    %5 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %6 = tt.expand_dims %5 {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x64xi32, #blocked> loc(#loc)
    %7 = tt.broadcast %6 : tensor<1x64xi32, #blocked> -> tensor<128x64xi32, #blocked> loc(#loc)
    %8 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc)
    %9 = tt.expand_dims %8 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<64x1xi32, #blocked2> loc(#loc)
    %last_problem_end:2 = scf.for %g = %c0_i32 to %group_size step %c1_i32 iter_args(%tile_idx = %0, %last_problem_end_1 = %c0_i32) -> (i32, i32)  : i32 {
      %10 = arith.muli %g, %c3_i32 : i32 loc(#loc)
      %11 = tt.addptr %group_gemm_sizes, %10 : !tt.ptr<i32>, i32 loc(#loc)
      %12 = tt.load %11 : !tt.ptr<i32> loc(#loc)
      %13 = tt.addptr %11, %c1_i32 : !tt.ptr<i32>, i32 loc(#loc)
      %14 = tt.load %13 : !tt.ptr<i32> loc(#loc)
      %15 = tt.addptr %11, %c2_i32 : !tt.ptr<i32>, i32 loc(#loc)
      %16 = tt.load %15 : !tt.ptr<i32> loc(#loc)
      %17 = arith.addi %12, %c127_i32 : i32 loc(#loc)
      %18 = arith.divsi %17, %c128_i32 : i32 loc(#loc)
      %19 = arith.addi %14, %c127_i32 : i32 loc(#loc)
      %20 = arith.divsi %19, %c128_i32 : i32 loc(#loc)
      %21 = arith.muli %18, %20 : i32 loc(#loc)
      %22 = arith.addi %last_problem_end_1, %21 : i32 loc(#loc)
      %23 = tt.addptr %g_lds, %10 : !tt.ptr<i32>, i32 loc(#loc)
      %24 = tt.addptr %23, %c1_i32 : !tt.ptr<i32>, i32 loc(#loc)
      %25 = tt.addptr %23, %c2_i32 : !tt.ptr<i32>, i32 loc(#loc)
      %26 = tt.addptr %group_a_ptrs, %g : !tt.ptr<i64>, i32 loc(#loc)
      %27 = tt.addptr %group_b_ptrs, %g : !tt.ptr<i64>, i32 loc(#loc)
      %28 = tt.addptr %group_c_ptrs, %g : !tt.ptr<i64>, i32 loc(#loc)
      %29 = arith.addi %16, %c63_i32 : i32 loc(#loc)
      %30 = arith.divsi %29, %c64_i32 : i32 loc(#loc)
      %tile_idx_2 = scf.while (%tile_idx_3 = %tile_idx) : (i32) -> i32 {
        %31 = arith.cmpi sge, %tile_idx_3, %last_problem_end_1 : i32 loc(#loc)
        %32 = arith.cmpi slt, %tile_idx_3, %22 : i32 loc(#loc)
        %33 = arith.andi %31, %32 : i1 loc(#loc)
        scf.condition(%33) %tile_idx_3 : i32 loc(#loc)
      } do {
      ^bb0(%tile_idx_3: i32 loc("tile_idx")):
        %31 = tt.load %23 : !tt.ptr<i32> loc(#loc)
        %32 = tt.load %24 : !tt.ptr<i32> loc(#loc)
        %33 = tt.load %25 : !tt.ptr<i32> loc(#loc)
        %34 = tt.load %26 : !tt.ptr<i64> loc(#loc)
        %35 = tt.int_to_ptr %34 : i64 -> !tt.ptr<f16> loc(#loc)
        %36 = tt.load %27 : !tt.ptr<i64> loc(#loc)
        %37 = tt.int_to_ptr %36 : i64 -> !tt.ptr<f16> loc(#loc)
        %38 = tt.load %28 : !tt.ptr<i64> loc(#loc)
        %39 = tt.int_to_ptr %38 : i64 -> !tt.ptr<f16> loc(#loc)
        %40 = arith.subi %tile_idx_3, %last_problem_end_1 : i32 loc(#loc)
        %41 = arith.divsi %40, %20 : i32 loc(#loc)
        %42 = arith.remsi %40, %20 : i32 loc(#loc)
        %43 = arith.muli %41, %c128_i32 : i32 loc(#loc)
        %44 = tt.splat %43 : i32 -> tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc)
        %45 = tt.splat %43 : i32 -> tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
        %46 = arith.addi %44, %1 : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc)
        %47 = arith.addi %45, %2 : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
        %48 = arith.muli %42, %c128_i32 : i32 loc(#loc)
        %49 = tt.splat %48 : i32 -> tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc)
        %50 = tt.splat %48 : i32 -> tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc)
        %51 = arith.addi %49, %3 : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc)
        %52 = arith.addi %50, %4 : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc)
        %53 = tt.expand_dims %46 {axis = 1 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<128x1xi32, #blocked> loc(#loc)
        %54 = tt.expand_dims %47 {axis = 1 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<128x1xi32, #blocked1> loc(#loc)
        %55 = tt.splat %31 : i32 -> tensor<128x1xi32, #blocked> loc(#loc)
        %56 = arith.muli %53, %55 : tensor<128x1xi32, #blocked> loc(#loc)
        %57 = tt.splat %35 : !tt.ptr<f16> -> tensor<128x1x!tt.ptr<f16>, #blocked> loc(#loc)
        %58 = tt.addptr %57, %56 : tensor<128x1x!tt.ptr<f16>, #blocked>, tensor<128x1xi32, #blocked> loc(#loc)
        %59 = tt.broadcast %58 : tensor<128x1x!tt.ptr<f16>, #blocked> -> tensor<128x64x!tt.ptr<f16>, #blocked> loc(#loc)
        %60 = tt.addptr %59, %7 {tt.divisibility = dense<16> : tensor<2xi32>} : tensor<128x64x!tt.ptr<f16>, #blocked>, tensor<128x64xi32, #blocked> loc(#loc)
        %61 = tt.splat %32 : i32 -> tensor<64x1xi32, #blocked2> loc(#loc)
        %62 = arith.muli %9, %61 : tensor<64x1xi32, #blocked2> loc(#loc)
        %63 = tt.splat %37 : !tt.ptr<f16> -> tensor<64x1x!tt.ptr<f16>, #blocked2> loc(#loc)
        %64 = tt.addptr %63, %62 : tensor<64x1x!tt.ptr<f16>, #blocked2>, tensor<64x1xi32, #blocked2> loc(#loc)
        %65 = tt.expand_dims %51 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x128xi32, #blocked2> loc(#loc)
        %66 = tt.expand_dims %52 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x128xi32, #blocked1> loc(#loc)
        %67 = tt.broadcast %64 : tensor<64x1x!tt.ptr<f16>, #blocked2> -> tensor<64x128x!tt.ptr<f16>, #blocked2> loc(#loc)
        %68 = tt.broadcast %65 : tensor<1x128xi32, #blocked2> -> tensor<64x128xi32, #blocked2> loc(#loc)
        %69 = tt.addptr %67, %68 {tt.divisibility = dense<16> : tensor<2xi32>} : tensor<64x128x!tt.ptr<f16>, #blocked2>, tensor<64x128xi32, #blocked2> loc(#loc)
        %70 = arith.muli %32, %c64_i32 : i32 loc(#loc)
        %71 = tt.splat %70 : i32 -> tensor<64x128xi32, #blocked2> loc(#loc)
        %accumulator:3 = scf.for %accumulator_4 = %c0_i32 to %30 step %c1_i32 iter_args(%arg11 = %cst, %arg12 = %60, %arg13 = %69) -> (tensor<128x128xf32, #mma>, tensor<128x64x!tt.ptr<f16>, #blocked>, tensor<64x128x!tt.ptr<f16>, #blocked2>)  : i32 {
          %82 = ttg.local_alloc : () -> !ttg.memdesc<1x128x64xf16, #shared, #smem, mutable> loc(#loc)
          %83 = ttg.memdesc_index %82[%c0_i32] : !ttg.memdesc<1x128x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<128x64xf16, #shared, #smem, mutable, 1x128x64> loc(#loc)
          %84 = ttg.async_copy_global_to_local %arg12, %83 : tensor<128x64x!tt.ptr<f16>, #blocked> -> <128x64xf16, #shared, #smem, mutable, 1x128x64> loc(#loc)
          %85 = ttg.async_commit_group tokens %84 loc(#loc)
          %86 = ttg.async_wait %85 {num = 0 : i32} loc(#loc)
          %87 = ttg.local_load %83 token %86 : !ttg.memdesc<128x64xf16, #shared, #smem, mutable, 1x128x64> -> tensor<128x64xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> loc(#loc)
          %88 = ttg.local_alloc : () -> !ttg.memdesc<1x64x128xf16, #shared, #smem, mutable> loc(#loc)
          %89 = ttg.memdesc_index %88[%c0_i32] : !ttg.memdesc<1x64x128xf16, #shared, #smem, mutable> -> !ttg.memdesc<64x128xf16, #shared, #smem, mutable, 1x64x128> loc(#loc)
          %90 = ttg.async_copy_global_to_local %arg13, %89 : tensor<64x128x!tt.ptr<f16>, #blocked2> -> <64x128xf16, #shared, #smem, mutable, 1x64x128> loc(#loc)
          %91 = ttg.async_commit_group tokens %90 loc(#loc)
          %92 = ttg.async_wait %91 {num = 0 : i32} loc(#loc)
          %93 = ttg.local_load %89 token %92 : !ttg.memdesc<64x128xf16, #shared, #smem, mutable, 1x64x128> -> tensor<64x128xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>> loc(#loc)
          %94 = ttg.local_alloc %93 : (tensor<64x128xf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>>) -> !ttg.memdesc<64x128xf16, #shared1, #smem> loc(#loc)
          ttng.fence_async_shared {bCluster = false} loc(#loc)
          %95 = ttng.warp_group_dot %87, %94, %arg11 {inputPrecision = 0 : i32, isAsync = true} : tensor<128x64xf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 2}>> * !ttg.memdesc<64x128xf16, #shared1, #smem> -> tensor<128x128xf32, #mma> loc(#loc)
          %96:2 = ttng.warp_group_dot_wait %95, %94 {pendings = 0 : i32} : tensor<128x128xf32, #mma>, !ttg.memdesc<64x128xf16, #shared1, #smem> loc(#loc)
          %97 = tt.addptr %arg12, %cst_0 : tensor<128x64x!tt.ptr<f16>, #blocked>, tensor<128x64xi32, #blocked> loc(#loc)
          %98 = tt.addptr %arg13, %71 : tensor<64x128x!tt.ptr<f16>, #blocked2>, tensor<64x128xi32, #blocked2> loc(#loc)
          scf.yield %96#0, %97, %98 : tensor<128x128xf32, #mma>, tensor<128x64x!tt.ptr<f16>, #blocked>, tensor<64x128x!tt.ptr<f16>, #blocked2> loc(#loc)
        } {tt.divisibility_arg1 = dense<16> : tensor<2xi32>, tt.divisibility_arg2 = dense<16> : tensor<2xi32>} loc(#loc11)
        %72 = arith.truncf %accumulator#0 : tensor<128x128xf32, #mma> to tensor<128x128xf16, #mma> loc(#loc)
        %73 = tt.splat %33 : i32 -> tensor<128x1xi32, #blocked1> loc(#loc)
        %74 = arith.muli %73, %54 : tensor<128x1xi32, #blocked1> loc(#loc)
        %75 = tt.splat %39 : !tt.ptr<f16> -> tensor<128x1x!tt.ptr<f16>, #blocked1> loc(#loc)
        %76 = tt.addptr %75, %74 : tensor<128x1x!tt.ptr<f16>, #blocked1>, tensor<128x1xi32, #blocked1> loc(#loc)
        %77 = tt.broadcast %76 : tensor<128x1x!tt.ptr<f16>, #blocked1> -> tensor<128x128x!tt.ptr<f16>, #blocked1> loc(#loc)
        %78 = tt.broadcast %66 : tensor<1x128xi32, #blocked1> -> tensor<128x128xi32, #blocked1> loc(#loc)
        %79 = tt.addptr %77, %78 : tensor<128x128x!tt.ptr<f16>, #blocked1>, tensor<128x128xi32, #blocked1> loc(#loc)
        %80 = ttg.convert_layout %72 : tensor<128x128xf16, #mma> -> tensor<128x128xf16, #blocked1> loc(#loc)
        tt.store %79, %80 : tensor<128x128x!tt.ptr<f16>, #blocked1> loc(#loc)
        %81 = arith.addi %tile_idx_3, %c132_i32 : i32 loc(#loc)
        scf.yield %81 : i32 loc(#loc)
      } loc(#loc7)
      scf.yield %tile_idx_2, %22 : i32, i32 loc(#loc)
    } loc(#loc9)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc = loc(unknown)
#loc8 = loc("a_ptrs")
#loc9 = loc("last_problem_end"(#loc7))
#loc10 = loc("b_ptrs"(#loc8))
#loc11 = loc("accumulator"(#loc10))
