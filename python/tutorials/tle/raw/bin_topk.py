from typing import Optional

import torch
import triton
import triton.language as tl
import numpy as np

# from topk_selector import tl_topk


@triton.jit
def convert_to_uint16(x):
    hval = x.cast(dtype=tl.float16)
    bits_uint = hval.cast(dtype=tl.uint16, bitcast=True) # 相当于reinterpret
    bits_uint = tl.where(x<0, ~bits_uint & (0xFFFF), bits_uint | (0x8000))
    return bits_uint >> 8

@triton.jit
def convert_to_uint32(x):
    bits_uint = x.cast(dtype=tl.uint32, bitcast=True)
    bits_uint = tl.where(x<0, ~bits_uint & tl.cast((0xFFFFFFFF), tl.uint32), bits_uint | tl.cast((0x80000000), tl.uint32))
    return bits_uint


@triton.autotune(
    configs=[
        triton.Config({'BS': 32, 'BK': 32}, num_stages=2, num_warps=1),
        triton.Config({'BS': 64, 'BK': 64}, num_stages=2, num_warps=1),
        triton.Config({'BS': 128, 'BK': 64}, num_stages=2, num_warps=1),
        triton.Config({'BS': 256, 'BK': 128}, num_stages=2, num_warps=2),
        triton.Config({'BS': 512, 'BK': 128}, num_stages=2, num_warps=2),
        triton.Config({'BS': 1024, 'BK': 256}, num_stages=2, num_warps=2),
        triton.Config({'BS': 2048, 'BK': 256}, num_stages=2, num_warps=4),
        triton.Config({'BS': 4096, 'BK': 512}, num_stages=3, num_warps=4),
        triton.Config({'BS': 8192, 'BK': 512}, num_stages=3, num_warps=8),
        triton.Config({'BS': 8192, 'BK': 1024}, num_stages=3, num_warps=8),
    ],
    key=['S', 'K'],
)

@triton.jit
def kernel_bucket_sort_topk( # grid(B, BS)
    inputs, # (B, S) 注意，没有 H，因为MLA基于MQA和MHA而非GQA
    indices, # (B, K) topk 索引数组
    # s_histogram,
    s_input_ids, # 下一轮中待筛选的数据索引
    starts,
    ends,
    S: tl.constexpr, # sequence length
    K: tl.constexpr, # k of topk
    HISTOGRAM_SIZE: tl.constexpr,
    SMEM_INPUT_SIZE: tl.constexpr,
    BS: tl.constexpr, # block size of S
    BK: tl.constexpr,
):
    # 获取线程块id
    i_b = tl.program_id(0)

    # 块基础指针定义
    s_base = inputs + i_b * S 
    indices_base = indices + i_b * K
    s_input_ids_base = s_input_ids + i_b * SMEM_INPUT_SIZE * 2

    # 直方图初始化
    s_histogram = tl.zeros([HISTOGRAM_SIZE], dtype=tl.int32)

    # 支持变长
    l_start_idx = tl.load(starts + i_b).to(tl.int32)
    l_end_idx = tl.load(ends + i_b).to(tl.int32)

    # 记录topk数组还剩多少可以被填满
    l_new_topk = K

    TS = tl.cdiv(S, BS)
    for s in range(TS):
        input_idx = s * BS + tl.arange(0, BS)
        input_mask = (input_idx < l_end_idx) & (input_idx >= l_start_idx) & (input_idx < S)
        input = tl.load(s_base + input_idx, input_mask, other=float("-inf")).to(tl.float32)
        # input = tl.rand(42, tl.arange(0, BS))
        inval_int16 = convert_to_uint16(input)
        # inval_int16 = tl.where(input_mask, inval_int16, 0)
        s_histogram += inval_int16.to(tl.int32).histogram(HISTOGRAM_SIZE)
    #     if i_b == 0:
    #         print("input", input)
    #         print("inval_int16", inval_int16)
    # if i_b==0:
    #     print("s_histogram", s_histogram)  

    s_histogram = s_histogram.cumsum(0, reverse=True) # 后缀和
    
    mv_idx = tl.arange(1,HISTOGRAM_SIZE+1) % HISTOGRAM_SIZE # 构造错位索引矩阵

    # cond = (s_histogram > l_new_topk) & (s_histogram.gather(mv_idx, 0) <= l_new_topk)
    # l_threshold_bin_id = tl.where(cond, tl.arange(1, HISTOGRAM_SIZE+1), 0).max(0)
    # l_threshold_bin_id = tl.where(l_threshold_bin_id>0, l_threshold_bin_id, HISTOGRAM_SIZE) - 1
    #因为无法设置第257个桶而加的补救措施，如果没有桶被找出，则赋值为最后一个
    # 对应tilelang中的如下语句：
    #   if s_histogram[tx] > l_new_topk and s_histogram[tx + 1] <= l_new_topk:
    #   s_threshold_bin_id[0] = tx

    # 该部分和上面的部分具有相同的功能，只是代码更简洁，速度更快。
    cond = (s_histogram > l_new_topk) & ((s_histogram.gather(mv_idx, 0) <= l_new_topk) | (mv_idx == 0))
    l_threshold_bin_id = cond.argmax(0)

    l_new_topk -= tl.where(tl.arange(0, HISTOGRAM_SIZE)==l_threshold_bin_id+1, s_histogram, 0).max(0)
    sum = 0
    thre_bin_sum = 0
    for s in range(TS):
        input_idx = s * BS + tl.arange(0, BS)
        input_mask = (input_idx < l_end_idx) & (input_idx >= l_start_idx) & (input_idx < S)
        input = tl.load(s_base + input_idx, input_mask, other=float("-inf")).to(tl.float32)
        # input = tl.rand(42, tl.arange(0, BS))
        inval_int16 = convert_to_uint16(input)
        # inval_int16 = tl.where(input_mask, inval_int16, 0) # 这种方法会导致速度变慢，因此采用other=float("-inf")的方法节省时间。

        over_thre = inval_int16.to(tl.int32) > l_threshold_bin_id
        cur_sum = over_thre.to(tl.int32).sum(-1)
        
        eq_thre = inval_int16.to(tl.int32) == l_threshold_bin_id
        thre_bin_cur_sum = eq_thre.to(tl.int32).sum(-1)

        topk_idx = over_thre.to(tl.int32).cumsum(-1)
        thre_bin_idx = eq_thre.to(tl.int32).cumsum(-1)

        # if (input_idx==65464).sum(-1) != 0 :
        #     print("input", tl.where(input_idx==65464, input, 0).sum(-1))
        #     print("l_threshold_bin_id", l_threshold_bin_id)
        #     temp = tl.where(input_idx==65464, inval_int16, 0).sum(-1)
        #     print("inval_int16", temp)
        #     print("histogram", tl.where(tl.arange(0,HISTOGRAM_SIZE)==temp, s_histogram, 0).sum(-1))

        concat_mask = tl.cat(over_thre, eq_thre, True)
        concat_input = tl.cat(input_idx, input_idx, True)
        concat_pointer_matrix = tl.cat(indices_base + sum + topk_idx - 1, s_input_ids_base + thre_bin_sum + thre_bin_idx - 1, True)
        tl.store(concat_pointer_matrix, concat_input, mask = concat_mask)

        # tl.store(indices_base + sum + topk_idx - 1, input_idx, mask = over_thre)
        # tl.store(s_input_ids_base + thre_bin_sum + thre_bin_idx - 1, input_idx, mask = eq_thre)
            
        thre_bin_sum += thre_bin_cur_sum
        sum += cur_sum

    # if i_b == 0:
    #     print("thre_bin_sum", thre_bin_sum)
    #     print("l_new_topk", l_new_topk)

    round = 0
    # 双buffer if_odd = 0
    while round < 4 and l_new_topk > 0 :
        # print("l_new_topk:", K-l_new_topk)
        ss = tl.cdiv(thre_bin_sum, BK)
        # 双buffer s_input_ids_base_load = s_input_ids_base + SMEM_INPUT_SIZE * if_odd
        # 双buffer s_input_ids_base_store = s_input_ids_base + SMEM_INPUT_SIZE * (1-if_odd)
        # 双buffer if_odd = 1-if_odd
        s_histogram = tl.zeros([HISTOGRAM_SIZE], dtype=tl.int32)
        padding_num = 0.0 if round else float("-inf")
        # 当 round == 0 时，如果padding值选用0.0会造成如下问题：
        # 0.0 = 0x00000000, inval_int32(0x|00|000000, round=0) = 0x80
        # 这会导致padding桶序比候选的负数更大，从而排在它们之前抢先一步被分入下一桶甚至直接进入topk序列
        # 而如果padding值取 “-inf” 则：
        # float("-inf") = 0xFFFFE000, inval_int32(0x|FF|FFE000, round=0) = 0x00 
        # 可以确保padding值被置于最小的bin中从而不影响前面所有正常候选数的排序
        #
        # 但当 round > 0 时，如果padding值依然选用“-inf”会造成如下问题：
        # float("-inf") = 0xFFFFE000, inval_int32(0xFFFFE0|00|, round=3) = 0xFF
        # 这会导致padding桶序比所有值更大，从而抢先一步进入topk序列，导致错误。
        # 因此 padding 值应选为 0.0
        for s in range(ss):
            s_input_idx = s * BK + tl.arange(0, BK)
            s_input_idx_mask = s_input_idx < thre_bin_sum
            # 双buffer input_idx = tl.load(s_input_ids_base_load + s_input_idx, s_input_idx_mask, other=-1)
            input_idx = tl.load(s_input_ids_base + s_input_idx, s_input_idx_mask, other=-1)
            s_input_mask = s_input_idx_mask
            s_input = tl.load(s_base + input_idx, s_input_mask, other=padding_num).to(tl.float32)
            inval_int32 = (convert_to_uint32(s_input) >> (24-round*8)) & 0xFF # 保证除了最后八位外都为0
            # inval_int32 = tl.where(s_input_mask, inval_int32, 0)
            s_histogram += inval_int32.to(tl.int32).histogram(HISTOGRAM_SIZE)
        #     if i_b == 0:
        #         print("s_input", s_input)
        #         print("inval_int32", inval_int32)
                
        # if i_b == 0:
        #     print("s_histogram", s_histogram)
        s_histogram = s_histogram.cumsum(0, reverse=True) # 后缀和
        mv_idx = tl.arange(1,HISTOGRAM_SIZE+1) % HISTOGRAM_SIZE # 构造错位索引矩阵
        # cond = (s_histogram > l_new_topk) & (s_histogram.gather(mv_idx, 0) <= l_new_topk)
        # l_threshold_bin_id = tl.where(cond, tl.arange(1, HISTOGRAM_SIZE+1), 0).max(0)
        # l_threshold_bin_id = tl.where(l_threshold_bin_id>0, l_threshold_bin_id, HISTOGRAM_SIZE) - 1
        cond = (s_histogram > l_new_topk) & ((s_histogram.gather(mv_idx, 0) <= l_new_topk) | (mv_idx == 0))
        l_threshold_bin_id = cond.argmax(0)
        l_new_topk -= tl.where(tl.arange(0, HISTOGRAM_SIZE)==l_threshold_bin_id+1, s_histogram, 0).max(0)
        thre_bin_sum, old_thre_bin_sum = 0, thre_bin_sum

        # if i_b == 0:
        #     print("l_threshold_bin_id", l_threshold_bin_id)
        #     print("cur_sum", cur_sum)

        #     print("\n")
        for s in range(ss):
            s_input_idx = s * BK + tl.arange(0, BK)
            s_input_idx_mask = s_input_idx < old_thre_bin_sum
            # 双buffer input_idx = tl.load(s_input_ids_base_load + s_input_idx, s_input_idx_mask, other=-1)
            input_idx = tl.load(s_input_ids_base + s_input_idx, s_input_idx_mask, other=-1)
            s_input_mask = s_input_idx_mask
            s_input = tl.load(s_base + input_idx, s_input_mask, other=padding_num).to(tl.float32)            
            inval_int32 = (convert_to_uint32(s_input) >> (24-round*8)) & 0xFF # 保证除了最后八位外都为0
            # inval_int32 = tl.where(s_input_mask, inval_int32, 0)

            over_thre = inval_int32.to(tl.int32) > l_threshold_bin_id
            cur_sum = over_thre.to(tl.int32).sum(-1)
            eq_thre = inval_int32.to(tl.int32) == l_threshold_bin_id
            thre_bin_cur_sum = eq_thre.to(tl.int32).sum(-1)

            topk_idx = over_thre.to(tl.int32).cumsum(-1)
            thre_bin_idx = eq_thre.to(tl.int32).cumsum(-1)

            # if (input_idx==65464).sum(-1) != 0 :
            #     print("input", tl.where(input_idx==65464, s_input, 0).sum(-1))
            #     print("l_threshold_bin_id", l_threshold_bin_id)
            #     temp = tl.where(input_idx==65464, inval_int32, 0).sum(-1)
            #     print("inval_int32", temp)
            #     origin = (convert_to_uint32(s_input) >> (24-round*8))
            #     print("inval_int32_32", tl.where(input_idx==65464, origin, 0).sum(-1))
            #     histo = tl.where(tl.arange(0,HISTOGRAM_SIZE)==temp, s_histogram, 0).sum(-1)
            #     print("histogram_suffix", histo)
            #     print("histogram", histo-tl.where(tl.arange(0,HISTOGRAM_SIZE)==temp+1, s_histogram, 0).sum(-1))

            concat_mask = tl.cat(over_thre, eq_thre, True)
            concat_input = tl.cat(input_idx, input_idx, True)
            # 双buffer concat_pointer_matrix = tl.cat(indices_base + sum + topk_idx - 1, s_input_ids_base_store + thre_bin_sum + thre_bin_idx - 1, True)
            concat_pointer_matrix = tl.cat(indices_base + sum + topk_idx - 1, s_input_ids_base + thre_bin_sum + thre_bin_idx - 1, True)

            # tl.debug_barrier()
            tl.store(concat_pointer_matrix, concat_input, mask = concat_mask)
            
            # tl.store(indices_base + sum + topk_idx - 1, input_idx, mask = over_thre)
            # tl.store(s_input_ids_base + thre_bin_sum + thre_bin_idx - 1, input_idx, mask = eq_thre)
                    
            thre_bin_sum += thre_bin_cur_sum
            sum += cur_sum
    
        round += 1
            
    # breakpoint()
    # tl.debug_barrier()
    # if i_b == 0:
    #     print("ther_bin_sum", thre_bin_sum)
    #     print("sum", sum)
    #     print("l_new_topk", l_new_topk)

    # 双buffer s_input_ids_base_load = s_input_ids_base + SMEM_INPUT_SIZE * if_odd
    if l_new_topk > 0:
        ss = tl.cdiv(l_new_topk, BK)
        for s in range(ss):
            s_input_idx = s * BK + tl.arange(0, BK)
            s_input_idx_mask = s_input_idx < l_new_topk
            # 双buffer input_idx = tl.load(s_input_ids_base_load + s_input_idx, s_input_idx_mask, other=-1)
            input_idx = tl.load(s_input_ids_base + s_input_idx, s_input_idx_mask, other=-1)
            s_input_mask = s_input_idx_mask
            tl.store(indices_base + sum + tl.arange(0, BK), input_idx, mask = s_input_mask) # 这一句非常慢
            sum += BK


def bucket_sort_topk(inputs, starts, ends, topk):
    B, S = inputs.shape
    K = topk
    HISTOGRAM_SIZE = 256
    SMEM_INPUT_SIZE = 8192
    indices = torch.ones(B, topk, dtype=torch.int32, device=inputs.device) * -1
    # s_histogram = torch.zeros(B, HISTOGRAM_SIZE, dtype=torch.int32, device=inputs.device)
    s_input_idx = torch.zeros(B, SMEM_INPUT_SIZE*2, dtype=torch.int32, device=inputs.device)
    grid = (B,)
    kernel_bucket_sort_topk[grid]( # grid(B, BS)
        inputs, # (B, S) 注意，没有 H，因为MLA基于MQA和MHA而非GQA
        indices, # (B, K) topk 索引数组
        # s_histogram,
        s_input_idx,
        starts,
        ends,
        S, # sequence length
        K, # k of topk
        HISTOGRAM_SIZE,
        SMEM_INPUT_SIZE
    )
    # print("s_input_idx", s_input_idx)
    return indices


def test_topk_selector(batch=64, seq_len=32 * 1024, topk=2048):

    batch = 64
    seq_len = 32 * 1024
    topk = 2048
    torch.manual_seed(1)
    input = torch.randn(batch, seq_len, dtype=torch.float32).cuda()
    starts = torch.zeros(batch, dtype=torch.int32).cuda()
    ends = torch.ones(batch, dtype=torch.int32).cuda() * seq_len

    indexes = bucket_sort_topk(input, starts, ends, topk)
    print(indexes)

    indexes_ref = torch.topk(input, topk, dim=-1)[1]
    print(indexes_ref)

    torch.set_printoptions(
        threshold=100,  # 显示所有元素
        edgeitems=100,            # 不省略边缘元素
        linewidth=100  # 不换行
    )
    # indexes_ref = fast_topk(input, topk)
    # print(indexes_ref)
    # Calculate intersection of out_ref and out_trt
    for i in range(batch):
        ref_np = indexes_ref[i].cpu().to(torch.int32).numpy()
        trt_np = indexes[i].cpu().to(torch.int32).numpy()

        set_ref = set(ref_np)
        set_trt = set(trt_np)
        intersection = set_ref & set_trt
        print("selected/all:", len(intersection), "/", len(set_ref), "=",
              len(intersection) / len(set_ref))
        # if len(intersection) != len(set_ref):
        #     print(ref_np)
        #     print(trt_np)
        # if len(intersection) != len(set_ref):
        #     ref_ordered = input[i][ref_np].sort()
        #     trt_ordered = input[i][trt_np].sort()
        #     # print(ref_ordered[1])
        #     # print(trt_ordered[1])
        #     print(indexes_ref[i][ref_ordered[1]])
        #     print(indexes[i][trt_ordered[1]])
        # # if len(intersection) != len(set_ref):
        # #     print(input[i][ref_np])
        # #     print(input[i][trt_np])

    # Performance test with CUDA events

    # torch.cuda.synchronize()
    # start_event = torch.cuda.Event(enable_timing=True)
    # end_event = torch.cuda.Event(enable_timing=True)

    # # Warmup
    # for _ in range(200):
    #     _ = bucket_sort_topk(input, starts, ends, topk)
    # torch.cuda.synchronize()

    # n_iters = 200
    # start_event.record()
    # for _ in range(n_iters):
    #     _ = bucket_sort_topk(input, starts, ends, topk)
    # end_event.record()
    # torch.cuda.synchronize()
    # elapsed_time_ms = start_event.elapsed_time(end_event)
    # print(f"Average bucket_sort_topk time: {elapsed_time_ms / n_iters:.3f} ms")

    # # Warmup
    # for _ in range(200):
    #     _ = tl_topk(input, starts, ends, topk)
    # torch.cuda.synchronize()

    # start_event.record()
    # for _ in range(n_iters):
    #     _ = tl_topk(input, starts, ends, topk)
    # end_event.record()
    # torch.cuda.synchronize()
    # elapsed_time_ms = start_event.elapsed_time(end_event)
    # print(f"Average tl_topk time: {elapsed_time_ms / n_iters:.3f} ms")


    # # Torch topk time
    # start_event.record()
    # for _ in range(n_iters):
    #     _ = torch.topk(input, topk, dim=-1)[1]
    # end_event.record()
    # torch.cuda.synchronize()
    # elapsed_time_ms = start_event.elapsed_time(end_event)
    # print(f"Average torch.topk time: {elapsed_time_ms / n_iters:.3f} ms")


if __name__ == "__main__":
    test_topk_selector()